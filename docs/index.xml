<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Jon Minton&#39;s Blog</title>
<link>https://jonminton.github.io/jon-blog/index.html</link>
<atom:link href="https://jonminton.github.io/jon-blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Jon Minton&#39;s personal blog. All things random.</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Mon, 13 Oct 2025 23:00:00 GMT</lastBuildDate>
<item>
  <title>Climbing with Claude: Understanding Collaborative Version Control</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/handdrawn-stats/version-control-as-rock-climbing/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Collaborative version control, with git and GitHub, is the coders’ <strong>Big Little Secret</strong>. It offers a set of tools and approaches to working securely, safely and collaboratively with others (including one’s past self) on complex projects that is <em>potentially</em> very transferrable to almost any kind of knowledge work that involves writing stuff down. (So, pretty much anything office-based.) Not just transferrable to other kinds of knowledge work, but potentially <em>transformative</em>.</p>
<p>The git/GitHub collaborative version control pattern isn’t coders’ <strong>Big Little Secret</strong> because coders <em>want</em> it to be a secret, however. Instead, it’s because collaborative version control, through git and GitHub, is <em>fundamentally weird</em>, inherently <em>arcane</em>, unintuitive, difficult to ‘grok’.</p>
<p>For years, I’ve been trying to work out some more intuitive ways to explain git/GitHub. And now, below, with the embarassingly sizeable help of Claude Sonnet 4.5, I think I might have it: <strong>Git/GitHub as rock climbing</strong>.</p>
<p>(If you’d prefer, you can <a href="git_climbing_guide.html">view the above directly too</a>)</p>
<p><em>Enjoy</em></p>
<iframe src="git_climbing_guide.html" width="100%" height="800px" style="border:none; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);"></iframe>


</section>

 ]]></description>
  <category>llm-generated</category>
  <category>version-control</category>
  <category>git</category>
  <guid>https://jonminton.github.io/jon-blog/posts/handdrawn-stats/version-control-as-rock-climbing/index.html</guid>
  <pubDate>Mon, 13 Oct 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Nine thoughts on Tim Berners-Lee’s This is for Everyone</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/was-this-for-everyone/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/was-this-for-everyone/this-is-for-everyone.jpg" class="img-fluid figure-img" alt="Book cover for This is For Everyone (2025) by Tim Berners-Lee"></p>
<figcaption class="figure-caption">This is for everyone</figcaption>
</figure>
</div>
<p>After reading, and writing my longest ever post about, Helen Lewis’ <em>The Genius Myth</em>, I entered a slightly fallow period in terms of reading engagement and motivation. I’d started reading <em>The Genius Myth</em> alongside Rutger Bregman’s <em>Moral Ambition</em>, but my interest in that book faded,<sup>1</sup> and I struggled to find something as engaging as the book I’d just finished.</p>
<p>Early in the third week of September, however, this fallow period finally ended, when I heard <a href="https://podcasts.apple.com/gb/podcast/the-man-who-invented-the-world-wide-web-tim-berners-lee/id1665265193?i=1000726522269">Tim Berners-Lee (TBL) being interviewed</a> by Rory Stewart and Alastair Campbell in The Rest is Politics Leading podcast series, to promote his new autobiography, <a href="https://www.tgjonesonline.co.uk/Product/Tim-Berners-Lee/This-is-For-Everyone/15609035?gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=22742995189&amp;gbraid=0AAAAAD-7g6QvyfwrhJCsO3hzpjljPttlq&amp;gclid=Cj0KCQjwo63HBhCKARIsAHOHV_VSorzAuwDEC7X-uk43tuZTX6QTedyuU2-pVNcISTmiVfcJUywa1zIaAjZ5EALw_wcB"><em>This is for everyone</em></a>, which in a sense is also an autobiography of the world wide web, his invention. I’d ordered the book within a few minutes of the podcast ending, and finished reading it in about three days (which is fast for me).</p>
<p>Here are nine thoughts I had prompted by (primarily) the book and the podcast:</p>
<section id="idea-1-why-are-you-only-a-millionaire-not-a-billionaire" class="level2">
<h2 class="anchored" data-anchor-id="idea-1-why-are-you-only-a-millionaire-not-a-billionaire">Idea 1: “Why are you only a millionaire, not a billionaire?”</h2>
<p>This seemed to be the subtext of (what felt like) at least half a dozen questions from on the TRIP Leading podcast, especially from Rory Stewart. To Stewart and Campbell, and I’m sure many who swirl in their social circles, the web is an engine of supreme wealth generation, a place that has created a new billionaire class, whose products affect almost everyone on Earth every day of our lives in some ways. So Stewart and Campbell seemed perplexed that the creator of the web, someone who ‘ought’ to have had the supreme first mover advantage, was ‘only’ a millionaire and not a billionaire. Even more perplexing to Stewart and Campbell: why does TBL appear not to <em>want</em> to be a billionaire, and not appear in any way envious of those who used his technology to become thousands of times wealthier than he is? Linked to this - something Stewart warned and apologised to the listener for at the start of the podcast - why is TBL not the highly articulate and polished media performer ‘we’ (?) are now conditioned to expect from Silicon Valley?</p>
<p>These questions weren’t, to my mind, hostile questions so much as questions orthogonal to TBL’s personality, pursuits and interests. To Stewart and Campbell, not seeking to use one’s ability to maximise wealth, power and influence appeared simply not to make sense. The best explanation they could come up with was simply that TBL is <em>an eccentric</em>, though really this is just a (borderline derogatory) label rather than an explanation.</p>
<p>Having read the book, however, I think the real answer is that TBL is, was, and always will be deeply passionate about building and promoting systems that connect information, ideas, and people, and that so long as his material circumstances are never so adverse as to impinge on this lifelong calling, they will always be sufficient. Sometimes money helps, as with ensuring TBL’s web-standards body, W3O/W3C, remains financially afloat; but often it risks making the web ‘worse’, which to TBL seems to have consistently meant something like ‘able to allow free exchange of information’. One of TBL’s proudest achievements, for example, seems to have been to convince CERN to give the world http, in perpetuity, for free [p.&nbsp;103]; another was to fight, through W3C, for the web to never become <em>de-facto</em> proprietary through intentional disalignment on standards between browsers run by either Microsoft or Netscape, both of which wanted to introduce additions and features to ‘their version’ of the web which were incompatible with other providers. TBL doubtless had many opportunities to make decisions which would have have allowed him to own and profit from a more proprietary variant of the web (such as if he worked with Netscape to build ‘the new Netscape web’), but would have slowed down growth and access to the web: whenever given the choice between owning a larger share of a smaller pie, or owning but influencing a more vibrant and faster growing pie, he seems to have chosen the option that makes the web better, rather than himself richer. His vision, always, seems always to have been much grander than personal fortune or political power. If that’s ‘eccentric’ for Stewart and Campbell, then in a sense that speaks mainly to their lack of genuinely transcendent vision, rather than TBL’s inherent strangeness.</p>
</section>
<section id="idea-2-cern-and-http-is-organisational-efficiency-fundamentally-a-myth" class="level2">
<h2 class="anchored" data-anchor-id="idea-2-cern-and-http-is-organisational-efficiency-fundamentally-a-myth">Idea 2: CERN and http: Is organisational efficiency fundamentally a myth?</h2>
<p>I vaguely remember seeing and hearing an online lecture by TBL many years ago, where in his excitable, self-distracting, and frenetic style he said something like “I took my proposal [for http] to my line manager. He said ‘I don’t really understand what you’re talking about. Why not spend a few weeks working on it?’” Within the book I can’t find the exact same quote (which of course I might have confabulated), but there are still plenty of references to those around TBL have difficulty understanding his vision, and the proportionality and relevance of his proposals to his specific remit at CERN, but nevertheless recognising his passions and ability, and supporting him in developing his ideas into technologies.</p>
<p>To this end, TBL writes of effectively being ‘protected’ by his bosses and his bosses’ bosses, despite them often having little understanding of what he was doing.</p>
<p>What does this say for the very idea of organisational efficiency? Though there were likely some genuine benefits to developing http within CERN, the specific examples - such as being able to find people’s phone numbers, linked research publications, and brief biographies of fellow staff at CERN a bit more easily - may well have never, in a strict sense, have been proportionate to the cost of investment. If CERN had been a more ‘efficient’ organisation, an organisation where all costs and expenses have to be justified clearly within work programes and cost centres, and audited carefully to justify the organisation’s costs to the European tax payer, it may well have killed the web before it was ever born.</p>
<p>Even considering the discovery of the Higgs Boson, however, the web is almost certainly the most important contribution CERN has made, or will ever made, to humanity. And it would never have done this if CERN were a truly ‘efficient’ organisation. Is the very idea of organisational efficiency therefore something of a dangerous myth?</p>
<p>I suspect the answer’s both yes and no. Efficiency seems a useful concept when it’s clear what we want to maximise, but an horrific and crushing concept when we don’t. One idea I’ve been fascinated by for many years are fitness surface optimisation algorithms, and the ways that the most ‘efficient’ algorithms tend to lead us to local optima, rather than global optima, when the fitness surface is complex rather than simple. The most efficient approaches are akin to ‘blind hill climbers’: place one of these devices on a hill within the landscape we want to explore, and it will detect locally the gradient around it, and start trundling to ever higher elevation, until the top of the hill is reached. Then it will stop. But if the hill on which the hill-climber is placed is an undulation in the shadow of a mountain, it won’t see or detect the mountain, and forever find itself stuck on the hill instead. At every step along the way, the hill-climber can report incremental improvement, but it will never understand the broader landscape, and the opportunities that might present themselves if it were less ‘efficient’ and allowed occasionally to simply ‘wonder around’.</p>
<p>Any approach that allows the possibility of finding the global optima consistently will necessarily be less ‘efficient’. One approach is to employ an ensemble of hill-climbers, each dropped off in different locations of an invisible and unexplored landscape. (i.e.&nbsp;to give the algorithms different starting values.) If there were 10 hill climbers, and they all end up on the same place as a single hill climber, then ten times as much effort will have been spent on finding the same optima. Clearly very ‘inefficient’. But if one of the ten hill climbers happens to have started at the foot of the mountain, whereas the rest were all somewhere along the hill, and the mountain’s peak elevation is twenty times as that of the hill, then the reward will have been worth the additional effort.</p>
<p>Another, related, related approach is to intentionally build into the algorithms an element of ‘forgetfulness’ and ‘play’, which clearly seems a very inefficient thing to do. Think of these algorithms as more like ladybirds, with both a ‘flying’ phase and a ‘crawling’ phase. 95% of the time (say) the algorithms are in the crawling phase, and behave just like the standard hill climbers. But then 5% of the time these algorithms suddenly start flying around, and land somewhere completely different. Often, this means that the apparent progress towards the top of the last hill’s peak has been lost - something that seems very wasteful - but <em>maybe</em> during the flying phase the ladybird has found its way to an even higher section of the same hill; or found its way to the base of the mountain - the true global optima, rather than the local optima the simple hill climbers would have dutifully crawled.</p>
<p>By analogy, the most genuinely innovative organisations support staff to pursue both ‘flying’ and ‘crawling’, and to this extent trade-off some ‘efficiency’ for more possibility of creativity. Within large organisations, the freedom to fly has often found its way through permitting or actively promoting ‘skunkworks’. And within small tech outfits, through the idea of ‘pivoting’: recognising that an adjunct of one technology and use-case might actually be where the genuine value of a technology and business exists. Getting the balance right between flying and crawling is a perennial challenge, but to only value the measurable ‘efficiency’ of crawling over the immeasurable potential benefits of flying makes for a bad organisation and bad society.</p>
</section>
<section id="idea-3-top-down-and-bottom-up-modes-of-enterprise-need-to-know-how-to-dance" class="level2">
<h2 class="anchored" data-anchor-id="idea-3-top-down-and-bottom-up-modes-of-enterprise-need-to-know-how-to-dance">Idea 3: Top down and bottom up modes of enterprise need to know how to dance</h2>
<p>The web (or rather http) is not the internet, which was developed in the US through military funding, before spreading through US universities. The military: top-down organisation based on hierarchy and standards operation processes; universities: bottom-up institutions based on exploration and emergent connections. Within the US, top-down started, then bottom-up followed.</p>
<p>Another theme of questions from Stewart and Campbell, once they’d tired of asking TBL why he wasn’t a billionaire, was “Why did the US, not Europe, capitalise so much on the European technology of the web?” The short answer seemed to be that the web was the next step of the internet dance that was taking place in US universities, and so the bottom-up, freewheeling sensibilities of these US research institutions were highly compatible with TBL’s vision of the web. Http was intended as a means of allowing people to tell machines something that people can identify easily but machines cannot: the way that data sources are connected and linked in the human mind. And it was intended to do so in a way that was akin to conversation: originally TBL wanted web pages to be editable by default, rather than just viewable, allowing new readers to themselves become editors, and find and refine the associations between nodes even further. Http was a lightweight framework offering a lot of possibilities for how people build links with each other. This open, democratic (but meritocratic) mentality was much more compatible with the often-anarchic researchers already using and familiar with the internet in US research institutions.</p>
<p>By contrast, it seems Europe was relatively reluctant to adopt the web for the same reasons the hippies and nerds over the Atlantic were keen on it: it was too <em>bottom-up</em>. The European instinct was instead to support and enforce a more top-down model of information sharing, based much more on conventions and standards. And conventions and standards mean meetings and bureaucracy, and meetings and bureaucracy takes <em>time</em> for deliberation and agreement. In short, it seems like Europe lost the advantage of its own technology by trying to <em>tame</em>, <em>organise</em> and <em>categorise</em> it, to make it work better in theory, rather than to adopt and use it in practice. After teaching the US a new series of dance moves, European bureaucracies then refused to dance any further.</p>
</section>
<section id="idea-4-the-web-was-for-information-not-engagement" class="level2">
<h2 class="anchored" data-anchor-id="idea-4-the-web-was-for-information-not-engagement">Idea 4: The Web was for Information, not Engagement</h2>
<p>For TBL, Wikipedia is the clearest working example of the web that he had envisaged. Wikipedia is not, by and large, a particularly <em>addictive</em> website. Instead, it’s something people will use to find information on something, and then once they’ve found that information, they will stop using it. Disengagement is therefore a <em>feature</em> of Wikipedia, not a <em>flaw</em> in Wikipedia.</p>
<p>But much of the modern web is the other way around: intended to <em>engage</em>, not to inform. The reasons for this are obvious once given the types of monetisation that have prevailed over the last twenty or so years: the profitability of a website is broadly proportional to the amount of time people spend on it, because users’ attention is the resource such companies sell to advertisers. Whereas the original aim of the web was to help people find what they are looking for, the engagement imperative of the commercial web instead militated towards almost the opposite: ensuring that users want more, but find less.</p>
</section>
<section id="idea-5-would-the-semantic-web-have-led-to-smarter-but-less-polite-ais" class="level2">
<h2 class="anchored" data-anchor-id="idea-5-would-the-semantic-web-have-led-to-smarter-but-less-polite-ais"><strong>Idea 5: Would the semantic web have led to smarter (but less polite) AIs?</strong></h2>
<p>Though the web itself saw explosive growth, some of TBL’s later ideas, promoted either personally or through the W3C, have found much less enthusiastic adoption. This includes what TBL referred to as ‘the Semantic Web’, or ‘Web 3.0’. In essence this was an argument, and a recommended set of standards, for embedding more machine readable data and information about associations between entities into websites. From the perspective of most viewers of a website, almost nothing would look any different. But within each site, so went the vision, was an extensive categorisation of information about entities and their relationships which a computer could understand. Eventually, if everyone building and maintaining websites went to the trouble of formally expressing information about what things are, and how they are are associated, then big thinking machines, crawling across the internet, could also become loaded up with all this information, and with enough entities, definitions, and associations, start to learn enough about the world to reason about it.</p>
<p>Perhaps the idea that individuals and businesses would go to a great deal of extra trouble to help computers know such facts as “Dresen is a city” and “Socrates is a man” was always fanciful, and so the concept was doomed from the get-go. TBL blames specific big players, like Microsoft, for not wanting to adopt semantic web standards, including RDF.</p>
<p>Perhaps modern LLMs, and how they work, has shown that the Semantic Web was not just unrealistic in terms of the amount of work it was expecting people to do behind the scenes to be nice to machines, but also turned out not to be especially valuable in helping machines to ‘think’ in any case.</p>
<p>There are broadly two paradigms guiding artificial intelligence research: semantic, and Markovian. The semantic paradigm was based around the idea that, if we explicitly instruct machines with enough facts and propositions, then eventually the machine will be able to take this nexus of information and reason on its own. The semantic web seems clearly most wedded this this paradigm for artificial intelligence.</p>
<p>The Markovian paradigm, by contrast, just requires streams of text, or other forms of data. The text doesn’t have to say anything rational or sensible - it could exclusively comprise verbatim transcripts of the ramblings of Schizophrenics,, for example - but there does need to be a lot of it. From this paradigm, the intelligence of AI is - depending on perspective - illusory or emergent, and just comes about from the data getting processed ever more effectively and comprehensively to predict the next word, or the next sentence, or the next paragraph.</p>
<p>Of the two AI paradigms, the second definitely sounds a lot dumber. But over the past five years (at most) pretty much all progress in AI has come from researchers, mostly commercial, pursuing this second paradigm. The results have been spectacular, and perhaps indicate we just don’t need the kind of explicit reasoning and logical, rule-bound cogitation that the first paradigm, and the semantic web, appeared to presume were so important.</p>
<p>On the other hand, many LLMs are exquisite confabulators and bullshitters, able to generate vast amounts of prose that claim with apparent confidence things that are utterly untrue, rewriting history to suit the apparent whims and wishes of the user, referencing academic papers making impossible claims that don’t exist, and so on. Although the apparent reasonableness of most LLMs has increased, and continues to each year, the tendency for LLMs to veer off into unreason and mutual insanity when the flow of a conversation takes them that way, seems something inherent to the stream-based-next-token-generating paradigm they sit upon.</p>
<p>Perhaps, if the semantic web had been as popular in the 1990s and 2000s as the original web had been, the first paradigm for AI might have won the race instead, and we would now have AIs that are both terser and more rational?</p>
<p>There is one area in which the value proposition of meeting semantic web standards is relatively clear, however, and that relates to making the web more accessible for persons with, for example, visual impairments. A picture of an apple, for example, would need to be labelled as a picture of an apple in order for a screen reader to tell a user what the images contain. By making the contents of websites more accessible to machines, semantic web standards also help make contents more accessible to ever more people as well. Requirements to make more of the web more accessible have been growing in recent years, especially in the EU, and so perhaps it is through such mandates and requirements that the semantic web can still find fuel to grow.</p>
</section>
<section id="idea-6-household-microcultures-a-licence-to-be-uninhibited-in-eccentric-passion" class="level2">
<h2 class="anchored" data-anchor-id="idea-6-household-microcultures-a-licence-to-be-uninhibited-in-eccentric-passion"><strong>Idea 6: Household Microcultures: A licence to be uninhibited in eccentric passion</strong></h2>
<p>If TBL appears eccentric, it’s likely partly because he is, and also because he was born and raised in a household environment where pursuits, preoccupations and interests that would strike most people as unusual were simply accepted. Both TBL’s parents were computer scientists and mathematicians, working in the nascent British computer industry of the 1950s. And both were highly creative systematisers, who fully supported TBL’s efforts as a child to build his own Heath Robinson-style computing device in the 1970s for the sheer sake of it, despite the risk of electrocution and exploding televisions.</p>
<blockquote class="blockquote">
<p>The first thing I built was a switch for my model railway. Then I built an intercom that linked the upper and lower floors of the family house. (‘He was very useful as the engineer around the house’, Mum would later say.) I bought a ‘breadboard’, a simple physical platform for building circuits, and starting chaining together logic gates made from my cast-off transistors. You could make a circuit on the breadboard in minutes, and if it worked, you could solder it up on a printed circuit card to make it permanent. I made a train whistle circuit and some automation for the model trains. [pp.&nbsp;19-20]</p>
</blockquote>
<p>TBL remembers his parents, who lived into their nineties, very fondly, despite occasionally being a victim of the downside of obsessive preoccupation:</p>
<blockquote class="blockquote">
<p>Dad was brilliant, but he could be a little absent-minded. One time, he took me to pick up his shirts at the dry-cleaner’s. He got the shirts, but left me behind in my pushchair. Another time, he parked our car by an embankment on the Thames. He returned to find the tide washing over it. When he was travelling back to London from Manchester will colleagues one day, he could not find the return half of his train ticket at the barrier at the station. His colleagues assured the ticket inspector that he had just lost it and was always forgetting things. So he got home, and then my mother asked, ‘Conway, where’s the car?’ [pp.&nbsp;11-12]</p>
</blockquote>
<p>For someone not similarly dispositioned to his parents, accounts like the above would have been grist for a misery memoir. For TBL, such incidents appear as fondly remembered as any others.</p>
</section>
<section id="idea-7-who-owns-my-data-double" class="level2">
<h2 class="anchored" data-anchor-id="idea-7-who-owns-my-data-double"><strong>Idea 7: Who owns my data double?</strong></h2>
<p>At the end of the TRIP Leading interview, Stewart picked up that TBL had become slightly frustrated with the types of question he had been asked (including implicit invitations to express envy and enmity towards billionaires and politicians), and asked (something like) “Is there anything you wish we had asked you?”</p>
<p>Somewhat regretfully, TBL stated (something like): “Well, I do wish you’d have asked more about the SOLID principles I’ve been developing and promoting the last few years:”</p>
<p>Much as the Semantic Web was TBL’s passion project in the late 1990s and 2000s, so in the 2010s and 2020s the question of personal data ownership - <em>cue bono</em>? - appears to have become TBL’s contemporary concern.</p>
<p>And with good reason, I’d suggest. If you’re not paying for a service, so the saying goes, you’re not the customer, you’re the product. And for companies like Facebook/Meta and Google the value of harvesting personal data is clearly estimable in the billions, with dividends returned to shareholders, not the users whose data are harvested. Meanwhile, inefficiencies and disconnects in many public and private services, lack of comprehensive and shared data about individuals, frequently leads to deeply frustrating experiences for those trying to get, for example, good quality healthcare, housing support, and financial services.</p>
<p>The problem, from TBL’s perspective, isn’t necessarily that too much, or too little, data is held about individuals, but that the individuals don’t own their own data. If individuals really did own their own data, they would have a clearer idea about how much such data are worth, and be able to make more informed and engaged decisions about how such data should be shared.</p>
<p>TBL tries, with some success, to articulate his vision as follows:</p>
<blockquote class="blockquote">
<p>Within the semantic web community, the idea of a ‘bit of the web of data which you own’ was becoming more and more desirable. So we built containers for our own data, and we called the containers Personal Online Data Stores, or ‘PODS’ [p.&nbsp;245]</p>
</blockquote>
<blockquote class="blockquote">
<p>We struggled to think of what to call [the PODS specification]… settling on ‘Social Linked Data’, or Solid… [p.&nbsp;245]</p>
</blockquote>
<blockquote class="blockquote">
<p>With Solid we had an ecosystem where your pod would sit like a blank canvas, or an empty Scrabble board, waiting for apps to write facts into it. [p.&nbsp;245]</p>
</blockquote>
<blockquote class="blockquote">
<p>The Solid layer would accomplish two things simultaneously. First, it would restore the privacy of the individual on the web, who would no longer have to worry what data was being generated about them, or who was looking at it. Second, it would unlock all manner of new functionality, by connecting data that had previously been stored in separate containers. [p.&nbsp;247]</p>
</blockquote>
<blockquote class="blockquote">
<p>For example, there were obviously huge benefits to be realized by attaching your smartwatch data to your medical records. If you were looking for new shows to watch, or new media to consume, you might attach your browsing history to a content recommendation algorithm. If you wanted to get a mortgage, you could attach your spending habits to your application. Maybe a travel agent would even be willing to pay you for access to information about the countries you’d visited and the restaurants you preferred. Of course, all of this was optional; if you were a privacy-oriented person, you would never have to share any of this information, and even if you did, you’d automatically be able to see who had access to anything you did share. [p.&nbsp;247]</p>
</blockquote>
<p>As with the semantic web, such a shift in data ownership standards might seem both highly technical and highly idealistic (two terms at whose intersection is often found TBL) and we might struggle to imagine how we could conceivably get from here - where warring territories of international corporations own and profit from our data in separate proprietary cages - to there - where Solid PODS empower the individual to choose what to share with third parties. It could come about, perhaps, if such a shift to Solid PODS were shown to enrich and empower all stakeholders - individuals, public services, private corporations alike - much as people tend to stick to the same rule of which side of the road to drive on for their benefit as much as others; and almost everyone agrees that some taxation is acceptable to pay for, at least, basic physical infrastructure and national security. Similarly, it could become adopted if a coalition of corporate underdogs - the second, third and forth largest companies, collectively owning 70% of personal data - adopts it to challenge the top dog. Or because a province, then a state, then a country, then a continent, adopts it first for public services, and at each stage the benefits in terms of reduced data friction and improved services are demonstrated.</p>
</section>
<section id="idea-8-apps-the-walled-gardens-of-the-modern-web" class="level2">
<h2 class="anchored" data-anchor-id="idea-8-apps-the-walled-gardens-of-the-modern-web"><strong>Idea 8: Apps: The Walled Gardens of the Modern Web</strong></h2>
<p>To an extent, phone apps are just little wrappers around pieces of web content. But as TBL came to realise, in practice they’re something much more, and much worse:</p>
<blockquote class="blockquote">
<p>I think the mobile experience would have been greatly improved if you didn’t have to download an app every time you wanted to engage with a new service. Interestingly, that’s what Steve Jobs seemed to first showcase with the iPhone.. If you watch his original presentation for the device, from 2007, he repeatedly demonstrates the unlimited functionality of the iPhone’s Safari browser. The app store wouldn’t launch for more than a year.</p>
</blockquote>
<blockquote class="blockquote">
<p>Why did Jobs change direction? The answer was suggested to me at a clandestine rendezvous I had in the late 2000s with a Google engineer who shall remain unnamed. We met at a restaurant at Half Moon Bay, a popular beach town across the mountains from Silicon Valley. At a quiet table overlooking the ocean, the engineer explained to me that, from what he could see from deep inside Google, Apple was deliberately throttling the functionality of both the Safari and Chrome mobile browsers. Apple, you see, got a 30 per cent commission of the apps it sold; plus, it received continuing income from subscriptions and in-app purchases. It was much more profitable for Apple to direct the developers to build an app than to build a mobile website. Apple got a cut from the former, and nothing from the latter.</p>
</blockquote>
<blockquote class="blockquote">
<p>I considered what he was saying as I stared out into the Pacific. He was right, of course …[p.&nbsp;226]</p>
</blockquote>
<p>TBL then concludes:</p>
<blockquote class="blockquote">
<p>The Apple app store was an example of exactly the kind of for-profit gatekeeping I’d always hoped the web could navigate around. But the iPhone was extraordinarily popular - I owned one myself. The toll booths the web had managed to avoid on the PC had found their way into the mobile realm.</p>
</blockquote>
<p>Quite.</p>
</section>
<section id="idea-9-even-nice-guy-millionaires-trade-up" class="level2">
<h2 class="anchored" data-anchor-id="idea-9-even-nice-guy-millionaires-trade-up"><strong>Idea 9: Even ‘Nice Guy’ Millionaires ‘Trade Up’</strong></h2>
<p>My last observation may strike the reader as somewhat facetious or <em>ad hominem</em>, because it is. But it was something that struck me, as ‘interesting’ at least, while reading the book.</p>
<p>Part way through, I lost count of the number of wives TBL has had, and became somewhat bemused by how casually he discussed the ending of each relationship, as well as non-professional relationships in general. I am fairly the answer is three. But each coupling and uncoupling - except the last - is mentioned with such parenthetic insouciance as to give each status change a kind of ‘blink-and-you-miss-it’ quality.</p>
<p>On TBL’s first wife, whom he met at Oxford:</p>
<blockquote class="blockquote">
<p>When my time at CERN was over, I saved the Enquire program to an 8-inch floppy disk, then entrusted it to Brian Carpenter. I included with the disk a five-page written explanation of what it was, and what it did. It wasn’t the last time I would see Brian Carpenter, but it was the last time I would see the disk. Our contracts were up and we returned to Poole. Sometime after, Jane and I decided to end our marriage and go our separate ways. [p.&nbsp;40]</p>
</blockquote>
<p>So, even decades later, TBL still appears bereft… about losing the disk containing a search program he’d written called enquire-within.</p>
<p>On meeting TBL’s second wife:</p>
<blockquote class="blockquote">
<p>While living in Switzerland, I met Nancy Carlson, an American working as an analyst at the World Health Organisation headquarters in Geneva. We moved in together and, a few years later, we married. Nancy worked with computers, too, and at home we shared a 286 Toshiba laptop. The personal computing revolution of the 1980s was well underway, and it was no longer necessary to build your own computer. I left my beloved homebrew computer behind in Poole; and in the mad rush to leave for CERN, I ended up throwing it out. (Kevin, the photographer of the group, took some photos of it.) In my apartment in Switzerland, I was content with a PC clone. [p.&nbsp;44]</p>
</blockquote>
<p>So, in the paragraph describing his meeting and marrying his second wife, TBL does use the term ‘beloved’… to describe the homebrew computer he discarded in Poole.</p>
<p>Writing about attending a trip to Finland to receive the Innaugural Millenium Technology Prize, TBL writes:</p>
<blockquote class="blockquote">
<p>The Finnish visit was one of the last official trips I took with Nancy. Our marriage in fact came to an end over the next few years, and I was hopeful for new horizons in my work and personal life [p.&nbsp;192]</p>
</blockquote>
<p>Two children, almost two decades of marriage, but time for Tim to move on. <em>With whom</em> is conveyed through some possibly inadvertent foreshadowing, in which Tim devotes more than a single sentence to a woman he knows (other than his mother):</p>
<blockquote class="blockquote">
<p>I first met Rosemary Leith at a dinner in 2008. The hosts were my friends Nigel Shadbolt and Wendy Hall, two professors at the University of Southampton. Nigel, Wendy and I were all on the board of the Web Science Trust, a charitable trust which supports interdisciplinary research into the effects the web has on society at large. They were courting Rosemary to join our board.</p>
<p>Rosemary was a highly accomplished businesswoman with an enormous gift in her ability to connect with people and understand how they think. She holds others and herself to a very high standard. She had grown up in Canada, then moved to the UK via Switzerland in the late 1980s to work for the private equity firm Pallas. In the late 1990s, she co-founded an early content company called Flametree, a dot-com that took advantage of web technology to provide flexible work-life solutions. Rosemary and her co-founder were very far ahead of their time; both had relied on flex-work in order to succeed in business while simultaneously raising children. Flametree was a success, and in 2001 they sold it to PwC just three years after inception. Rosemary then worked as a venture investor, using her ability to recognize early shifts in society that impacted technology and to see their resulting commercial impact.</p>
<p>I found in Rosemary a strong-willed, highly intelligent woman. She had dark hair, dark eyes and a winning smile. I liked her right away, and I began inventing reasons to see her again. I had a TED talk comping up and, although I didn’t know her very well, I asked her to help me write it. I believe she was a bit skeptical of me at first - but why don’t I let her tell this part of the story? [pp.&nbsp;204-205]</p>
</blockquote>
<p>There then follows another page in which Tim quotes Rosemary lavishing praise on Tim.</p>
<p>Then, in the world’s most predictable plot development:</p>
<blockquote class="blockquote">
<p>Years later, in 2014, when I asked Rosemary to marry me, the Queen gave us permission to use the Chapel Royal, dating from Henry VIII’s time, and the adjoining St James’s Palace, as our venue. [p.&nbsp;228]</p>
</blockquote>
<p>Many years ago, I remember listening to <a href="https://www.bbc.co.uk/sounds/play/p06n2nfl">an episode of Radio 4’s public statistics programme, More or Less</a>, discussing divorce rates within straight (or ‘mixed sex’) couples, as well as amongst gay men, and gay women. The key finding surprised me enough to have been burned in my consciousness ever since.</p>
<p>The key finding was this: Lesbian divorce rates are the substantially <em>higher</em> than divorce rates in mixed-sex couples, which are substantially higher than divorce rates amongst Gay Men. The researcher who crunched the numbers was interviewed, and matter-of-factly stated something like, “this was an expected result, as in mixed-sex couples it is more likely to be the female partner who initiates divorce proceedings, so in a sense we have in a Lesbian marriage a ‘double dose’ of partners with an increased proclivity to initiate divorce proceedings.” This finding is perhaps not we might expect if we assume divorce occurs mainly through something like a personality-mismatch pathway, in which inherent differences between male-typical and female-typical personality profiles would be expected to be greatest in mixed-sex couples, leading to the greatest level of conflict leading to divorce.</p>
<p>Now, though I think this higher-female-propensity-to-divorce tendency likely <em>is</em> true amongst most marriages, I think there may be an exception to this ‘rule’: amongst ‘high status’ (and rising status) males, I suspect it may be the male partner of a mixed-sex marriage who becomes more likely to divorce or separate (or at least to become increasingly inattentive, leading to the female partner to initiate divorce or separation proceedings). <em>Why?</em> Because someone who over the course of a marriage or other long-term relationship gains substantially in status and success also gains in <em>partner options</em>, i.e.&nbsp;the number of other people who may seek or be receptive to advances from ‘high status’ individuals. And, given polygyny (the marriage of one to many) is near-universally proscribed within modern societies, the caricatured response to these growing status-based opportunities for partners is for high status men (especially, but I suspect some women too) to ‘trade up’ through serial monogomy, multiple marriages, instead.</p>
<p>So, my suspicion is TBL’s multiple marriages may well fit this cliched pattern amongst ‘successful high status men’. So far, so disappointingly familiar. Three somewhat redeeming aspects to TBL’s own version of this pattern, however: firstly, that he never seems to have anything negative or critical to say about his previous wives (if in part because, at least in this autobiography, he has little to say about them at all); secondly, that he appears immensely proud and devoted to his children from previous marriages; and thirdly, that those traits he sought to ‘trade up’ in in his partners were those of professional success and ambition rather than youthfulness (see <a href="https://graziadaily.co.uk/celebrity/news/leonardo-dicaprio-dating-history/">DiCaprio’s Immortal Girlfriend</a>, for example), physical attractiveness, and subservience.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>So, there’s nine somewhat-random-and-scattershot ideas prompted by TBL’s book, and the podcast by which I became aware of it. Near the start I mentioned that I’m somewhat jaundiced by works of industrialist hagiography, hence not taking to Bregman’s <em>Moral Ambition</em>, and there are certainly aspects of <em>This is for Everyone</em> that could fit within this mould. Like Helen Lewis, I also rate highly Steven Johnson’s arguments about the <em>adjacent possible</em>, the concept that new ideas have their time and place, and it can often be little more than accident who takes credit for their discovery, as an antidote to excess beliefs that, but for a scattering of great individuals throughout history, we would still be banging rocks together. But at the same time, in this reality at least, I think there are clear, obdurate, and positive ways in which the specific form of the digitally connected world in which we all live - such as those related to interoperability and net neutrality - continue to be shaped by the flavour of interconnectivity brought by TBL’s vision in the late 1980s, rather than some - perhaps more profit-minded - also-ran who would have stepped into the <em>adjacent possible</em> if, for example, TBL’s bosses at CERN were not as forgiving of his idiosyncracies and reveries as they turned out to be.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The tl;dr: like many breathless works of hagiography, <em>Moral Ambition</em> struck me as monotone, valourising a personality profile that, in certain lights, sure looks pathological. Whereas ‘great man’ accounts running from Galton’s 19th century proto-eugenics work <em>Hereditary Genius</em>, and through to ‘titans of industry’ books of the 20th century, and into ‘cyberindustrialist’ books of the 21st century, valourise cognitively gifted monomanaics’ pursuit of wealth and growth in the private sector, Bregman’s <em>Moral Ambition</em> seems to employ exactly the same formula in valourising the same gifted-obsessive profile in the public and third sector.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>internet</category>
  <category>connections</category>
  <category>bureaucracy</category>
  <category>web</category>
  <category>eccentricity</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/was-this-for-everyone/index.html</guid>
  <pubDate>Sat, 11 Oct 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>The Man Who Solved Intelligence</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/the-man-who-solved-intelligence/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-man-who-solved-intelligence/thinking-game-image.jpg" class="img-fluid figure-img" alt="The thinking game documentary image"></p>
<figcaption class="figure-caption">The thinking game</figcaption>
</figure>
</div>
<p>Compared with OpenAI’s CEO Sam Altman, <a href="https://en.wikipedia.org/wiki/Demis_Hassabis">Demis Hassabis</a>, the cofounder of <a href="https://en.wikipedia.org/wiki/Google_DeepMind">DeepMind</a>, is perhaps less well know amongst the general public. However, after watching <a href="https://www.imdb.com/title/tt32150119/">The Thinking Game</a> recently, the 2024 documentary tracking DeepMind’s staggering progress towards Artifical General Intelligence (AGIs), Hassabis may well turn out to have been the more impactful in the course of human cultural and technological evolution. Founding the company in 2010 with the modest goal of ‘solving intelligence’, DeepMind was then acquired by Google in 2014 for an unfathonable amount of money, after being able to show remarkable success in teaching AIs to solve complex but well defined goal-orientated activities.</p>
<p>These complex but well defined goal-orientated activities: playing computer games, where the goals can be as simple as ‘win points’, but means of achieving this are anywhere but simple. Starting from Atari games from the late 1970s and 1980s, Alpha, DeepMind’s insatiably improving megatech, initially struggled, like any infant, to even know how to move a paddle up or down on a screen. But before too long it had learned to play an increasingly complex array of 8 bit games to greater standards than any human.</p>
<p>Hassabis is still fairly young, looks younger still, and appears to have lived many remarkable lives of precocious intellectual supremacy: a prize winning chess champion before the age of 10, completing secondary education a year early, and needing to wait a year before Oxford was legally permitted to admit him, he won a place at Peter Molyneux’ early 90s games powerhouse, Bullfrog, where he co-designed, and wrote the AI for, a game called Theme Park. He then turned down an offer of a million pounds to <em>not</em> attend university and continue coding games, because the Oxbridge degree was an essential part of his longer term vision.</p>
<p>Step ahead to the late 2000s. Hassabis - game player, game developer, computer scientist, and now neuroscientist - calmly and quietly explains firstly that his company aims to ‘solve intelligence’, and ‘produce an Artificial General Intellgience’, and secondly the types of modelling approach he thinks will achieve this aim.</p>
<p>Step ahead to 2020. Alpha has beaten the finest Go players in the world, a game recognised to be orders of magnitude harder for computers to master than Chess; it’s also almost unbeatable at StarCraft, a real time tactics game that has become an esports stalwart. Much more critically, it’s solved what may be the hardest game life has to offer: protein folding, predicting what kind of complex three dimensional structure is likely to emerge from a linear chain of amino acids, a problem that had represented a bottleneck on basic pharmaceutical and biological research for generations.</p>
<p>Step forward to 2024. Hassabis is a recipient of the Nobel Prize in Chemistry. AlphaFold has predicted the protein structure of almost every protein ever discovered. Rather than hoarding such knowledge, perhaps equivalent to millennia of human endeavour, DeepMind releases all predictions.</p>
<p>Although it may be OpenAI’s ChatGPT which showed the potential of AIs to the general public, to me the kinds of advances DeepMind have made seem much more impressive, and to offer a much stronger foundation for advancing towards a true <em>general</em> intelligence, based on very specific and measurable goals and aims, rather than in producing the kind of mellifluous sycophantic confabulation that LLMs tend to be (in)famous for. Real general intelligence, whether from ‘artificial’ origins or not, must be about more than the ability to endlessly produce sweet-sounding bullshit and uncanny slop.</p>
<p>Maybe I was too harsh on LLMs just then. My apologies. As penance, here’s a kind of exploratory reverie I had with Claude, which gives the appearance of being comparatively low in confabulation and sycophancy - to help reflect on the documentary:</p>
<hr>
<blockquote class="blockquote">
<p>What do protein folding problems entail? Why has this historically been such a challenge? What are the possible acceleration in scientific advances that should result over the next 1-10 years from Alpha’s work in this area?</p>
</blockquote>
<section id="the-protein-folding-problem" class="level1">
<h1><strong>The Protein Folding Problem</strong></h1>
<p>Protein folding is one of biology’s most fundamental puzzles: predicting how a protein’s amino acid sequence determines its three-dimensional structure. This matters because a protein’s shape dictates its function—enzymes, antibodies, structural components, and virtually every biological process depends on proteins adopting the correct 3D configuration.</p>
<section id="what-the-problem-entails" class="level2">
<h2 class="anchored" data-anchor-id="what-the-problem-entails"><strong>What the Problem Entails</strong></h2>
<p>The challenge has several layers:</p>
<p><strong>The fundamental question</strong>: Given a linear sequence of amino acids (the primary structure), can we predict how it will fold into its final 3D shape (tertiary structure)? Proteins can fold into incredibly complex configurations with helices, sheets, loops, and intricate binding sites.</p>
<p><strong>The astronomical complexity</strong>: A typical protein might have 100-300 amino acids. Even if each amino acid could adopt just 3 conformations, that’s 3^100 possible structures—more than the number of atoms in the universe. Yet proteins fold correctly in milliseconds to seconds inside cells.</p>
<p><strong>The physics</strong>: Folding is driven by countless weak interactions—hydrogen bonds, hydrophobic effects, electrostatic forces, van der Waals interactions. Simulating all these forces accurately requires immense computational power, and even then, the timescales involved (microseconds to seconds) were beyond reach for most proteins.</p>
</section>
<section id="why-its-been-so-hard" class="level2">
<h2 class="anchored" data-anchor-id="why-its-been-so-hard"><strong>Why It’s Been So Hard</strong></h2>
<p>For decades, scientists faced multiple obstacles:</p>
<p><strong>Experimental methods are slow and expensive</strong>: Determining protein structures through X-ray crystallography or cryo-electron microscopy takes months to years and doesn’t work for all proteins. Many important proteins (like membrane proteins) are extremely difficult to crystallize.</p>
<p><strong>Computational approaches struggled</strong>: Traditional molecular dynamics simulations could model only microseconds of folding for small proteins. Ab initio prediction methods that tried to calculate structures from first principles were computationally intractable.</p>
<p><strong>The gap between sequence and structure</strong>: By 2020, we knew sequences for hundreds of millions of proteins but had experimental structures for only about 170,000. This enormous gap limited our understanding of biology and medicine.</p>
</section>
<section id="alphafolds-breakthrough-and-future-impact" class="level2">
<h2 class="anchored" data-anchor-id="alphafolds-breakthrough-and-future-impact"><strong>AlphaFold’s Breakthrough and Future Impact</strong></h2>
<p>AlphaFold2 (2020) and AlphaFold3 (2024) have revolutionized this field by using deep learning to predict structures with near-experimental accuracy. Here’s what this enables over the next 1-10 years:</p>
<p><strong>Drug discovery acceleration</strong>: Understanding protein structures allows pharmaceutical companies to design drugs that fit precisely into binding sites. This could compress drug development timelines from 10-15 years to potentially 5-7 years for some targets, and open up “undruggable” targets that were previously too difficult to work with.</p>
<p><strong>Understanding disease mechanisms</strong>: Many diseases involve misfolded proteins (Alzheimer’s, Parkinson’s, cystic fibrosis). Predicting how mutations affect folding helps us understand pathology and design therapies. We’re already seeing this with personalized medicine approaches.</p>
<p><strong>Enzyme engineering</strong>: Researchers can now design novel enzymes for industrial processes—breaking down plastics, producing biofuels, synthesizing chemicals more sustainably. What once required years of trial-and-error can now be guided by structural predictions.</p>
<p><strong>Synthetic biology</strong>: Designing new proteins from scratch becomes feasible. Scientists are creating novel proteins for carbon capture, biosensors, and new materials. This could lead to programmable biological systems.</p>
<p><strong>Antibody design</strong>: Faster development of therapeutic antibodies and vaccines. Understanding antibody-antigen interactions at atomic resolution accelerates development of treatments for cancer, autoimmune diseases, and infectious diseases.</p>
<p><strong>Basic research acceleration</strong>: Biologists can now generate hypotheses about protein function instantly rather than waiting months for experimental structures. This fundamentally speeds up the research cycle across molecular biology, genetics, and biochemistry.</p>
<p><strong>Structural proteomics</strong>: AlphaFold has already predicted structures for over 200 million proteins—essentially all known proteins. This creates a comprehensive map of the protein universe, revealing evolutionary relationships and functional patterns never before visible.</p>
<p>The most profound impact may be how this changes the nature of biological research itself. Structure prediction becomes a routine computational step rather than a bottleneck, allowing scientists to ask bigger questions and test more hypotheses. Combined with other AI advances in protein design, gene editing, and systems biology, we’re entering an era where biology becomes more predictable and engineering-driven—potentially as transformative as the transition from alchemy to modern chemistry.</p>
<blockquote class="blockquote">
<p>When discussing ‘sites’/‘targets’, is the lock-and-key analogy appropriate, with the challenge being that given the amino acid sequence alone neither the lock nor key structure was previously known?</p>
</blockquote>
<p>Yes, the lock-and-key analogy is quite appropriate and captures the essence of the challenge beautifully!</p>
</section>
<section id="the-lock-and-key-model" class="level2">
<h2 class="anchored" data-anchor-id="the-lock-and-key-model"><strong>The Lock-and-Key Model</strong></h2>
<p>The analogy works well for understanding molecular recognition. Proteins often have specific binding sites (the “lock”) where other molecules—drugs, substrates, other proteins, DNA, etc. (the “key”)—fit with high specificity. The shape complementarity, along with chemical properties like charge distribution and hydrophobicity, determines whether binding occurs and how strong it is.</p>
</section>
<section id="the-double-blind-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-double-blind-problem"><strong>The Double-Blind Problem</strong></h2>
<p>Your insight about the double challenge is exactly right. Historically, drug designers faced a frustrating situation:</p>
<p><strong>Without knowing the lock’s shape</strong>, you couldn’t rationally design a key. You’d have to try thousands or millions of chemical compounds hoping something would fit—essentially trying random keys in a lock you couldn’t see. This “high-throughput screening” approach is expensive, time-consuming, and often misses good candidates.</p>
<p><strong>Even when you had a target sequence</strong>, you didn’t know what 3D structure it would adopt, so you couldn’t predict where the binding site would be, what shape it would have, or which chemical properties would matter for binding.</p>
<p>It’s like being asked to design a key for a lock when all you have is the manufacturing instruction manual written in code, with no picture of the actual lock.</p>
</section>
<section id="how-alphafold-changes-the-game" class="level2">
<h2 class="anchored" data-anchor-id="how-alphafold-changes-the-game"><strong>How AlphaFold Changes the Game</strong></h2>
<p>Now with structure prediction, researchers can:</p>
<ul>
<li><p>See the lock’s shape from the amino acid sequence alone</p></li>
<li><p>Identify binding pockets and cavities computationally</p></li>
<li><p>Understand which amino acids line the binding site</p></li>
<li><p>Design molecules that complement that specific geometry</p></li>
</ul>
<p>This transforms drug discovery from a “blind search” into a “rational design” problem.</p>
</section>
<section id="refining-the-analogy" class="level2">
<h2 class="anchored" data-anchor-id="refining-the-analogy"><strong>Refining the Analogy</strong></h2>
<p>That said, the lock-and-key metaphor has some limitations worth noting:</p>
<p><strong>Induced fit</strong>: Proteins aren’t rigid locks. They’re often flexible and change shape when the key binds—more like a glove conforming to a hand than a rigid lock. This dynamic behavior adds complexity that AlphaFold is increasingly capturing.</p>
<p><strong>Multiple conformations</strong>: Proteins can adopt different shapes (conformational states), essentially changing the lock’s shape depending on conditions. Some proteins have “open” and “closed” states, or undergo large structural rearrangements.</p>
<p><strong>Allosteric sites</strong>: Sometimes the best “lock” isn’t the active site at all, but a distant site that, when bound, changes the protein’s shape or function. These regulatory mechanisms add another layer of sophistication.</p>
<p>But fundamentally, yes—you’ve captured the core problem perfectly. AlphaFold reveals the lock’s structure from its genetic blueprint, making rational key design possible for the first time at scale.</p>
<blockquote class="blockquote">
<p>Given the suggested decline in drug development from 10-15 to 5-7 years, what are the remaining steps that take the 4-6 years?</p>
</blockquote>
<p>Great question! Even with perfect structural knowledge, drug development remains a lengthy, complex process. Here’s what fills those remaining 5-7 years:</p>
</section>
<section id="the-remaining-timeline" class="level2">
<h2 class="anchored" data-anchor-id="the-remaining-timeline"><strong>The Remaining Timeline</strong></h2>
<p><strong>Lead Optimization (1-2 years)</strong> Even after identifying a molecule that fits the binding site, you need to optimize it. The initial “hit” might bind well but have terrible properties:</p>
<ul>
<li><p>Poor solubility (can’t dissolve in blood)</p></li>
<li><p>Rapid metabolism (body breaks it down too quickly)</p></li>
<li><p>Toxicity to human cells</p></li>
<li><p>Inability to cross cell membranes or reach the target tissue</p></li>
<li><p>Off-target effects (binds to unintended proteins)</p></li>
</ul>
<p>Medicinal chemists iterate through hundreds of variants, tweaking the structure to improve these properties while maintaining binding affinity. Structure prediction helps but doesn’t solve pharmacokinetics (how the drug moves through the body) or toxicity.</p>
<p><strong>Preclinical Testing (1-2 years)</strong> Before human trials, extensive animal studies are required:</p>
<ul>
<li><p>Toxicology studies in multiple species</p></li>
<li><p>Pharmacokinetics (absorption, distribution, metabolism, excretion)</p></li>
<li><p>Safety profiling at various doses</p></li>
<li><p>Efficacy testing in disease models</p></li>
<li><p>Manufacturing process development</p></li>
</ul>
<p>These can’t be fully simulated—you must observe actual biological responses in living systems.</p>
<p><strong>Phase I Clinical Trials (1-2 years)</strong> First tests in humans, usually 20-100 healthy volunteers:</p>
<ul>
<li><p>Is it safe at various doses?</p></li>
<li><p>How does the human body process it?</p></li>
<li><p>What are the side effects?</p></li>
<li><p>What’s the maximum tolerated dose?</p></li>
</ul>
<p>About 70% of drugs fail here despite looking promising in animals.</p>
<p><strong>Phase II Clinical Trials (1-2 years)</strong> Testing in 100-300 patients who actually have the disease:</p>
<ul>
<li><p>Does it work in humans?</p></li>
<li><p>What’s the optimal dose?</p></li>
<li><p>What are the side effects in sick patients?</p></li>
<li><p>Early efficacy signals</p></li>
</ul>
<p>About 33% of drugs that passed Phase I fail here.</p>
<p><strong>Phase III Clinical Trials (2-4 years)</strong> Large-scale trials with 300-3,000+ patients:</p>
<ul>
<li><p>Definitively prove efficacy compared to standard treatment or placebo</p></li>
<li><p>Comprehensive safety data across diverse populations</p></li>
<li><p>Long-term effects</p></li>
<li><p>Statistical proof of benefit</p></li>
</ul>
<p>This is the most expensive phase—often costing hundreds of millions. Only about 25-50% of drugs entering Phase III get approved.</p>
<p><strong>Regulatory Review (1-2 years)</strong> Submitting data to FDA/EMA and waiting for approval:</p>
<ul>
<li><p>Reviewing thousands of pages of data</p></li>
<li><p>Addressing regulatory questions</p></li>
<li><p>Inspecting manufacturing facilities</p></li>
<li><p>Risk-benefit analysis</p></li>
</ul>
</section>
<section id="why-these-steps-cant-be-dramatically-shortened" class="level2">
<h2 class="anchored" data-anchor-id="why-these-steps-cant-be-dramatically-shortened"><strong>Why These Steps Can’t Be Dramatically Shortened</strong></h2>
<p><strong>Biological complexity</strong>: AlphaFold tells you the lock’s shape, but not:</p>
<ul>
<li><p>Whether blocking/activating that protein actually treats the disease in humans</p></li>
<li><p>How the drug affects other proteins and pathways (systems-level effects)</p></li>
<li><p>Individual patient variability in response</p></li>
<li><p>Long-term consequences</p></li>
</ul>
<p><strong>Safety requirements</strong>: You can’t simulate whether a drug causes liver damage, heart problems, or cancer over time. This requires observing actual patients for months or years.</p>
<p><strong>Statistical rigor</strong>: Clinical trials need sufficient patient numbers and follow-up time to prove the drug works and is safe. A drug might show early promise but fail in larger populations or reveal rare but serious side effects.</p>
<p><strong>Manufacturing scale-up</strong>: Making grams in a lab differs vastly from producing tons reliably and consistently. This process development happens in parallel but takes years.</p>
<p><strong>Regulatory conservatism</strong>: After disasters like thalidomide, regulators rightfully demand extensive proof. The bar is high, and shortcuts have catastrophic consequences.</p>
</section>
<section id="where-ai-might-further-accelerate-things" class="level2">
<h2 class="anchored" data-anchor-id="where-ai-might-further-accelerate-things"><strong>Where AI Might Further Accelerate Things</strong></h2>
<p>Beyond structure prediction, AI could potentially compress timelines by:</p>
<ul>
<li><p>Predicting toxicity and drug properties computationally (reducing trial-and-error in optimization)</p></li>
<li><p>Identifying biomarkers for patient selection (making trials more efficient)</p></li>
<li><p>Optimizing trial design and patient recruitment</p></li>
<li><p>Predicting drug-drug interactions and side effects</p></li>
</ul>
<p>But the irreducible core—proving safety and efficacy in actual human beings over time—remains. Biology is messy, patients are variable, and rare side effects only emerge in large populations.</p>
<p>That said, going from 10-15 years to 5-7 years would be transformative. It means patients get treatments roughly twice as fast, development costs drop significantly (making more “niche” drugs economically viable), and pharmaceutical companies can tackle more targets with the same resources. The impact compounds across the entire healthcare ecosystem.</p>
<blockquote class="blockquote">
<p>Given this, should we expect pharmaceutical companies to grow in value faster than over the last 20-30 years?</p>
</blockquote>
<p>This is a fascinating question that cuts to the heart of whether scientific breakthroughs translate into investment returns. The answer is nuanced and probably <strong>not as straightforward as you might expect</strong>.</p>
</section>
<section id="arguments-for-faster-growth" class="level2">
<h2 class="anchored" data-anchor-id="arguments-for-faster-growth"><strong>Arguments for Faster Growth</strong></h2>
<p><strong>Improved R&amp;D productivity</strong>: The pharmaceutical industry has suffered from declining R&amp;D efficiency for decades—“Eroom’s Law” (Moore’s Law backwards). Despite spending more on R&amp;D, fewer drugs were approved per billion dollars spent. If AlphaFold and related AI tools reverse this trend, companies could get more successful drugs from the same investment.</p>
<p><strong>Expanded druggable targets</strong>: Many disease-causing proteins were previously “undruggable” because we couldn’t understand their structure well enough to design inhibitors. Suddenly having access to 200+ million protein structures could open entirely new therapeutic areas—particularly in rare diseases and precision medicine.</p>
<p><strong>Faster time-to-market</strong>: Getting drugs approved in 5-7 years instead of 10-15 years means:</p>
<ul>
<li><p>Earlier revenue generation</p></li>
<li><p>Longer effective patent life (more years of exclusivity)</p></li>
<li><p>Lower cost of capital (less money tied up for shorter periods)</p></li>
<li><p>Ability to pursue more projects simultaneously</p></li>
</ul>
<p><strong>Better capital allocation</strong>: Companies can computationally filter out likely failures earlier, concentrating resources on more promising candidates.</p>
</section>
<section id="arguments-against-faster-growth-or-why-it-might-not-matter-as-much" class="level2">
<h2 class="anchored" data-anchor-id="arguments-against-faster-growth-or-why-it-might-not-matter-as-much"><strong>Arguments Against Faster Growth (or Why It Might Not Matter as Much)</strong></h2>
<p><strong>Competition intensifies equally</strong>: Every pharma company gets access to the same tools. If everyone becomes more efficient simultaneously, the competitive advantage disappears. This could lead to:</p>
<ul>
<li><p>More drugs reaching market (supply increase)</p></li>
<li><p>Increased pricing pressure as multiple companies target the same diseases</p></li>
<li><p>Faster erosion of market share as competitors develop alternatives more quickly</p></li>
</ul>
<p><strong>Value accrues elsewhere</strong>: The companies capturing value might not be traditional pharma:</p>
<ul>
<li><p>AI biotech startups using these tools</p></li>
<li><p>Tech companies (Google/DeepMind, etc.) that own the platforms</p></li>
<li><p>Contract research organizations (CROs) that offer AI-enabled services</p></li>
<li><p>Generic manufacturers who can more quickly develop biosimilars</p></li>
</ul>
<p><strong>Regulatory and pricing pressure</strong>: Governments and insurers are increasingly aggressive about drug pricing. Even if companies develop drugs faster and cheaper, they may not be able to charge proportionally more. In fact, regulators might argue that lower development costs should mean lower prices.</p>
<p><strong>The clinical trial bottleneck remains</strong>: As we discussed, 5-7 years of the timeline can’t be compressed much. So while early-stage productivity improves dramatically, the rate-limiting step (human trials) doesn’t change proportionally. The benefit is real but perhaps more incremental than revolutionary.</p>
<p><strong>Market saturation</strong>: Many “easy” and lucrative targets (common diseases in wealthy populations) already have treatments. New drugs increasingly target:</p>
<ul>
<li><p>Rare diseases (smaller markets)</p></li>
<li><p>Precision medicine (fragmented patient populations)</p></li>
<li><p>Diseases more common in lower-income countries (pricing challenges)</p></li>
</ul>
<p><strong>The innovation paradox</strong>: As medicine advances, we’re left with harder problems. The remaining diseases are often more complex, multifactorial, or involve targets that are difficult to modulate without side effects.</p>
</section>
<section id="historical-context-the-last-20-30-years" class="level2">
<h2 class="anchored" data-anchor-id="historical-context-the-last-20-30-years"><strong>Historical Context: The Last 20-30 Years</strong></h2>
<p>Looking backward provides useful perspective:</p>
<p><strong>Pharmaceutical stocks have grown, but inconsistently</strong>: Large-cap pharma has roughly tracked or slightly outperformed the broader market over 20-30 years, but with high volatility tied to patent cliffs, pipeline failures, and blockbuster approvals. Biotech has been more variable—spectacular winners but many complete failures.</p>
<p><strong>The industry has consolidated</strong>: Much of the “growth” came through mergers and acquisitions rather than organic innovation, suggesting structural challenges in R&amp;D productivity.</p>
<p><strong>Previous technological revolutions had mixed impacts</strong>:</p>
<ul>
<li><p>Genomics (Human Genome Project, 2003) was supposed to revolutionize drug discovery. Results have been real but slower than expected.</p></li>
<li><p>High-throughput screening, combinatorial chemistry, and other tools improved efficiency but didn’t fundamentally change growth trajectories.</p></li>
<li><p>Monoclonal antibodies and biologics created huge value, but much of it accrued to a few companies with platform advantages.</p></li>
</ul>
</section>
<section id="the-realistic-scenario" class="level2">
<h2 class="anchored" data-anchor-id="the-realistic-scenario"><strong>The Realistic Scenario</strong></h2>
<p>My best guess is <strong>moderate acceleration rather than explosive growth</strong>:</p>
<p><strong>Near-term (3-5 years)</strong>: Traditional pharma companies will see improved R&amp;D metrics—higher success rates, better target selection, reduced costs in early stages. Stock performance will likely improve modestly, but much of this may already be priced in by forward-looking investors.</p>
<p><strong>Medium-term (5-10 years)</strong>: We’ll see the first wave of “AI-designed” drugs reaching market. Winners will be companies that:</p>
<ul>
<li><p>Integrated AI tools most effectively into their workflows</p></li>
<li><p>Combined computational power with deep biological/clinical expertise</p></li>
<li><p>Maintained or built strong data assets (patient data, trial results, etc.)</p></li>
<li><p>Adapted organizational culture to new ways of working</p></li>
</ul>
<p>This could create differentiated returns—some companies pull ahead while others lag.</p>
<p><strong>Long-term questions</strong>:</p>
<ul>
<li><p>Does value concentrate (a few winners dominate) or fragment (many specialized players)?</p></li>
<li><p>Do tech companies enter pharma directly or just sell tools?</p></li>
<li><p>How do regulatory frameworks and pricing policies adapt?</p></li>
<li><p>Does AI-enabled drug development become commoditized (eliminating competitive advantage)?</p></li>
</ul>
</section>
<section id="the-contrarian-take" class="level2">
<h2 class="anchored" data-anchor-id="the-contrarian-take"><strong>The Contrarian Take</strong></h2>
<p>There’s a scenario where pharmaceutical <em>stock returns</em> don’t improve much despite massive scientific progress:</p>
<p>If development becomes much cheaper and faster, <strong>barriers to entry fall</strong>. More companies can afford to develop drugs. Competition increases. Pricing power decreases. The consumer/patient wins (more treatments, lower costs), but shareholders don’t necessarily benefit proportionally. The economic surplus gets distributed to patients and healthcare systems rather than captured by pharma companies.</p>
<p>This has precedent—many technological revolutions (personal computers, solar panels, LED lighting) delivered enormous societal value but became commoditized industries with modest profit margins.</p>
</section>
<section id="bottom-line" class="level2">
<h2 class="anchored" data-anchor-id="bottom-line"><strong>Bottom Line</strong></h2>
<p>Scientific progress doesn’t automatically translate to outsized stock returns. The key questions are:</p>
<ul>
<li><p>Can individual companies create sustainable competitive advantages?</p></li>
<li><p>How much of the value gets captured by pharma vs.&nbsp;distributed to other stakeholders?</p></li>
<li><p>Does increased efficiency get competed away?</p></li>
</ul>
<p>I’d expect pharma to grow <strong>somewhat faster</strong> than the last 20-30 years—perhaps adding 1-3% annually to returns relative to historical performance—but not the explosive multiples you might expect from such a fundamental breakthrough. The biggest winners might be AI-native biotech companies and platforms rather than traditional pharma giants, though the latter have capital and infrastructure advantages for clinical development and commercialization.</p>
<p>The real beneficiaries will be patients and society through better treatments arriving faster and more diseases becoming treatable. Whether that translates to proportional shareholder returns remains genuinely uncertain.</p>
<blockquote class="blockquote">
<p>Are allosteric sites essentially upstream sites in terms of causal influence on downstream protein structure, or is a different mental model more suited to understanding this?</p>
</blockquote>
<p>The “upstream causal influence” framing is partially correct but misses some key aspects. Let me offer a more nuanced mental model.</p>
</section>
<section id="why-upstream-works-sort-of" class="level2">
<h2 class="anchored" data-anchor-id="why-upstream-works-sort-of"><strong>Why “Upstream” Works (Sort Of)</strong></h2>
<p>Allosteric sites do exert causal influence on function, and there is a sense of information flow:</p>
<ul>
<li><p>Ligand binds to allosteric site → conformational change propagates → active site changes shape/activity</p></li>
<li><p>This creates a regulatory pathway: the allosteric site acts as a control knob</p></li>
</ul>
<p>So yes, in terms of signal transduction and regulatory logic, “upstream” captures something real.</p>
</section>
<section id="why-upstream-is-misleading" class="level2">
<h2 class="anchored" data-anchor-id="why-upstream-is-misleading"><strong>Why “Upstream” Is Misleading</strong></h2>
<p><strong>It’s not strictly hierarchical</strong>: The relationship isn’t like a linear pathway where A causes B causes C. Instead, it’s more like a <strong>mechanical coupling</strong> or <strong>network of interactions</strong>. Think of it less like a signal cascade and more like:</p>
<ul>
<li><p><strong>A network of springs and struts</strong>: When you pull on one part of an interconnected structure, the strain propagates throughout, causing distant parts to shift position. The allosteric site doesn’t “send a signal” so much as it perturbs the entire mechanical/energetic landscape.</p></li>
<li><p><strong>Energetic redistribution</strong>: Proteins exist in multiple conformational states, constantly fluctuating. The allosteric ligand doesn’t create new structures—it <em>shifts the equilibrium</em> between pre-existing conformations. It stabilizes certain states and destabilizes others, changing the probability distribution of shapes the protein adopts.</p></li>
</ul>
</section>
<section id="better-mental-models" class="level2">
<h2 class="anchored" data-anchor-id="better-mental-models"><strong>Better Mental Models</strong></h2>
<p><strong>Conformational ensemble</strong>: Proteins aren’t static structures but dynamic populations. Imagine the protein as existing in multiple shapes simultaneously (like a quantum superposition, though the mechanism is classical):</p>
<ul>
<li><p>State A: 70% of molecules, active site “open”</p></li>
<li><p>State B: 30% of molecules, active site “closed”</p></li>
</ul>
<p>An allosteric ligand binding might shift this to:</p>
<ul>
<li><p>State A: 20% (now disfavored)</p></li>
<li><p>State B: 80% (now favored)</p></li>
</ul>
<p>The allosteric site doesn’t cause the closed state—it already existed—but it changes which state predominates.</p>
<p><strong>Mechanical linkage</strong>: Think of proteins like intricate origami or mechanical linkages where:</p>
<ul>
<li><p>Different domains are connected by flexible hinges and rigid segments</p></li>
<li><p>Binding at one site constrains certain degrees of freedom</p></li>
<li><p>This constraint propagates through the structure via physical connections</p></li>
<li><p>Distant regions adjust to accommodate the new constraints</p></li>
</ul>
<p>For example, many enzymes have domains connected by hinge regions. When an allosteric regulator binds, it might lock a hinge in place, forcing other domains to adopt specific relative orientations.</p>
<p><strong>Energy landscapes</strong>: Proteins navigate a rugged energy landscape with multiple valleys (stable conformations) separated by hills (energy barriers). The allosteric ligand:</p>
<ul>
<li><p>Deepens some valleys (stabilizes certain conformations)</p></li>
<li><p>Raises others (destabilizes alternative conformations)</p></li>
<li><p>Changes the relative heights of barriers between states</p></li>
</ul>
<p>This shifts the protein’s exploration of conformational space without creating entirely new structures.</p>
</section>
<section id="spatial-relationships-matter-but-not-simply" class="level2">
<h2 class="anchored" data-anchor-id="spatial-relationships-matter-but-not-simply"><strong>Spatial Relationships Matter, But Not Simply</strong></h2>
<p><strong>“Upstream” implies linear directionality</strong>, but allosteric effects can be:</p>
<ul>
<li><p><strong>Reciprocal</strong>: The active site’s state can also influence the allosteric site. It’s bidirectional coupling, not unidirectional causation.</p></li>
<li><p><strong>Distance-independent in surprising ways</strong>: Sometimes allosteric sites are far from the active site (classic allostery), but sometimes they’re quite close—just positioned so that binding causes a localized distortion that propagates. Conversely, distant sites might have weak effects if they’re not mechanically coupled through the protein’s architecture.</p></li>
<li><p><strong>Pathway-dependent</strong>: The conformational change might propagate through specific structural elements (alpha helices, beta sheets, loop regions) that act as “wires” transmitting strain. Different allosteric sites might use different pathways to influence the same active site.</p></li>
</ul>
</section>
<section id="examples-that-clarify-the-model" class="level2">
<h2 class="anchored" data-anchor-id="examples-that-clarify-the-model"><strong>Examples That Clarify the Model</strong></h2>
<p><strong>Hemoglobin</strong> (classic example):</p>
<ul>
<li><p>Four subunits arranged symmetrically</p></li>
<li><p>Oxygen binding to one subunit makes it easier for others to bind</p></li>
<li><p>Not “upstream/downstream” but rather <strong>cooperative coupling</strong>—binding at one site physically strains the interfaces between subunits, making the others more receptive</p></li>
</ul>
<p><strong>Kinases</strong> (signaling enzymes):</p>
<ul>
<li><p>Often have activation loops that block the active site</p></li>
<li><p>Phosphorylation at an allosteric site causes the loop to swing away</p></li>
<li><p>This is mechanical: the added negative charge creates electrostatic repulsion that destabilizes the “closed” conformation</p></li>
</ul>
<p><strong>G-protein coupled receptors</strong> (GPCRs):</p>
<ul>
<li><p>Have distinct “inactive” and “active” conformations</p></li>
<li><p>Agonist binding at one site stabilizes the active state</p></li>
<li><p>Inverse agonists stabilize the inactive state</p></li>
<li><p>The binding site itself is arguably both the “active site” and “allosteric site”—these categories blur</p></li>
</ul>
</section>
<section id="implications-for-drug-design" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-drug-design"><strong>Implications for Drug Design</strong></h2>
<p>Understanding allostery as energetic/mechanical coupling rather than simple causal hierarchy matters because:</p>
<p><strong>You can target multiple states</strong>: If you understand the conformational ensemble, you can design drugs that:</p>
<ul>
<li><p>Stabilize inactive conformations (inverse agonists)</p></li>
<li><p>Stabilize active conformations (agonists)</p></li>
<li><p>Lock the protein in intermediate states</p></li>
<li><p>Prevent conformational transitions altogether</p></li>
</ul>
<p><strong>You can predict effects more accurately</strong>: AlphaFold and molecular dynamics simulations can now model:</p>
<ul>
<li><p>How binding at one site changes the energy landscape</p></li>
<li><p>Which pathways transmit conformational changes</p></li>
<li><p>Whether an allosteric effect will be activating or inhibiting</p></li>
</ul>
<p><strong>You can find better drug sites</strong>: Allosteric sites often have advantages:</p>
<ul>
<li><p>Less conserved across protein families (more selective)</p></li>
<li><p>Less critical for function (mutations less likely to cause resistance)</p></li>
<li><p>Can fine-tune activity rather than completely blocking it</p></li>
</ul>
</section>
<section id="so-whats-the-right-mental-model" class="level2">
<h2 class="anchored" data-anchor-id="so-whats-the-right-mental-model"><strong>So, What’s the Right Mental Model?</strong></h2>
<p>I’d suggest thinking of allosteric regulation as <strong>mechanical-energetic coupling within a dynamic conformational ensemble</strong> rather than upstream/downstream causation. The protein is:</p>
<ul>
<li><p>A flexible structure exploring conformational space</p></li>
<li><p>Mechanically coupled across its domains</p></li>
<li><p>Constantly shifting between related shapes</p></li>
<li><p>Stabilized in particular conformations by ligands that change the energy landscape</p></li>
</ul>
<p>The allosteric site doesn’t “control” the active site in a hierarchical sense—rather, they’re parts of an interconnected system where perturbations in one region necessarily affect the stability and dynamics of other regions.</p>
<p>This model better captures the reciprocal nature, the role of protein dynamics, and why drugs targeting allosteric sites can have such diverse effects (activation, inhibition, modulation) depending on exactly how they reshape the conformational landscape.</p>
<blockquote class="blockquote">
<p>Considering the famous science video powers of ten, is the sense of awe associated with complex revealed structure at different scales more likely to be induced through consideration of micro scales (such as those at which protein structures are apparent) or macro scales such as those that are the focus of cosmology?</p>
</blockquote>
<p>What a beautiful question—it strikes at the heart of how scale shapes wonder. My intuition is that <strong>microscales may increasingly rival or even surpass macroscales</strong> in their capacity to induce awe, though the <em>type</em> of awe differs in important ways.</p>
</section>
<section id="the-traditional-dominance-of-cosmic-awe" class="level2">
<h2 class="anchored" data-anchor-id="the-traditional-dominance-of-cosmic-awe"><strong>The Traditional Dominance of Cosmic Awe</strong></h2>
<p>Historically, the macro has dominated our sense of sublime wonder:</p>
<ul>
<li><p>The “pale blue dot” photograph</p></li>
<li><p>Galaxies stretching across billions of light-years</p></li>
<li><p>The observable universe containing ~2 trillion galaxies</p></li>
<li><p>Deep time—13.8 billion years of cosmic history</p></li>
</ul>
<p>This cosmic awe taps into something primal: our smallness against vastness, our insignificance within immensity. Pascal captured it: “The eternal silence of these infinite spaces frightens me.” There’s an almost spiritual quality to confronting scales that dwarf human comprehension.</p>
<p><strong>Why macro-awe works so effectively:</strong></p>
<ul>
<li><p><strong>Visual immediacy</strong>: Space imagery is spectacular—Hubble photos, the Milky Way arcing overhead, total solar eclipses</p></li>
<li><p><strong>Narrative simplicity</strong>: “Billions of galaxies” is conceptually graspable even if the numbers are incomprehensible</p></li>
<li><p><strong>Existential resonance</strong>: It naturally triggers questions about meaning, purpose, our place in existence</p></li>
<li><p><strong>Cultural embedding</strong>: Cosmic wonder is deeply embedded in human culture—religion, philosophy, art, science fiction</p></li>
</ul>
</section>
<section id="the-emerging-power-of-microscopic-awe" class="level2">
<h2 class="anchored" data-anchor-id="the-emerging-power-of-microscopic-awe"><strong>The Emerging Power of Microscopic Awe</strong></h2>
<p>But something has shifted in recent decades. The molecular and quantum scales are becoming increasingly <strong>visceral and imaginatively accessible</strong> in ways they never were before:</p>
<p><strong>Visualization breakthroughs</strong>: We can now <em>see</em> atoms, proteins, viruses, and cellular machinery:</p>
<ul>
<li><p>Cryo-EM structures showing molecular machines in exquisite detail</p></li>
<li><p>AlphaFold’s entire protein structure database</p></li>
<li><p>Real-time videos of molecular motors “walking” along cellular filaments</p></li>
<li><p>Quantum microscopy revealing electron clouds</p></li>
</ul>
<p>These aren’t artist’s conceptions—they’re data-driven reconstructions showing actual structure and dynamics.</p>
<p><strong>Functional complexity</strong>: The micro reveals not just structure but <strong>purposeful intricacy</strong>:</p>
<ul>
<li><p>Ribosomes as molecular 3D printers</p></li>
<li><p>ATP synthase as a rotary motor</p></li>
<li><p>DNA repair mechanisms that proofread and correct errors</p></li>
<li><p>Immune receptors with millions of variants</p></li>
<li><p>Enzymatic cascades with feedback loops</p></li>
</ul>
<p>This isn’t random complexity—it’s <strong>engineered</strong> complexity (by evolution, but the effect on our intuitions is similar). We recognize problem-solving, information processing, error correction. It feels designed, intentional, purposeful.</p>
<p><strong>Personal stakes</strong>: The micro is literally <em>us</em>:</p>
<ul>
<li><p>These proteins are in your body right now, performing functions that keep you alive</p></li>
<li><p>Mutations in these structures cause diseases affecting people you know</p></li>
<li><p>Understanding them leads to treatments, cures, interventions</p></li>
<li><p>You are, in a very real sense, a vast colony of molecular machines</p></li>
</ul>
<p>There’s an intimacy to microscopic awe that cosmic wonder can’t match. The universe is indifferent to us; our proteins are <em>constitutive</em> of us.</p>
</section>
<section id="different-flavors-of-awe" class="level2">
<h2 class="anchored" data-anchor-id="different-flavors-of-awe"><strong>Different Flavors of Awe</strong></h2>
<p>The two scales evoke qualitatively different experiences:</p>
<p><strong>Cosmic awe</strong>:</p>
<ul>
<li><p>Characterized by smallness, insignificance, humility</p></li>
<li><p>“We are nothing; the universe is everything”</p></li>
<li><p>Often melancholic or anxiety-inducing</p></li>
<li><p>Emphasizes <em>simplicity</em> at cosmic scales (physics reduces to elegant laws)</p></li>
<li><p>Distance and alienness—we can never visit those places</p></li>
</ul>
<p><strong>Molecular awe</strong>:</p>
<ul>
<li><p>Characterized by intricacy, sophistication, marvel at engineering</p></li>
<li><p>“We are everything; look at the complexity required to exist”</p></li>
<li><p>Often exhilarating or empowering</p></li>
<li><p>Emphasizes <em>complexity</em> and functional organization</p></li>
<li><p>Intimacy—this is happening inside you right now</p></li>
</ul>
<p>I’d argue the molecular realm offers something the cosmic doesn’t: <strong>comprehensible complexity</strong>. The cosmic is vast but relatively simple (gravity, nuclear forces, expansion). The molecular is dense with <em>meaning</em>—information encoded, decoded, processed, acted upon.</p>
</section>
<section id="why-micro-awe-may-be-ascendant" class="level2">
<h2 class="anchored" data-anchor-id="why-micro-awe-may-be-ascendant"><strong>Why Micro-Awe May Be Ascendant</strong></h2>
<p>Several factors suggest microscopic wonder is gaining ground:</p>
<p><strong>Accessibility</strong>: You can explore protein structures on your laptop. You can’t meaningfully explore distant galaxies. The democratization of molecular visualization tools makes this accessible to billions of people in ways cosmology cannot match.</p>
<p><strong>Actionability</strong>: Understanding proteins leads to tangible outcomes—medicines, treatments, biotechnology. This creates a positive feedback loop: interest → understanding → application → renewed interest. Cosmology, for all its grandeur, rarely affects daily life.</p>
<p><strong>Educational emphasis</strong>: Biology education increasingly focuses on molecular mechanisms. Children grow up seeing animations of molecular machines. This cultivates intuitions about the micro that previous generations lacked.</p>
<p><strong>Technological mediation</strong>: We’re getting better at making the molecular world <em>feel real</em>:</p>
<ul>
<li><p>VR experiences of molecular environments</p></li>
<li><p>Interactive protein folding games (Foldit)</p></li>
<li><p>Real-time visualizations of cellular processes</p></li>
<li><p>Even art and design inspired by molecular structures</p></li>
</ul>
<p><strong>The complexity gradient</strong>: We may be reaching the limits of cosmic surprise. We’ve mapped the observable universe’s large-scale structure. Discoveries continue, but the basic picture is established.</p>
<p>By contrast, molecular biology feels <strong>pre-paradigmatic</strong> in comparison—we’re still discovering fundamental organizing principles. The complexity seems bottomless. Every protein structure reveals new ingenuity. Every pathway connects to others in unexpected ways.</p>
</section>
<section id="a-personal-anecdote-tells-the-story" class="level2">
<h2 class="anchored" data-anchor-id="a-personal-anecdote-tells-the-story"><strong>A Personal Anecdote Tells the Story</strong></h2>
<p>Carl Sagan’s <em>Cosmos</em> inspired a generation with cosmic wonder. But today’s equivalent might be David Goodsell’s molecular illustrations or the stunning cryo-EM structures winning Nobel Prizes. When AlphaFold2 was announced, I saw scientists literally weeping—not because of the cosmic implications, but because the molecular world had suddenly opened up.</p>
<p>I suspect if you showed someone:</p>
<ol type="1">
<li><p>The Hubble Deep Field (thousands of galaxies)</p></li>
<li><p>A rotating 3D structure of ATP synthase with annotations showing how it generates cellular energy</p></li>
</ol>
<p>…many would find (2) more genuinely astonishing. Why? Because it combines visual beauty with functional comprehension with personal relevance. It’s not just structure—it’s a <strong>machine that makes sense</strong>, operating at a scale that’s alien yet intimate.</p>
</section>
<section id="the-synthesis-different-people-different-awe" class="level2">
<h2 class="anchored" data-anchor-id="the-synthesis-different-people-different-awe"><strong>The Synthesis: Different People, Different Awe</strong></h2>
<p>Ultimately, this may be personality-dependent:</p>
<p><strong>Cosmological temperaments</strong> are drawn to:</p>
<ul>
<li><p>Philosophical abstraction</p></li>
<li><p>Grandeur and vastness</p></li>
<li><p>Simplicity underlying complexity</p></li>
<li><p>Existential questions</p></li>
<li><p>The sublime and ineffable</p></li>
</ul>
<p><strong>Molecular temperaments</strong> are drawn to:</p>
<ul>
<li><p>Detailed mechanism</p></li>
<li><p>Functional elegance</p></li>
<li><p>Complexity serving purpose</p></li>
<li><p>Practical understanding</p></li>
<li><p>The intricate and intelligible</p></li>
</ul>
<p>But I’d wager that as molecular visualization improves, as education emphasizes these scales, and as biotechnology makes molecular understanding increasingly relevant, <strong>more people will find their deepest scientific awe in the micro rather than the macro</strong>.</p>
<p>The Powers of Ten journey is bidirectional, but we may discover that the inward journey—from human scale down to atoms—is ultimately richer in wonder than the outward journey to galaxies. Not because the cosmic is less magnificent, but because the molecular is both magnificent <em>and</em> meaningful in ways the cosmic cannot be.</p>
<p>We are, after all, not made of galaxies. We are made of proteins. And that may be the more profound truth.</p>


</section>
</section>

 ]]></description>
  <category>intelligence</category>
  <category>AI</category>
  <category>games</category>
  <category>protein-folding</category>
  <category>claudialectics</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/the-man-who-solved-intelligence/index.html</guid>
  <pubDate>Wed, 08 Oct 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Remembering KGB: 1992’s subtly terrifying social poison simulator</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/https:/upload.wikimedia.org/wikipedia/en/8/83/KGB-Box_Art.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">KGB Front Cover</figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>There was a computer ‘game’, released way back in 1992, that wasn’t really a game at all, but a <strong>social poison simulator</strong>. The game was called <a href="https://en.wikipedia.org/wiki/KGB_(video_game)">KGB</a>, and published by an appositely named company called Cryo. It was a terrifying, fascinating, possibly unique ‘game’, the likes of which I don’t think we’ll ever see again.</p>
</section>
<section id="when-computer-games-were-learning-about-themselves" class="level2">
<h2 class="anchored" data-anchor-id="when-computer-games-were-learning-about-themselves">When Computer Games were learning about themselves</h2>
<p>You see, back in the early 1990s, computer games, as a neophyte artform, were still trying to find out their grammar, best practice, standards and conventions that a history of experimentation already shown to have ‘worked’. Back in the 8 bit era of the 1980s even the basic mechanical conventions for inputting into games were still up for negotation: it took many years, for example, for the WASD keys to become the standard for specifying up-left-down-right on a standard keyboard. The increased power of 16 bit computers in the 1990s created a new set of dilemmas, conventions still to work out, simply because 16 bit computers were capable of doing many things that their 8 bit predecessors were not: they could <em>create and maintain complex simulations</em>, simplified, rule-bound, abstracted worlds, in which the player was foisted.</p>
</section>
<section id="games-just-one-component-of-games" class="level2">
<h2 class="anchored" data-anchor-id="games-just-one-component-of-games">Games: just one component of games</h2>
<p>Not all simulations are games, but the majority of games have elements of both theatricality and simulation. Theatricality includes everything from more-than-rudimentary graphics, through to sound design and story-telling. A game of sudoko could be rendered theatrical by, for example, telling a story about how solving the number sequence will unlock an antidote to a deadly poison. And like with pulp fiction, the same underlying game mechanics can be rendered sci-fi, fantasy or Western depending on the graphical stage dressing applied to the avatar and its obstacles.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/three-elements.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Three Elements of Computer Games</figcaption>
</figure>
</div>
</section>
<section id="simulation-in-games" class="level2">
<h2 class="anchored" data-anchor-id="simulation-in-games">Simulation in games</h2>
<p>Simulation emerges when there exist non-player agents in the game world whose behaviours are rule-bound in more than extremely simple ways. For example, a predator might exist in the game whose reaction to the player may depend on its level of hunger, and its level of hunger might itself depend on its interactions with other prey non-player agents whose behaviours are themselves rule-bound and determined by various competing motivations. As another example, a humanoid character may behave differently towards the player depending on the player’s behaviour towards other humanoid characters that the index character possesses either amity or emnity towards, or depending on the class of character the player elected as their avatar. Put simply, it is relatively simple, at least in theory, to simulate predator-prey dynamics, tribalism, and racism.</p>
</section>
<section id="the-fun-zone" class="level2">
<h2 class="anchored" data-anchor-id="the-fun-zone">The Fun Zone</h2>
<p>So to what extent is a good computer game one that is theatrically dressed, and exists in a rich simulation? Well, define ‘good’, and the kinds of feelings and experience one wishes to evoke in the player. Much of the grammar of modern games - the grammar established through experimentation and practice over the last three decades - seems to focus on helping players get quickly to what I’ve heard called the Fun Zone, and then keeping them there. Aside from the theatrics, the Fun Zone seems largely indistinguishable from the concept of the <a href="https://en.wikipedia.org/wiki/Flow_(psychology)">Flow State</a>: a state of being in which both one’s perception of time becomes much compressed, and one’s perception of self becomes greatly attenuated. A Flow State classically occurs when an individual is engaged in an activity that exists <em>at or marginally beyond</em> their current abilities. A Flow State occurs when an individual has submitted themselves to a form of activity that demands their full attention, giving little or no opportunity for the kind of conscious self-reflection and rumination that defines the state of existing in the Default Mode Network. The Flow State is when Human Being becomes Human Doing, and through this achieves a kind of sublime integration of self. Games are, at their best, the canonical learning experience, and learning is, at its best, the ultimate form of game.</p>
</section>
<section id="simulation-and-the-fun-zone" class="level2">
<h2 class="anchored" data-anchor-id="simulation-and-the-fun-zone">Simulation and the Fun Zone</h2>
<p>Given this, how does simulation help help gamers enter and remain in the Fun Zone? Of course, it depends. Some aspects of simulation can help with entering and remaining in this state; whereas other can make entry harder and the Zone itself more slippery. Let’s try to think of some examples:</p>
<ul>
<li><strong>Simulation makes enemies and other characters more complex</strong>: This could harm entry/accessibility, but increase the challenge and reward, and so longevity of the Fun Zone experience, for those who manage to cross the initially higher barrier.</li>
<li><strong>Simulation makes the rules of the game more complex</strong>: If these simulation dynamics are introduced only incrementally, rather than all at once, then moderate-to-high simulation-based complexity can be absorbed successfully by the player, and lead to a gaming experience that has many more permutations of challenge to attempt to master, so increasing the longevity of the Fun Zone.</li>
<li><strong>Simulation brings the ecology of the game to the foreground, and therefore diminishes the impact of the player’s actions</strong>: Sometimes this can work, though more for games that preference low intensity longevity over high intensity brief bursts of full focus.</li>
<li><strong>Simulation adds elements that break or obscure the links between player action and consequence</strong>: Here simulation will tend to diminish the player experience, as it makes it harder to know how the player enters and remains on the Fun Zone.</li>
</ul>
</section>
<section id="kgb-as-a-social-standing-simulator" class="level2">
<h2 class="anchored" data-anchor-id="kgb-as-a-social-standing-simulator">KGB as a Social Standing Simulator</h2>
<p>It’s in relation to this last point of possible interaction between simulation and challenge-based Fun Zone maintenance that the key distinct feature of KGB comes to the fore. See, in KGB, you play an investigator in a crumbling Soviet Union, where everyone has learned never to say quite what they think, what they want, and what they intend to do. As an investigator, you will speak with dozens of other characters. As that’s your job. Every conversation affects how others see you, and how others see you has consequences for you and other. But as the characters you are speaking to tend to conceal their true motives and beliefs, the consequences of your conversations may not reveal themselves for some time.</p>
</section>
<section id="games-as-decision-feedback-mechanisms" class="level2">
<h2 class="anchored" data-anchor-id="games-as-decision-feedback-mechanisms">Games as Decision-Feedback Mechanisms</h2>
<p>To understand the implications of building these kinds of social dynamics into a game, let’s start with the following:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/options-and-simple-quick-feedback.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Decisions and Feedback</figcaption>
</figure>
</div>
<p>Here the player (left) has four distinct options: A, B, C and D. If they pick options A, C or D, <em>something bad</em> happens, and happens as a clear consequence of the player’s action. For example, if a player doesn’t jump over a barrier, they can’t move past the barrier. But if the player picks option B, <em>something good</em> happens: progress to a new area, an upgrade, a nicely reassuring sound and animation, etc. The link between the player’s <em>action</em> and the game’s <em>reaction</em> is short and and direct enough that the player quickly comes to recognise the reactions as feedback. And it’s this clear, direct feedback loop that provides the player with a sense of agency and engagement with the dynamics of the game.</p>
<p>A series of challenges, with right and wrong answers, can be the core of what makes a game an engaging experience, if served up in the right way. An obvious example of this type of game is a quiz, where by convention points conditionally accumulate depending on how many correct options were selected by the player. Many computer games implicitly involve something slightly more like a tournament of short quizzes, where progress to the next round depends on selecting all or most of the right answers to the current round.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/quiz-tournament.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Games as a tournament of short quizzes</figcaption>
</figure>
</div>
</section>
<section id="choice-but-not-too-much-choice-avoiding-the-curse-of-dimensionality" class="level2">
<h2 class="anchored" data-anchor-id="choice-but-not-too-much-choice-avoiding-the-curse-of-dimensionality">Choice, but not too much choice: Avoiding the Curse of Dimensionality</h2>
<p>This ‘quiz tournament’ structure to many computer games seems common for two reasons: firstly, it forces players to encounter, and master, different requisite skills in order of importance to the gameplay. If one gameplay mechanic depends on having understood another mechanic - rolling depending on walking; double-jumping depending on jumping, and so on - then this skills tournament structure ensures players should only be expected to solve problems they should already be just-about able to handle. The second reason relates to the ‘curse of dimensionality’, i.e.&nbsp;the way that if apparent choice really is an equally valid option, and if a game really were to keep track and respond to each of the choices made by the player, then the number of possible permutations of player action to react quickly explodes to an unmanageable level:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/curse-of-dimensionality.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Curse of Dimensionality</figcaption>
</figure>
</div>
</section>
<section id="games-as-funny-shaped-corridor-simulators" class="level2">
<h2 class="anchored" data-anchor-id="games-as-funny-shaped-corridor-simulators">Games as Funny-Shaped Corridor Simulators</h2>
<p>It’s for this kind of reason that, since the late 1990s at least, many of the worlds in which games are set tend to be much more limited and constrained than they first appear. Imagine the following: you’re walking in a corridor. There’s a door to the left; and a suspiciously large air-vent to the right.</p>
<ul>
<li>You keep going forward in the corridor: Your path is blocked by a giant boulder.</li>
<li>You take the door to the left: It’s just a cupboard.</li>
<li>You interact with the air-vent, and it opens. You can walk through this vent, and get to the next section.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/funny-shaped-topography.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Funny Shaped Topography</figcaption>
</figure>
</div>
<p>This particular dynamic, which I think was largely pioneered by Half-Life in the late 1990s, has led to a genre I personally call <em>funny-shaped corridor simulators</em>. Why? Because for all of the curviness and excentricity of some of the concealed dead ends, <em>topologically</em> such game environments are just big corridors!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/funny-shaped-topology.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Funny Shaped Topology</figcaption>
</figure>
</div>
<p>This their introduction in the late 1990s, funny-shaped-corridor games have been subject only to one further refinement: some of the ‘wrong paths’ in fact contain special prizes and ‘Easter eggs’, encouraging slightly more exploration and replay:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/funny-shaped-with-prizes.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Funny Shaped Corridors (With Prizes!)</figcaption>
</figure>
</div>
<p>So, clearly, the development of funny-shaped corridors in computer games has now become part of the standard grammar of modern games. A convention for giving players the illusion of choice about where to go, without having to deal with the explosive unpredictability that would come about if they really did have such choice.</p>
</section>
<section id="social-poisoning-as-cruelly-delayed-feedback" class="level2">
<h2 class="anchored" data-anchor-id="social-poisoning-as-cruelly-delayed-feedback">Social Poisoning as (Cruelly) Delayed Feedback</h2>
<p>What then does the social poisoning of KGB look like as a game dynamic, and why, perhaps, did it not become a part of the conventional game toolbox?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/social-poisoning.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Social Poisoning - Bad choice, but I don’t know it</figcaption>
</figure>
</div>
<p>To simplify greatly, in most games there are:</p>
<ul>
<li><ol type="A">
<li>Correct choices, that are presented as correct choices</li>
</ol></li>
<li><ol start="2" type="A">
<li>Incorrect choices, that are presented as incorrect choices</li>
</ol></li>
</ul>
<p>But in KGB, there were:</p>
<ul>
<li><ol type="A">
<li>Correct choices, that look like correct choices;</li>
</ol></li>
<li><ol start="2" type="A">
<li>Incorrect choices, that look like incorrect choices;</li>
</ol></li>
<li><ol start="3" type="A">
<li>Incorrect choices, that look like correct choices</li>
</ol></li>
</ul>
<p>In the figure, an example of A is the green path, which takes the player successfully from the start to the end of the game: the investigator solves the mystery, and not to too detrimental a cost to their health and/or sanity. And an example of B is the short path to the X, ‘A clear dead end’. The player says or does something, and the game tells them it was the wrong choice.</p>
<p>But <em>social poisoning</em>, path type C, is what’s represented by the orange series of paths. Initially, the choice appears to be positively rewarded: other options at the juncture all lead clearly to dead ends, whereas the option selected still brings up other options. The player <em>thinks</em> they are winning, whereas instead they are <em>just losing exceptionally slowly</em>. Each choice the player makes, conditional on having started out along the poison path, is just wasting more of their time, further elasticating the feedback loop connecting player action and consequence. The feedback loop is a <em>noose</em>, and with each further choice, each apparent step towards progress and reward, when on the poison path this noose tightens ever so slightly further.</p>
<p>So when, after having invested many hours in the game, apparently solved the mystery and navigated the hoodlums and apparatchiks and other threats, the player is then told their character upset a senior Kremlin member in disguise in the first few minutes, by expressing a personal preference for their erstwhile rival, and was from that conversation onwards marked for death… the player may well declare, <em>this game isn’t fair!</em>. (And worse: <em>this game isn’t fun!</em>)</p>
</section>
<section id="concealed-endings-a-slight-return" class="level2">
<h2 class="anchored" data-anchor-id="concealed-endings-a-slight-return">Concealed Endings: A Slight Return</h2>
<p>Although games that depend as cryptically on apparently innocuous early game choices are not common, there are many games where - throughout - the player is given a clear choice between a ‘low road’, combining short-term expedience with longer-term costs, and a ‘high road’, with the opposite, and served up a ‘better ending’ if they keep choosing high road options and a ‘worse ending’ if they keep choosing low road options. In almost all such cases, however, implications of such choices are not concealed, and the vast majority of the game experience is identical regardless of whether the player elects to be more of a ‘scoundral’ or a ‘savior’. Such choices are mostly illusory and aesthetic in their implications: you travel the concealed corridor in either case, just the door at the end will be painted blue or red depending on the earlier ‘decisions’.</p>
<p>There is only one modern game I’m aware of that goes some way towards concealing important decisions of this form. In <a href="https://en.wikipedia.org/wiki/Metro:_Last_Light">this game</a> the player is fighting - in a very linear fashion - for the salvation of the human race. But it is through many apparently innocuous decisions that the player can ‘decide’ whether the human race is itself worth saving. One example of this: the protagonist has a guitar in their bunk, and this guitar can be interacted with. If the player chooses to arrest their bloodlust briefly, and stop to play this guitar, to value music and play over warfare and following orders, unbeknownst to their player their ‘karma score’ is increased, and with this their probability of seeing the ‘good ending’.</p>
</section>
<section id="games-as-escapism-the-real-reason-social-poison-simulators-arent-popular" class="level2">
<h2 class="anchored" data-anchor-id="games-as-escapism-the-real-reason-social-poison-simulators-arent-popular">Games as Escapism: The Real Reason Social Poison Simulators aren’t popular</h2>
<p>So, KGB - <a href="https://classicreload.com/play/dosx-kgb.html#">which can now be played online</a> - represents an intriguing failed experiment in games mechanics. An interesting curio that, for various reasons, failed to become part of the standard grammar of modern games.</p>
<p>In the above, I’ve aimed to use KGB as a slight aberation from the conventions of modern games in order to bring these conventions and standards to light, along with some explanations for why they became so. In particular, in terms of the role that aspects of simulation and games mechanics have to delivering the Fun Zone to players, we can say that long and concealed decision implications of the sort embedded in KGB meant that the conventional learning and feedback loop at the heart of most engaging games was missing in places, even though (given some choices can cause the protagonist to lose immediately) most of the time the action-consequence loop was conventionally short.</p>
<p>But of course there’s one explanation, for why Social Poison Simulators didn’t take off as games, that should be uncontroversial to both many critics and some supporters of computer games alike: <em>part of the appeal of games is that they offer a form of escapism</em>. And one of the things that many people seek respite from is exactly the kind of complex social judgement, the meta-thinking, the higher-order guessing games, the lack of ever quite knowing where one stands amongst peers, of not knowing what one does not know, and of sensing but not quite being able to confirm that one’s fate has been decided silently by others, that KGB’s social poison mechanics were, in a highly simplified and stylised form, alluding to and evoking.</p>
<p>Put simply: social poison simulators are rare in computer games <em>because</em> they’re common in the real life games of social relationships. The concept of social poison is perhaps <em>too real</em>, no matter how crudely it’s implemented in game form. Perhaps the most important reason social poisoning never took off in computer games is because it reminds people that, in the one game they cannot elect not to play, the game they can only play once, they might have already lost without ever realising it.</p>


</section>

 ]]></description>
  <category>games</category>
  <category>simulators</category>
  <category>feedback</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/remembering-kgb-social-poison-simulator/index.html</guid>
  <pubDate>Mon, 25 Aug 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Three quality-of-life upgrades</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/three-qol-updates/index.html</link>
  <description><![CDATA[ 




<p>Here’s a brief update to showcase three new improvements to this blog, along with a question (about RSSes), and some broader reflections:</p>
<section id="rss-feed" class="level2">
<h2 class="anchored" data-anchor-id="rss-feed">RSS Feed</h2>
<p><a href="https://www.danolner.net/">Dan Olner</a>, who’s been blogging longer than me, and usually with more interesting contents, made a request on Linkedin to enable RSS on the blog. Thankfully he supplied <a href="https://quarto.org/docs/websites/website-blog.html#rss-feed">the relevant link too</a>, and it all seems quite straightforward. If you now look towards the top right of the blog, you should be able to see the standard RSS icon, and clicking on it does seem to do <em>something</em>.</p>
<ul>
<li><strong>Reflection</strong>: This blog largely began with two aims: to have a practical application for practicing web development skills, and to have a place to develop and showcase my knowledge of statistical methods and data science. I think it’s been successful on both fronts, but it’s also become my platform for trying to think deeply about less technical and work-related domains, such as with my unpop series, and more recently the first short story I’ve finished writing for a number of years. Though writing is a practice I find purposive and enjoyable, and my writing is on topics and ideas that are interesting to me, they might not be of as much interest to persons reading just for the more techical materials.</li>
<li><strong>Question</strong>: There are ways of creating multiple RSS feeds - such as one for more technical posts, and another for less technical posts. <strong>Should I create separate RSS feeds for this blog?</strong> Any views on this are much appreciated.</li>
</ul>
</section>
<section id="word-count" class="level2">
<h2 class="anchored" data-anchor-id="word-count">Word Count</h2>
<p>The subheader to the main blog page should now be procedurally updated to report the number of words the blog contains. At the time of writing the total estimated word count is slightly under 180,000 words, which if at all accurate means, since starting the blog in 2023, I’ve now put out around two books worth of content into the world.</p>
<p>Here’s broadly how the word count works:</p>
<ul>
<li>The <code>_quarto.yml</code> file in the root now has a pre-render argument, meaning each time the blog is rendered or published an R script is run.</li>
<li>The R script recursively searches for all .qmd (quarto) files inside the project folder and its subfolders. Within each .qmd file it looks for anything that looks to be a word (i.e.&nbsp;something made up of letters and numbers, surrounded by spaces or punctuation) and adds that to a running total, until all has run out of .qmd files.</li>
<li>The R script then looks for the subtitle field in index.qmd, then inserts the new word count into the value component of that field.</li>
</ul>
<p>As with so much knowledge work, this solution was arrived at after asking a series of questions to an LLM. This time I tried Claude as I’d heard it was better at technical queries than most alternatives (though Claude are not Claude is: there are many versions). The solution I used was more inspired by, rather than derived directly from, any specific pieces of code it suggested. The subtle danger of using LLMs is that, though they promise to make coding tasks easier, they often instead just transfer the challenges from searching and writing code, to prompting and debugging code. Almost every code solution offered had bugs, and almost every suggested fix introduced new bugs. Knowing when to step away from just plugging in a new AI-generated code, and instead writing something loosely based on the code snippets, seems to be at least half the battle in using AI effectively.</p>
</section>
<section id="repeated-measures-header-image" class="level2">
<h2 class="anchored" data-anchor-id="repeated-measures-header-image">Repeated Measures Header Image</h2>
<p>My <a href="../../posts/handdrawn-stats/repeated-measures/index.html">article on repeated measures</a> is the first post I’ve written that’s entirely hand-written, and hand-drawn, using my <a href="https://remarkable.com/">Remarkable</a> tablet. This meant the post comprised one single image. And in Quarto blogs the first image in a post is used, along with the title and first paragraph, to show previews of that post in the main blog page. This in effect meant the entire repeated measures post was used as its own preview, creating one very long and awkward side image for the post in the main blog page view.</p>
<p>I’ve now corrected this by adding a smaller image, copied out from the main image, at the start of the repeated measures post. This should hopefully ensure the preview for the post is a bit less ‘greedy’, and can be more easily scrolled through with other blog entries in the main blog page.</p>
<p>I’m still trying to come up with the best way of using Remarkable. For <a href="../../posts/fiction/its-your-choice/index.html">my short story</a>, for example, the entire story was first drafted with the device, then transcribed (manually, not automatically, as I don’t trust the image-to-text conversion enough, especially for conveying formatting) onto a Quarto page. For the repeated measures blog, where I frequently swap between text and sketches, I think the Remarkable was fully appropriate. For the story, it was still useful because it meant I could take the tablet alone, without my computer, forcing myself to have fewer distractions while writing it.</p>
<p>For the most recent post - my <a href="../unpop/the-what-is-a-genius-myth/9781787333246-jacket-large.webp">book review of The Genius Myth</a> - I instead adopted more of a hybrid approach from the get-go, writing most of the text in Quarto, then having the Remarkable by my side for drawing sketches to go alongside the text. As the Remarkable syncs quite nicely and quickly with my macbook, this hybrid approach seemed to work pretty well, though it did involve taking more, rather than less, electronic equipment with me.</p>


</section>

 ]]></description>
  <category>blog</category>
  <category>web development</category>
  <category>rss</category>
  <guid>https://jonminton.github.io/jon-blog/posts/three-qol-updates/index.html</guid>
  <pubDate>Sat, 23 Aug 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Some thoughts on The Genius(*) Myth: A Review and a Reverie</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/9781787333246-jacket-large.webp" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Genius Myth Front Cover</figcaption>
</figure>
</div>
<section id="revisionism-and-reactionism" class="level2">
<h2 class="anchored" data-anchor-id="revisionism-and-reactionism">Revisionism and Reactionism</h2>
<p>There was a phase, a few years ago, when revisionist social science non-fiction by British science authors (often affiliated with the BBC) was in vogue. By revisionist I mean something like <em>works intending to challenge problematic assumptions commonly made in certain social scientific and affiliated disciplines, assumptions considered potentially dangerous and socially regressive in their implications and popular interpretations</em>. Often such assumptions related to sex and gender, sometimes to race, sometimes to sexuality, or more occasionally to cultural superiority.</p>
<p>Some examples: <a href="https://en.wikipedia.org/wiki/Inferior_(book)"><strong>Inferior</strong></a> (about gender differences) and <a href="https://en.wikipedia.org/wiki/Superior:_The_Return_of_Race_Science"><strong>Superior</strong></a> (about race differences) by Angela Saini; a tranche of books about testosterone and sex differences by <a href="https://en.wikipedia.org/wiki/Cordelia_Fine">Cordelia Fine</a>; certain books by <a href="https://en.wikipedia.org/wiki/Adam_Rutherford">Adam Rutherford</a>; <a href="https://en.wikipedia.org/wiki/Invisible_Women:_Exposing_Data_Bias_in_a_World_Designed_for_Men"><strong>Invisible Women</strong></a> by Caroline Criado Perez: mostly books I’ve read (or tried to).</p>
<p>The problem with such books: <em>revisionism is to the political left as reactionism is to the political right</em>. The impulse is the same: to be contrary, sometimes just for the sake of it. The strength of such books is they <em>can</em> help to help us see the waters in which specific disciplines swim; the limitations are then either that they may argue for the fields to be dredged; or that they are in practice simply incurious about the the disciplines they seek to critique, seeing them just as another field to fight the progressive fight.</p>
<p>Sometimes the urge towards resistance and contrarianism - whether to fight the progressive fight as in revisionism, or fight the conservative fight as in reactionism - can lead to strange bedfellows and outright contradiction. A key example of this: on <a href="https://www.bbc.co.uk/sounds/play/m00055m9">Monday 20 May 2019 Radio 4’s <em>Start the Week</em></a> featured Angela Saini, and Caroline Criado Perez. Saini’s previous book, <strong>Inferior</strong>, essentially argued that many sciences overstate sex differences, leading to sexism and other forms of harm against women. Perez’s book, <strong>Invisible Women</strong>, by contrast argues that many sciences <em>understate</em> sex differences, and assume that research conducted in men also generalises simply to women, <em>also</em> constituting a form of sexism and harm against women. So, identifying and highlighting sex differences is sexist; and not identifying and not highlighting sex differences is also sexist.<sup>1</sup></p>
</section>
<section id="the-genius-myth-conceit" class="level2">
<h2 class="anchored" data-anchor-id="the-genius-myth-conceit">The Genius Myth Conceit</h2>
<p>All of which is intended to be a preamble to my notes on Helen Lewis’ book <strong>The Genius Myth</strong>. Many years ago Lewis could easily be grouped with the likes of Saini, Fine, and Perez, as someone perhaps more motivated to argue against a perceived (and perceived-to-be-harmful) scientific orthodoxy, than to present a coherent scientific synthesis on particular topics and fields, the kind of synthesis - the capacity to abstract, generalise, explain and understand, efficiently and effectively - that, for me, allows popular science to, at its best, induce a near psychedelic sense of <em>awe</em> in the reader.<sup>2</sup> Fortunately, Lewis’ <strong>The Genius Myth</strong> has two things going for it that make it a much more interesting book than some of the above: 1) Lewis has to an extent been ‘mugged by reality’ when it comes to failing certain ideological purity tests (mostly due to holding views considered by some to be ‘gender critical’, and by others just as ‘common sense’); 2) Lewis is genuinely curious and an effective, engaging writer.</p>
<p>The <em>conceit</em> of <strong>The Genius Myth</strong> is definitely <em>revisionist</em>. It’s something like:</p>
<blockquote class="blockquote">
<p>the idea of labelling some people as ‘geniuses’ is right-wing, because it focuses on the myth of inherent superiority, and downplays the sociological and environmental factors that enabled such individuals to flourish. It also gives such individuals too much of a ‘free pass’ in tolerating, even condoning, bad behaviour that would not be acceptable in non-geniuses. So it promotes something like a two-tier ethics: one rule for them, another for everyone else.</p>
</blockquote>
<p>However, both the advantage and limitation of <strong>The Genius Myth</strong> is in its chatty wooliness, its (and Lewis’) convivial curiosity. Despite being anchored around the conceit of deconstructing a dangerous dogma, <strong>The Genius Myth</strong> takes a scenic route through to its (uncertain) destination, stopping frequently to smell the roses (and all too often the malodorous manure in which it’s grown).</p>
<p>Now to the subtitle of my review: <em>term undefined</em>. Lewis adopts, at best, a pornography censor’s approach to defining genius: <em>you know it when you see it</em>. Or at least she seems to for the first part of the book, which focuses on criticising various efforts to identify geniuses, support geniuses, and (as part of the right-edge of the eugenics movement) to help breed more geniuses.</p>
</section>
<section id="searching-for-genius-a-right-wing-enterprise" class="level2">
<h2 class="anchored" data-anchor-id="searching-for-genius-a-right-wing-enterprise">Searching for Genius: A Right-wing enterprise?</h2>
<p>Starting with the claim that “Genius is a right-wing concept, because it champions the individual over the collective”, part one focuses on endeavours by the likes of Francis Galton and Lewis Terman to, respectively, profile proven geniuses and identify potential geniuses. The former endeavour suffered from a kind of survivorship bias: of course in iniquitous times only those whose hereditary bequests are financial as well as cognitive, people independently wealthy have well connected, have the kind of environment in which such talents are liable to flourish, and for their potential to be fulfilled.</p>
<p>So, over the early 20th century attempts to measure cognitive ability in everyone, not just laud its presence in the landed gentry, gained momentum, and the science and concept of IQ was born. Lewis Terman attempted to use this nascent discipline to identify, at a young age, those children most likely to become exceptionally smart adults, and support them in actualising their potential. How smart? ‘Genius level’, of course. Casting the net of cognitive testing wide, Terman’s cognitive child elites were dubbed his ‘Termites’.</p>
<p>Lewis argues that such efforts - to pick ‘winners’ early using cognitive testing - were largely unsuccessful. How? By pointing out a number of occasions where individuals, who were judged ‘smart but not smart enough’ and rejected (miscategorised?) by Terman in his attempts to find budding geniuses, then turned out to be extremely capable scientists and engineers, clearly ‘geniuses’ (again using the porn censor’s definition) in retrospect. The median achievements of the Termites, however, were much more modest.</p>
<p>Later, and entertainingly, Lewis discusses the highly dysfunctional and fractious nature of high IQ societies, more bastions for obsessive weirdos and conspiracy theorists with limited practical skills and big chips on their shoulders, than for high functioning geniuses.</p>
<p>Many of the examples in this part were interesting to me, and many of the arguments broadly convincing. Part of me wishes Lewis had delved a little more into the technical minutae of the concept of ‘g’ in cognitive testing, and of its measurement in children, as such issues could explain much of what she discusses in this part. (A more realistic part of me is glad she didn’t, as I don’t think these aspects would be her forte…)</p>
</section>
<section id="iq-and-g" class="level2">
<h2 class="anchored" data-anchor-id="iq-and-g">IQ and g</h2>
<p>Regarding IQ and <strong>g</strong>. We have, fundamentally, a proposition: how good someone is at answering one question testing general reasoning ability should be broadly predictive of how they answer others. The tendency to answer each question correctly is partly determined by something underlying and inherent, a single ‘latent factor’, commonly called <strong>g</strong>; conversely, the average tendency (maybe weighted by difficulty) to answer a batch of questions correctly should be a reasonable way of assessing what this <strong>g</strong> is for an individual. IQ scores are therefore broadly numeric descriptions of what an individual’s estimated <strong>g</strong> value, as normed against the general population: 100 for the average score, 115 (usually) for about one standard deviation above the average (higher than about two thirds of the population), 130 for two standard deviations above (higher than about 19 people out of 20), and so on. (See <a href="https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule">here</a> for the statistical heuristics; and <a href="../../../posts/handdrawn-stats/how-factor-analysis-is-used-in-testing/index.html">this earlier statistical post</a> for more on the theory of psychometric testing.)</p>
<p>However, though psychometric models can be run which jump straight to this ‘one underlying factor model’ (the ‘big <strong>g</strong>’), this doesn’t seem to be how most modern IQ test batteries are designed. Rather, it’s recognised that there are a number of distinct subdimensions - sub-batteries of test items that are more internally coherent to each other than to other items - that the battery of items group into. One subdivision is between ‘crystallised’ and ‘fluid’ intelligence; another subdivision may be between ‘verbal’ and ‘numeric’ intelligence. Such subdivisions just tend to drop out of patterns of correlation between collections of items. The sub-factors tend to be positively correlated; but items testing (say) crystallised intelligence tend to be more correlated with each other than (say) items testing fluid intelligence.</p>
</section>
<section id="iq-vs-achieved-genius" class="level2">
<h2 class="anchored" data-anchor-id="iq-vs-achieved-genius">IQ vs Achieved Genius</h2>
<p>What implications do these subfactors have on what we might call ‘achieved genius’? Well, an IQ test is something of a grab-bag of evaluations, and to the extent it’s at all predictive of job performance, what it tends to return is an average of expected performant abilities across a variety of jobs and roles. It’s a <em>generic score</em> for a <em>generic job</em> requiring some level of cognitive ability.</p>
<p>But <em>no one has a generic job</em>, i.e.&nbsp;a job whose performance depends equally<sup>3</sup> on all those subfactors tested somewhere within most IQ tests. IQ tests are, at best, attempts at predicting the ability of someone in a fictitious job that doesn’t exist. (Though a fictitious job also potentially closer to most jobs than any specific job selected at random.)</p>
<p>No.&nbsp;All too often <em>realised genius</em> (if we are to use that term) is a function of how well one’s specific cognitive profile <em>matches</em> with the demands of the role someone is actually expected to perform. Someone might have great ability with spatial reasoning, say, but if the demands of their role are largely about verbal acuity, then that high <em>potential</em> ability in their strongest subdomain won’t translate into real world achievements. Almost invariably, if an individual <em>can</em> find a role that works to their strengths, their actual performance will tend to be greater than that predicted by a generic <strong>g</strong> score implicitly based around the requirements of a generic job.</p>
<p>We’ll delve more into this in the critique of part two. But first let’s address the issue of how IQ tests are performed in children, as this relates to another piece of technical context for part one.</p>
</section>
<section id="iq-norms-in-infancy-and-childhood" class="level2">
<h2 class="anchored" data-anchor-id="iq-norms-in-infancy-and-childhood">IQ Norms in Infancy and Childhood</h2>
<p>Think of <a href="https://www.rcpch.ac.uk/resources/uk-who-growth-charts-0-4-years">an infant growth chart</a> used by pediatricians. The weight and height (initially length) of the infant is recorded at different times since birth. What’s the infant’s size and weight at birth, at 6 months, and two years, and so on? Such information, tracking an individual size and weight over time, can be plotted with age on the horizontal axis, and height/weight on the vertical. Typically, for hundreds or thousands of such infants, the height/weight trajectories of infants on their path to childhood have a tendency to increase quickly to start with, then perhaps to level off. There are also some types of trajectory, and age-based values of height/weight, that are more common, and others that are more uncommon.</p>
<p>From the assessment of a large population of infants over time, growth charts are developed, and child’s weight and height at a particular age since birth can be categorised both <em>relative to their younger and older selves</em> (a polyline through time), <em>and also</em> relative to a population of infants measured at exactly the same age. From this, the infant’s dimension can be expressed as being on <em>a percentile</em> given their age. And from this the pediatrician might, if they were feeling especially brave or incautious, wish to produce a predicted (or projected) height and weight of that infant if and when they reach adulthood. At its simplist, this would involve stating something like: <em>this infant was measured as on the 20th percentile of length at six weeks of age. If they were to remain at this same percentile throughout childhood then they would grow to 5’11” in height in adulthood.</em></p>
<p>So, why would this kind of extrapolation be incautious? Because we know there can be a great deal of variation between how <em>a specific infant</em> grows over time, and the statistical average. For example: one infant could start off on the 90th percentile at 6 weeks, then fall off to the 60th by six months; another could remain at the 30th percentile from birth to 12 years of age, then jump to the 70th percentile between their 13th and 14th birthday. In either case, relying on a single measure to extrapolate to adult height and weight seems pretty foolish.</p>
<p>But when it comes to identifying ‘geniuses’ in childhood, it does seem that something like this single-measure extrapolation issue is at play. Like size, performance in cognitive tests tends to vary with age across childhood. So like weight and length/height in infant growth charts, a given score could (say) place someone at the 20th percentile if measured at five years of age, but at the 55th percentile if measured at the six and a half years of age.</p>
<p>Which brings us to the (I think) largely justified questioning in the Genius Myth of whether the individual reported as having the highest recorded IQ, Marilyn vos Savant, really did so (and whether this high recorded score really means what we might intuitively assume it to mean). To quote the opening paragraph of the chapter:</p>
<blockquote class="blockquote">
<p>Who has the highest IQ in history? One answer would be: a little girl from Missouri. In 1956, she took a version of the Stanford-Binet test and recorded a mental age of twenty-two years and ten months, equivalent to an IQ of 228. (The score needed to get into Mensa is 140, and the average IQ in the general population is 100.) Her score lay unnoticed for decades, until it was uncovered and sent in to the Guinness Book of World Records, which declared her to be the smartest person who ever lived. A genius, in other words. Her name, appropriately enough, was Marilyn vos Savant.</p>
</blockquote>
</section>
<section id="fermi-and-the-million-planets" class="level2">
<h2 class="anchored" data-anchor-id="fermi-and-the-million-planets">Fermi and the Million Planets</h2>
<p>A critical question about this little girl: <em>how</em> little? How young was Marilyn when this test was taken? As Lewis discusses, there’s some uncertainty in this answer, and this uncertainty could be crucial. Let’s walk through why, with a little Fermi estimation and my sketch below:</p>
<ul>
<li>Assuming a standard deviation of 16<sup>4</sup> points, an IQ of 228 is 8 standard deviations above the average.</li>
<li>Now, with a Normal distribution, <img src="https://latex.codecogs.com/png.latex?P(Z%20%5Cge%208)%20%5Capprox%2010%5E%7B-15%7D">.</li>
<li>World population back in 1956, <img src="https://latex.codecogs.com/png.latex?%5Capprox%2010%5E%7B9%7D"></li>
</ul>
<p>Put simply: the world population was orders of magnitude too small back in 1956 for it to have been likely to have found someone whose ‘true’ cognitive ability was 8 standard deviations above the mean. How many orders of magnitude? Well, 15 - 9 is 6, so we would likely require about a million Planet Earths, with 1950s/1960s population sizes, to find someone as apparently able as vos Savant. <sup>5</sup></p>
<p>Given this, artefactual explanations seem far more likely. Let’s look at the sketch:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/mvs.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">MVS age uncertainty</figcaption>
</figure>
</div>
<p>In this sketch I’ve drawn out some cognitive growth curves showing how raw scores might get translated into age-normalised scores. The average score for a particular age is shown as a solid blue line, one standard deviation above and below as blue dashed lines, and 2 standard deviations as green dashed lines. We could imagine further isobars(?) like these, indicating, three, four, five, up to 8 standard deviations below and above the age-normed population average.</p>
<p>Something else I’ve drawn is a horizontal red line: this is the maximum raw score achievable given the test battery. If the test has 40 items, and someone gets every question correct, then the test is technically <em>censored</em> in its estimate of the person’s ability to complete such tests. Note a couple more things: firstly, how the same raw test score (a perfect score) maps onto <em>different percentiles</em> depending on the test-taker’s age. Secondly (and this is just the converse of the first point), how the very highest apparent percentile scores can only be achieved in earlier childhood. So, at age 5, the top raw score might place someone 8 standard deviations above the mean; at age 6, the same score might place them ‘only’ 6.4 SDs above the mean; and at 7, ‘only’ 5.7 SDs above, and so on. All the way up to adulthood, where the top score will ‘only’ indicate that someone’s 3.2 SDs above the population average.</p>
<p>Now imagine there’s also uncertainty about the test-taker’s age, especially in earlier childhood, where the gradient of percentiles is steepest. Let’s say Marilyn’s recorded age was as indicated with the letter <strong>M</strong>: <em>very</em> very very impressive for her age (and most ages). But if her actual age were a few weeks or months later, indicated by the symbol <strong>M?</strong>, this equal raw score would be ‘merely’ very very impressive for her age. This loss of a ‘very’ could conceivably be a couple of standard deviations, even more, if the error in age is especially egregious (and/or the accuracy with which the percentiles are estimated at younger ages is especially lower).</p>
</section>
<section id="a-quiet-return-from-galton" class="level2">
<h2 class="anchored" data-anchor-id="a-quiet-return-from-galton">A quiet return from Galton…</h2>
<p>Something else is also likely at play too, one of the oldest phenomena observed in statistical inference. See the figure below as an illustration. Here I’ve drawn just the Z scores (tramlines for percentiles) against age. I’ve sketched out three individuals who were tested multiple times, each at slightly different ages. Red has a first score that starts off high, then <em>falls down towards the average</em>; grey stays around the middle throughout, though oscillates quite a lot. Black starts off with an especially low score, but over time it <em>rises up towards the average</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/reg.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Examples of regression to the mean in score percentiles against age for three hypothetical persons</figcaption>
</figure>
</div>
<p>What is this an example of? <em>Regression towards the mean</em>, originally referred to as <em>regression towards mediocrity</em> by none other than.. Francis Galton. Put simply: when something or someone is being tested repeatedly, more generically but abstractly whenever a population is being sampled from repeatedly, exceptional scores are likely to be followed by less exceptional scores, regardless of the direction of exceptionalness. Here red’s first score was exceptionally high, and black’s score exceptionally low, but both subjects tended towards less exceptional scores after more measures.</p>
<p>Now, as far as I can tell the “World’s Smartest Person” moniker for vos Savant was based on a single childhood test. Given it implies an IQ eight standard deviations above the mean, and we would likely require about a million planets to find someone this exceptional if artefacts aren’t at play, we can hopefully assume something like the following:</p>
<ul>
<li>vos Savant was and remained better at completing these kinds of tests than most people at all ages</li>
<li>vos Savant was likely precocious in her cognitive development, literally much ahead of the growth curve for critical parts of childhood.</li>
<li>vos Savant’s age may well have been misestimated when ‘The Test’ was completed.</li>
<li>vos Savant likely had a good day on the day she was asked to complete the test.</li>
</ul>
</section>
<section id="back-to-iq-and-job-performance" class="level2">
<h2 class="anchored" data-anchor-id="back-to-iq-and-job-performance">Back to IQ and Job Performance</h2>
<p>Let’s now start to close another open loop from earlier: the idea that if IQ is positively predictive of job performance, it’s only in quite a generic sense, for quite a generic job. If ‘genius’ is about achievement in a specific career pathway (and the career is in something other than completing IQ tests), then why might we <em>not</em> expect the persons with the highest measured IQ scores to be most most likely to be ‘geniuses’ in any particular fields?</p>
<p>To think more about that question, let’s think a bit about role-playing games, and in particular standard practices for generating characters in such games.</p>
</section>
<section id="cognitive-traits-and-rpgs" class="level2">
<h2 class="anchored" data-anchor-id="cognitive-traits-and-rpgs">Cognitive Traits and RPGs</h2>
<p>Typically, an RPG that allows character design will have the following:</p>
<ul>
<li>A series of K (say ten) attributes, each with minimum and maximum possible scores.</li>
<li>A total ‘pool’ of M (say 150) attribute or skill points, which can be spent/allocated to each of the 10 attributes.</li>
</ul>
<p>One option a player could take would be to create a ‘balanced’ character. With 10 attributes and 150 points, for example, this would mean assigning 15 equally to each of the 10 attributes. This would be a Jack-of-all-Trades type character, with no obvious weaknesses, but no particular strengths either.</p>
<p>For many RPGs, however, a balanced character tends neither to be the most interesting nor strategically advantageous way to play. Instead, most such games involve forming a team (either composed of other real-life players, as in an online game, or computer-generated characters, as with a single person game). The challenge in forming a team then becomes <em>recruit and maintain working relationships with other persons whose attributes <strong>complement</strong> one’s own</em>. Within a team, the weaknesses or shortfalls in one character’s attributes are balanced out by another character’s strengths in these same attributes. (For example, someone with high strength but low wisdom being balanced out by another character with high wisdom but low strength: The brains, and the brawn.)</p>
</section>
<section id="teamwork-in-theory" class="level2">
<h2 class="anchored" data-anchor-id="teamwork-in-theory">Teamwork in Theory</h2>
<p>The effectiveness of the team at meeting the challenges it encounters, i.e.&nbsp;the effectiveness of the team, therefore depends on the following:</p>
<ul>
<li>The strategic decisions made by the team to direct itself to challenges that it is at least adequately prepared for;</li>
<li>The maximum potential ability that exists within the team to solve the specific challenges of the particular encounters it faces;</li>
<li>The tactical capacity of the team to turn to and support the specific team member best suited to the current challenge quickly and efficiently.</li>
</ul>
<p>Although many or most RPGs are set in fantasy worlds, the factors at play in ensuring a team works effectively are far from fantastical, and very much real life matters. I think there’s both something in this realisation that strongly supports the general thrust of Lewis’ arguments, as well as something that either challenges or caveats them.</p>
<p>In terms of supporting Lewis’ position: throughout the book there are many examples given of where the apparent, realised genius of an individual ‘genius’ turns out to be a much more collective endeavour than it might first appear, and even if the maximum team size that a ‘genius’ can effectively recruit and maintain throughout their lifetime is two people. In the chapter <strong>Great Wives</strong>, Lewis highlights the critical importance of Leo Tolstoy’s wife, Sofia, in managing the more mundane intellectual tasks - such as transcription and editing - which allowed his most (purportedly) well read novels to become works of genius. For those lacking the inclination or social aptitude to acquire a wife, a mother or even an institution (Cambridge university in Isaac Newton’s case, insane asylums or cloisters for others) can function similarly to remove those quotidian considerations otherwise required to feed the (often minimal) material necessities of those obsessed ‘loners’ whom history has come to consider ‘genius’. Such loners are seldom ever really alone, rather supported quietly by others, allowing them in which they can feed deeply on their own thoughts.</p>
<p>In the chapter following <strong>Great Wives</strong>, <strong>Keepers of the Flame</strong>, Lewis points out that the tenure of such complementary partnerships can even extend beyond the life of the index case, as with the widows of Jackson Pollock and Vincent Van Gogh. <sup>6</sup></p>
</section>
<section id="deficit-models-strong-and-weak" class="level2">
<h2 class="anchored" data-anchor-id="deficit-models-strong-and-weak">Deficit Models: Strong and Weak</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/three-profiles.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Three possible cognitive profiles. Compared with the second profile, the third profile might be more likely to manifest both as ‘genius’ as well as learning disabled</figcaption>
</figure>
</div>
<p>There’s another aspect of this team-level focus on the creation of genius which, I think, either challenges or caveats aspects of Lewis’ arguments. This relates to the chapter <strong>The Deficit Model</strong>, whose opening quotation, by Aldous Huxley, is as follows:</p>
<blockquote class="blockquote">
<p>If we evolved a race of Isaac Newtons, that would not be progress. For the price Newton had to pay for being a supreme intellect was that he was incapable of friendship, love, fatherhood, and many other desirable things. As a man he was a failure; as a monster he was superb.</p>
</blockquote>
<p>Lewis later defines ‘the deficit model of genius’ as being the idea that “in exchange for the precious gift of genius, there is a human price to be paid.” Here I think there’s a <strong>strong version</strong> of the Deficit Model, which <em>is</em> likely a myth in every sense; and a <strong>weak version</strong> of the Deficit Model, which I think Lewis might be too easily discounting.</p>
<p>The <strong>strong version</strong> of the Deficit Model would be something like <em>the greater an individual’s failings in other domains, the greater their genius in their specialism</em>. An example of this would be arguing that Stephen Hawking’s achievements in cosmology in a sense emerged <em>because</em> of his Motor Neuron Disease, rather than <em>despite</em> his disability. Or that John Nash’s insights into game theory emerged <em>because</em> of his schizophrena, not <em>despite</em> it. As Lewis suggests (I assume correctly, but haven’t checked), Hawking’s research intensity fell after his MND became more severe, even though it was after this period when he reached broad public consciousness; and Nash’s work tended to be hindered, rather than enabled, by his more severe mental health crises. The strong version is clearly false, but mythical, because it implicitly posits something like Karmic justice afoot in an indifferent, cold, rule-bound universe: some kind of cosmic compensation being at play in cards people are dealt. Unlike a nice, fair fantasy game, some people really are given far more attribute points to spend on themselves than others, and so the game will tend to be easier for them than others granted less generous endowments.</p>
<p>But then there does seem to be a <strong>weak version</strong> of the Deficit Model which I think should be harder to discount. This comes about from both the strengths and the limitations that emerge when people might have had the good fortune to have been allocated a great many skill points, but also the mixed fortune to have had such points allocated in a very uneven way.</p>
<p>Let’s return to the RPG skill point example. A nice, balanced game would hold the skill points allotment - the pool of free skill points which can be allocated - constant, while allowing players high latitude in how such points can be allocated. And as already mentioned, the simplest way to allocate such skill points would be equally, the Jack-of-all-Trades strategy, leading to low (or no) <em>variance</em> between skill items.</p>
<p>Implicitly, something like an IQ score can be seen both as a measure of the <em>skill points allotment</em>, the <em>pool of free points,</em> as well as the assumption that such points <em>are</em> allocated in a Jack-of-all-Trades style way, with fairly low variance between specific cognitive traits. How do we know this? Because for most people, the between-traits variance <em>is</em> low. This shouldn’t be surprising, because the specific traits are often selected such that, within most of the population tested (i.e.&nbsp;most people) they are highly correlated, and have low variance.</p>
<p>And what happens when individuals’ profiles exhibit lower-than-expected correlation between traits, much higher variance? Well, quite often the implication is drawn that it’s the high-variance individuals, rather than the test assumptions, that are <em>wrong</em>. More specifically, high variance between cognitive traits - ‘hills and valleys’ rather than ‘plateaus’ - is often used as evidence with which to label such individuals as having <em>specific learning disabilities</em> (SLD) or <em>developmental disorders,</em> such as ADHD, dyslexia, and autism.</p>
<p>And therein lies the possible truth behind a <strong>weak version of the Deficit Model:</strong> having higher variance between cognitive traits, including performance in specific traits that are below the population average (not just below those that might be expected from a high-variance individual’s <strong>g</strong>), can be highly debilitating in a great many ways. In particular, by analogy with something like Endowment Theory,<sup>7</sup> we might assume that having a trait score (say) 10 points below the population average can be substantially more disadvantagous to an individual being able to perform trait-related activities than being 10 points above the population average would be advantageous for performing such activities. Put more simply: deficits often harm more than opposite-but-equivalent advantages help. Why? In large part because much of the world is designed around average people, with average trait abilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/asymmetry.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Asymmetry in the gains from being better than average, compared with the functional deficits of being worse than average</figcaption>
</figure>
</div>
</section>
<section id="deficits-in-working-memory-as-an-example-of-asymmetries-in-function" class="level2">
<h2 class="anchored" data-anchor-id="deficits-in-working-memory-as-an-example-of-asymmetries-in-function">Deficits in Working Memory as an example of asymmetries in function</h2>
<p>As a simple example (now thankfully somewhat historic due to the rise of smartphones) consider the ease with which someone with slightly worse-than-average working memory, and someone with slightly better-than-average working memory, would be able to remember and follow some verbal instructions about how to get from <em>here</em> to <em>there</em>. The person asked for the directions, who is likely to have average working memory - let’s say <strong>5</strong> elements - is then likely to offer instructions of no more than their own working memory capacity: <em>first you (1), until you get to (2), then turn (3), at (4), and look for (5)</em>. For someone whose working memory capacity is a bit lower (say <strong>4</strong> elements) such instructions are <em>almost always</em> likely to be forgotten by the end; either the entire instruction set is likely to be forgotten in trying to squeeze <strong>5 into 4</strong>, or the last, critical, piece of the instruction set is likely to be forgotten, and so someone else will need to be asked. Conversely, for someone whose working memory capacity is a bit higher than average (say <strong>6</strong> elements), they will be able to remember the complete instruction set no better than the person whose working memory capacity is average. One element more isn’t as much better as one element less is worse: the practical navigation test is <em>pass-or-fail</em>, and being only slightly below average can mean <em>always failing</em>.</p>
</section>
<section id="the-glass-cannon" class="level2">
<h2 class="anchored" data-anchor-id="the-glass-cannon">The Glass Cannon</h2>
<p>There’s another term I’m aware from games, about exceptionally <em>unbalanced</em> character builds: <strong>glass cannons</strong>. Both exceptionally powerful, <em>and</em> exceptionally fragile, the glass cannon is a high-risk build, not for the faint of heart. But a glass cannon, surrounded and supported by a team of adventurers with complementary skills and a willingness to shield the glass cannon’s fragilities, can be exceptionally strong, and achieve much more than a balanced team would ever be capable of.</p>
<p>So the <strong>weak version of the Deficit Model</strong> I think worth defending is something like <em>many apparent geniuses are cognitive glass cannons</em>, who have somehow found themselves in the kind of protective and supportive environments where their exceptional strengths in one or two traits can flourish, while their many deficits in other traits can be mitigated, somewhat at least, by their specific social and institutional millieu.</p>
</section>
<section id="the-artistic-genius" class="level2">
<h2 class="anchored" data-anchor-id="the-artistic-genius">The Artistic Genius</h2>
<p>So far, most of my discussion of <strong>The Genius Myth</strong> has focused on what might be called <em>scientific geniuses</em>. But a number of examples Lewis gives are of <em>artistic geniuses</em>. I think I draw more a distinction between these two types of genius than Lewis does. Though maybe not. When it comes to <em>artistic geniuses</em> Lewis’ main concerns are that the designation of <em>genius</em> has historically been used by such designees as social licence for bad behaviour. Unlike mere mortals, such genius creatives <em>should be</em> allowed to indulge in selfish, harmful, hateful, cruel and lascivious behaviour. In fact, such behaviours, and the proclivities and instincts that guide them, may even be the <em>source of their genius</em>, their <em>muse</em>, and so should be - if anything - encouraged.</p>
<p>As well as referencing the adolescent-male-pornographic preoccupations of much of Salvador Dali (most of what he painted <em>wasn’t</em> melted clock faces, but idealised womens’ bodies), Lewis devotes a chapter - <strong>Monsters and Tortured Artists</strong> - to the works of English playwright Chris Goode, whose predatory peadophilic impulses seemed to drive much of his artistic output, as well as his highly unprofessional behaviour towards the many young men and boys he recruited to realise abstractions of his sexual fantasies on the stage. Lewis suggests, I think quite plausibly, that Goode’s homosexuality meant a double standard was applied by critics when encountering his onstage kinks, as compared with an equally horny, youth-focused, and predatory heterosexual male. <a href="../../../posts/unpop/brother-lee-the-antimonk/index.html">My post on William S Burroughs</a>, inspired by the positive critical reception to the recent film adaptation of <em>Queer</em>, hopefully illustrates why I’m largely in sympathy this position. There should not be double standards, no differential treatment in relation to sex, nor sexuality, nor any other immutable characteristics.</p>
<p>But as with the strong and weak version of the Deficit Model, I think there might be a need for a similar distinction between strong and weak versions of arguments about Artistic Geniuses as Self-Indulgers and Self-Expressors. If the strong version is as described above - someone who publicly revels and marinates in their basest carnal instincts and desires, and demands others applaud their indulgences - what might a defensible weak version look like?</p>
<p>To me the defensible weak version is something like the following: art that honestly expresses the shadows in (first and foremost) the artist’s character, and through this helps the consumer of such art to recognise such shadows as essential features of the human condition.<sup>8</sup> Without a willingness on behalf of the artist to express their own darker aspects, and without the consumer’s willingness to look at such depictions of weakness and darkness without reactionary condemnation, the capacity for art to facilitate feelings of compassion, empathy, tolerance and forgiveness is never developed. More abstractly, a culture that cannot tolerate honest expressions of darkness by artists is one in which the shadow is forever dis-integrated from the self, and so more likely to become expressed only in pathology.</p>
<p>Perhaps the most famous quote related to this idea is Aleksandr Solzhenitsyn’s, that “The line separating good from evil passes … through every human heart.” The quote in full, seldom quoted, is worth considering:</p>
<blockquote class="blockquote">
<p>The line separating good and evil passes not through states, nor between classes, nor between political parties either – but right through every human heart – and through all human hearts. This line shifts. Inside us, it oscillates with the years. And even within hearts overwhelmed by evil, one small bridgehead of good is retained.</p>
</blockquote>
<p><a href="https://www.goodreads.com/quotes/450864-the-line-separating-good-and-evil-passes-not-through-states">Source</a></p>
<p>So, in context, Solzhenitsyn’s quote argues that the failure to recognise both the capacity for evil in ourselves and others we consider ‘good’, and for goodness in those we consider enemies, can lead to a kind of Manichean tribalism, a mentality of binary sorting - good guys like <em>us</em>; bad guys like <em>them</em> - and from this an implicit moral license to overlook flaws and transgressions in <em>us</em>, and to do righteous harm to those we consider <em>them.</em></p>
<p>Art that promotes critical reflection on the shadows within ourselves, and the virtues in our enemies, of course isn’t the only art worth having. Art which evokes a more general sense of transcendence and awe in the natural world may be another category of art invaluable contribution to humanity. But the weak version of the <strong>Monster and Tortured Artist</strong> myth I think worth defending and saving is that of the artist willing to look unflinchingly and represent honestly the flaws in themselves, and through this to quietly promote consolation and compassion through such critical reflection. The line in practice between reflecting on one’s shadows, and indulging and reveling in one’s darkness, may at times be blurry and indistinct, but I think is worth maintaining. A crude reading of Lewis’ chapter framed around Goode may lead us to conclude we should simply be more intolerant, more ready to condemn, artists who bring their own shadows to light, the worst possible outcome of which would be cow such troubled souls into a permanent state of dishonesty and hypocrisy, forever forced to pretend to be a caricature of virtue, while underneath letting their shadows quietly metastasize in the darkness. That way, I think, ultimately lies a more intolerant, more hate-filled, and ultimately less beautiful world.</p>
</section>
<section id="concluding-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="concluding-thoughts">Concluding Thoughts</h2>
<p>This post has been somewhere between a review of <strong>The Genius Myth</strong>, and a kind of reverie inspired by it. If the mark of a good book is that it inspires in readers a wish or need to think deeply about the topics and themes it raises, then surely <strong>The Genius Myth</strong> is, to my estimation, a good book. As with the previous section, however, perhaps it’s good in this sense in large part <em>because</em> of its flaws? Its breezy anecdotal style; its looseness with definitions; its impression and conceit as a somewhat staid act of progressive revisionism, which it then (thankfully) never quite manages to live up to.</p>
<p>Recently, Lewis reports that so far sales and/or critical engagement of <strong>The Genius Myth</strong> <a href="https://helenlewis.substack.com/p/the-bluestocking-379-the-economics">have been somewhat disappointing</a>. Perhaps this reflects a more general trend for full length nonfiction books themselves to have become a harder sell in an age of ever more fractured attentions and in particular - either fittingly or ironically from Lewis’ perspective, given her ubiquity in the medium - due to the rising popularity of long-form podcasts as ways of scratching the nonfiction itch for information. Perhaps it’s due to the question of Genius not being an especially hot topic at the moment, even if it emanates some evergreen warmth.</p>
<p>Or perhaps (to say the quiet part out loud) <strong>The Genius Myth</strong> ultimately just isn’t an especially insightful or focused contribution to the topic. I don’t know. It’s definitely been an interesting read from my perspective, which has sparked a lot of ideas… hence the length of this blog post!</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See approximately 25 into the programme, where Saini and Perez attempt to find a reasonable synthesis of their respective positions. What was interesting to me was how <em>motivated</em> they both appeared to be to do so, <em>as if</em> they both recognised each other as being on ‘the same side of the cause’…↩︎</p></li>
<li id="fn2"><p>Jared Diamond, Robert Sapolsky, Richard Dawkins, and to a lesser extent Steven Pinker are all experts in this kind of <em>awesome</em> popular scientific nonfiction.↩︎</p></li>
<li id="fn3"><p>Or, more technically, in direct proportion to how such subdimensions are weighted in IQ tests in the determination of <strong>g</strong>.↩︎</p></li>
<li id="fn4"><p>The SD of earlier tests of this form was 16 units, not 15, apparently.↩︎</p></li>
<li id="fn5"><p>And as we’re dealing with order of magnitudes only, and our population hasn’t increased tenfold or more since, that’s still the case today.↩︎</p></li>
<li id="fn6"><p>Morbidly, we might also consider adding those surviving relatives of Anne Frank as keepers of the flame, without whose efforts and comparative luck Frank’s diaries might never have been read.↩︎</p></li>
<li id="fn7"><p>You gain £10. You feel better. You lose £10. You feel worse. But you feel about twice as bad for losing £10 - part of your endowment - than you feel good for gaining £10.↩︎</p></li>
<li id="fn8"><p>I’ve <a href="../../../posts/unpop/unrepentent-confessional/index.html">written previously</a> about my admiration for David Sedaris’ ‘unrepentant observational confessional’ style of writing, and stand by this assessment. More recently I rewatched the Netflix series <em>Baby Raindeer</em>, and was struck by the level of honesty, sympathy and nuance in that story: a protagonist victim who’s neither blameless nor flawless; and two victimisers who are depicted as having clear virtues despite their monstrous behaviour. It is, my my view, a work of exactly this type of artistic genius.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>books</category>
  <category>intelligence</category>
  <category>nonfiction</category>
  <category>reviews</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/the-what-is-a-genius-myth/index.html</guid>
  <pubDate>Mon, 18 Aug 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>More on the Stand Ident</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/more-on-the-stand-ident/index.html</link>
  <description><![CDATA[ 




<p><a href="../../../posts/unpop/no-longer-understanding/index.html">Previously I wrote</a> about how the main logo, ident or icon for the Stand comedy club in Glasgow and Edinburgh - a goofy child cowboy - became altered in a way that makes it politer, on the one hand, but symbolically meaningless, on the other. A bit like the British Petroleum rebranding as <strong>BP</strong>, and then declaring that these two letters now no longer stand for anything, the Stand’s goofy cowboy is still around, but in a sense no longer performs.</p>
<p>Anyway, walking around Edinburgh yesterday I chanced upon a little more background on the ident, the artist who painted it, and the fated juxtaposition that led the club to disarm the boy:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/more-on-the-stand-ident/stand-main.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stand Main Image</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/more-on-the-stand-ident/stand-text.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stand Text</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/more-on-the-stand-ident/stand-mini.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stand Mini</figcaption>
</figure>
</div>
<p>(I’d suggest it <em>seemed</em> like a great visual analogy for the performance of stand-up because it <em>is</em>.)</p>
<p>Anyway, now we know, and if you head to St Andrew Square Garden you can see this the giant poster, with much larger images, for yourself.</p>
<p>The QR code in the bottom right also works, and links to <a href="https://www.tdmacgregor.com/">Mac’s webpage here</a></p>



 ]]></description>
  <category>branding</category>
  <category>comedy</category>
  <category>edinburgh</category>
  <category>glasgow</category>
  <category>followup</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/more-on-the-stand-ident/index.html</guid>
  <pubDate>Sat, 02 Aug 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>It’s your choice</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/fiction/its-your-choice/index.html</link>
  <description><![CDATA[ 




<section id="waiting-area" class="level2">
<h2 class="anchored" data-anchor-id="waiting-area">Waiting Area</h2>
<p>Jim puts his head in his hands. Or at least he tries to. The hands don’t quite reach, arrested by the chains.</p>
<p>Jim lowers his head to his hands and groans.</p>
<p>The noise, all around, bad at the best of the times, and this isn’t the best of times. Noise, noise, noise from without, noise from within.</p>
<p>Jim doesn’t know why he’s here. Or at least that’s what he tells himself. Part of him - his guts, his spleen - knows <em>exactly</em> why he’s here. That’s why the other bits of him, the mouth and the tongue and the neck and the skull and the throbbing grey goo inside, would rather not listen to the insistent noises below.</p>
<p>“10872!”. A languid voice bellows with an indignant, officious tone. “10872!”</p>
<p>Jim remembers the coupon scrolled in his hand. Unfurling. Tongue moves softly, tracing the digits.</p>
<p>“won… oh … ate… seven… too!”</p>
<p>Jim stands, steps forward, trips over. Skull falls onto stained cyan carpet.</p>
<p>“You have to wait for an officer to unlock you,” the voice at the desk drawls. “We’re not exactly free range here.”</p>
<p>Jim pulls himself back into a jangly ball, pivots himself against the front of the bench, and hops to a stand.</p>
<p>The polyester shuffle gets louder, becoming a ring of keys.</p>
<p>“10872?” asks the mouth behind the ring.</p>
<p>“Erm, yeah!” confirms Jim.</p>
<p>“Up a bit.” Sleeves gesture at hands.</p>
<p>Jim obliges.</p>
<p>“Wait a bit. Hold it.” A tongue appears in the corner of the mouth. The keys start to circle around the ring, each engraved number scanned. “I think it’s this one,” says the mouth to itself. The ring is thrust, index key first, into Jim’s cuffs. “Hold it!”, the mouth repeats.</p>
<p>Twisting, grabbing, pushing, prodding. Then a turn. The tension drops from Jim’s wrists, from the cuffs to the ankles to the back of the bench.</p>
<p>“Follow me”.</p>
<p>Jim shambles along in the mouth’s wake.</p>
<p>“Is this an office or a jail?” Jim wonders to himself.</p>
<p>“Both,” answers the mouth. “Back in the day, just an office. Then there was that whole work-from-home craze, and then for a while it was nothing. Then it was a squat. And then it was ours.”</p>
<p>“Sorry, I didn’t realise I asked that out loud.”</p>
<p>“Your lot often doesn’t.”</p>
<p><em>My lot?</em>, wonders Jim.</p>
<p>“Anyway, of course the squatters didn’t want to leave.” The mouth licks its lips. “But then once they’d been convicted, they ended up here. And then the didn’t want to <em>stay</em>!” <strong>Bronchial spluttering</strong>. (Silence)</p>
<p>(Silence.)</p>
<p>(Silence.)</p>
<p>“Case adviser’s in there,” says the mouth. The polyester straight-arm salutes the door of an office in a box.</p>
<p>Jim looks at the mouth and the uniform.</p>
<p>“In there,” says the mouth.</p>
<p>Jim shambles <em>in there</em>, pushing open the door by knocking against the kickplate.</p>
</section>
<section id="outer-room" class="level2">
<h2 class="anchored" data-anchor-id="outer-room">Outer Room</h2>
<p>“Come in!” says the box’s occupant. “Come in! Come in!” A smile. Genuine. (You can see it in the eyes. And hear it in the voice.) The occupant wears a shirt, short-sleeved, crinkling slightly as he moves. Glasses, wire-framed. A moustache that looks like it used to be more distinctively zoned, whose boundaries are fuzzier against a half-week’s growth of pepper-grey hairs on cheek, chin and neck. His build is on the hard edge of soft. From his skin the man looks to be in his late thirties, pale, red threaded.</p>
<p>“Take a seat,” says the man, gesturing to a worn swivelchair.</p>
<p>Jim obliges.</p>
<p>“Hi!” says the man, extending his hand in greeting. “I’m Kevin; and I’ll by your CDSO during your visit here.”</p>
<p>“What’s a CDSO?” asks Jim.</p>
<p>“Sorry for the ETLA,” says Kevin, chuckling lightly to himself. “Case and Decision Support Officer.”</p>
<p>“Oh,” says Jim, seated.</p>
<p>“So,” says Kevin. “Have you thought some on The Decision? Any preferences? <em>TBJ</em>, or <em>TBO</em>?”</p>
<p>“What?!” exclaims Jim.</p>
<p>Kevin looks at Jim for a second. “You really don’t know. Haven’t you been following the news for the last couple of years? It’s been the big flagship policy the current lot came in on.”</p>
<p>Jim looks blankly.</p>
<p>“You really don’t know, do you?” Kevin pauses, recalling the form of words. “The TBO initiative was introduced to improve criminal justice outcomes for the three main stakeholders in our sector: the victim, the perpetrator, and the taxpayer. As I said, it’s the current lot’s big idea, and very popular with voters. After they did the pilot programme over in Northern Ireland they mostly sorted out the wrinkles and it got rolled out nationwide. And over there, next door, I’m pleased to tell you we’ve got one of our brand new TBO units, last safety inspection just six weeks ago, all prepped and ready to use.” Kevin pauses. “If you go for the TBO path, of course. <em>It’s your choice</em>.”</p>
<p>Jim looks more carefully at the room they’re in. Beyond and facing the nondescript office door he entered the room through is a second, much sturdier door, metal, by the looks of it much thicker, looking a bit like something that fit in a bank vault or a submarine.</p>
<p>Jim first realises that the room they’re in is more wide than long, as if it were just one third of an initially cuboid space.</p>
<p>Jim looks now at the wall in which the vault-like door is inset, and from the sturdiness and apparent thickness of the inner door infers that the entire wall is much thicker than the wall containing the office space. Jim notes that the vault-like door is inset slightly against the apparent contours of the wall, and from this infers that the inner wall itself is covered by a thin facade, chipboard perhaps, which has been papered and painted the same light green as the other three walls of the drably officious outer sanctum he currently understands himself to be sitting in. About halfway along the width of the wall, and about two fifths of the way down the wall, Jim sees a light curtain rail from which some light crimson drapes are suspended. Jim thinks he can make out some rivets recessed slightly behind the drapes.</p>
<p>“Yes!” says Kevin. “It’s all over there. We’re an integrated service here. Just a one minute walk, no delays.”</p>
<p>Jim turns back to face Kevin ‘behind’ the small desk. A very small desk, in fact, more like a coffee table, round, slightly to one side. On this small desk: a charging stand with a rubber-enclosed tablet computer, and a squatter, wider stand with the following words written, by the looks of it, in some professionalised derivative of comic sans.</p>
<blockquote class="blockquote">
<p>Kevin Peterson, PhD Senior Case/Decision Support Officer</p>
</blockquote>
<p>“What’s a per-her-der?” asks Jim.</p>
<p>Kevin grins. “Pee aitch Dee.” He pauses. “A doctorate (Too much time in school.) I got it in criminal psychology, about eight years ago. Back when a lot of this stuff was more theoretical.”</p>
<p>“Oh,” says Jim.</p>
<p>“Anyway, enough about me. This is <em>your</em> meeting. I’m here to support and guide you through your Criminal Justice Journey. This meeting is <em>your</em> meeting. It’s <em>your</em> Decision.”</p>
<p>“My decision?”, asks Jim.</p>
<p>“Yes.” Kevin exhales, then speaks more slowly and clearly, as if to a child or an invalid. “<em>TBJ</em>… <em>or</em>… <em>TBO</em>?” Kevin waits and stares.</p>
<p>Jim blinks.</p>
<p>“Let’s get your case file up…” Kevin picks up the tablet and starts prodding. After a few seconds he stops, eyes saccading, frowns, and forces his mouth back upright.</p>
<p>“So…” Kevin speaks deliberatively. He inhales. “You’re ‘accused’ of killing a cat, last night, at 1:03am, on King Street. As well as the usual drunk and disorderly.”</p>
<p>Jim’s eyes widen and start to tear up. “I’m accused of doing <em>what</em>?!” he exclaims. “But I love cats!”</p>
<p>“I said ‘accused’ with inverted commas,” Kevin clarifies, this time quivering the first two fingers of his free hand, like bunny ears, while saying ‘accused’. “With my TBO hat on, and my very similar looking Common Sense hat on, I can just say this: You killed a cat. You’ve done wrong. How are you going to make this right?”</p>
<p>Jim realises that Kevin’s face is now less than two hand lengths from his own, as with each of the previous fifteen words Kevin had heanty ever closer towards Jim’s eyes. Jim can smell the tuna sandwich that Kevin had for lunch.</p>
<p>Kevin straightens and backs up again, returning to a more comfortable distance. “Of course, from the TBJ perspective, you’re just ‘accused’ at this stage. ‘Innocent until proven guilty’, as they still sometimes say. But we’ve already got…” Kevin scrolls down on the tablet. “… three eyewitness statements, two Ring camera records (with audio), and blood and fur samples recovered from your right shoe and tracksuit bottoms.”</p>
<p>Only now does Jim realise he’s wearing open sandals he’s never owned, and this his trousers appear to be made of thick green paper.</p>
<p>“And of course,” Kevin continues, “we’ve got this recorded by the arresting officer at 1.42am last night…” Kevin jabs a button on the tablet.</p>
<p>“Oh my God!”, cries the tablet in Jim’s voice. “I’ve killed a cat! I’ve killed a cat! What the hell have I done?! I’ve killed a cat!”</p>
<p>“But of course,” continues Kevin, “statements made by intoxicated individuals aren’t considered especially high quality evidence. In isolation, it wouldn’t have been enough.”</p>
<p>Jim is a quietly heaving, deflated thing, arms draped awkwardly, face to floor, back round and quivering.</p>
<p>Kevin waits momentarily. “So,” he begins, “to repeat, you’ve basically got two options. (Well, technically two-and-a-half, I guess, but anyway…): You can go down the TBJ route, where you’re ‘just accused’ of all this (or you could plead guilty, the half option, but that’s not really too different to the TBJ path in practice). Or you could go down the TBO route, where you accept you did it, and it can all be resolved in the next hour.”</p>
<p>Jim arrests his sniffles and raises his head. “Wait… what day is it?”</p>
<p>“It’s Sunday, James.”</p>
<p>“Shit!”, says Jim. “I can’t miss work tomorrow. They’ll fire me.”</p>
<p>“Well,” says Kevin, “in that case the only chance you’ve got of getting to work tomorrow is the TBO route. We’re looking at a…” - Kevin prods the tablet - “… 22 month delay for trials.”</p>
<p>“And if I just plead guilty?”</p>
<p>“Even that’s quite backed up too. Currently we’re looking at a …” - more prodding on the tablet - “13 week delay to see a circuit judge to hear the plea.”</p>
<p>“Could I work while I wait?”</p>
<p>“We don’t do that anymore.” Kevin shakes his head. “You’d have to spend the wait in jail. Currently things are getting a little better there. You’ll be looking at..” - more prodding - ” 1.13 square metres (estimated average stay) to yourself while you’re with us. And you’ll be sharing a latrine with just 41 other guests.”</p>
<p>Jim pauses. In a half whisper he says, “I’ll pick TBO.”</p>
<p>“What’s that?” asks Kevin.</p>
<p>“I’ll pick TBO. I <em>did it</em>. I’ll choose TBO. I’m <em>choosing</em> TBO. Thank you!”</p>
<p>“Great!”, exclaims Kevin, jumping to a stand. “Let’s hope Algos and Stochastos are smiling today.” Kevin winks.</p>
<p>“Who?” asks Jim.</p>
<p>“The gods, Algos and Stochastos. Though they might sound a bit foreign they’re proudly made in Britain. First we’ve got Algos. He listens and weights…”</p>
<p>“Waits for what?” asks Jim.</p>
<p>“Not <em>waits</em>,” Kevin chuckles. “Weights! As in, like heavier or lighter, more weight to <em>this</em> side, or to <em>that</em> side. Algos, you see, he’s fair, and he listens. He listens to <em>The Chorus</em>, fifteen freshly picked members from the Good Citizens Panel. They look, they hear, they have a quick think, then they tell Algos what they reckon about what they’ve seen and heard.”</p>
<p>“Fifteen, like a big jury?”</p>
<p>“Technically a Chorus isn’t a jury. But they do have a quick look at some materials and try to answer and grade some questions. But unlike a jury they just tend to focus on grading the State’s evidence, rather than listening to those overpaid fools in white wigs drone on for days and weeks on end, and the witnesses getting asked silly questions by the white wig brigade.” Kevin pauses. “That way, the Chorus can usually get set up and grading done in under an hour, sitting in their dressing gown over a glass of red wine at home. It’s so much more of an efficient system than the old jury way of doing things.”</p>
<p>Kevin looks some more at the tablet, scrolls up and down. He looks at Jim with a wide smile, almost giddy. “And I’m pleased to tell you that the grading for your case has already been completed, and told to Algos, all while we were having this chat. The Chorus spoke, Algos heard, and the weighting’s been finalised. Now it’s just over to Stochastos for the final stage. Over there please!” Kevin gestures to the vault-like door.</p>
<p>Jim stands, walks over, and reaches for the thick door’s handle.</p>
<p>“It’s open,” says Kevin. “Just give it a light push.”</p>
<p>Jim does as instructed. The heavy looking door glides about its axis almost effortlessly. Jim takes a couple of tall steps to clear the threshold.</p>
</section>
<section id="inner-room" class="level2">
<h2 class="anchored" data-anchor-id="inner-room">Inner Room</h2>
<p>Inside, the room is covered - floor to wall to ceiling - in white tiles, with harsh, uniform lighting. The dimensions of this inner room are like those of the outer chamber, only a bit smaller, implying all walls of this door are of similar thickness to the vault door entrance. On the narrowest wall to his left a dark inset glass-like bulb is visible, jutting carefully from the wall. Something inside the bulb whirrs and lights up. A camera, operated elsewhere? Facing this presumed target-hardened camera, at the far side of the room, is a strange contraption of many parts.</p>
<p>At the top of the contraption is something like looks like a modified bicycle helmet held up by a thick, horizontal grey tube, coming out of the otherwise featureless wall to the left from Jim’s view. The helmet appears complete along the far side (the tube side), but parts are missing along its other side. Instead it looks adapted near the front and back to hold a currently loose, dangling pair of straps.</p>
<p>Below the modified bicycle helmet is something that looks like a patio chair with arm rests. The chair sits atop a height adjustable circular column, at the base of which are four concrete ‘feet’ which step astride - what is that? a gutter? - cutting deeper, and wider to the right than the left of the footed ‘pillar’ on which the seat sits. From Jim’s current position it’s difficult to know how deep the gully goes.</p>
<p>“There it is,” says Kevin, “Where Stochastos does her thing. Walk towards it. Check it out!”</p>
<p>“<em>Her</em> thing?” enquires Jim, stepping towards the garden throne contraption with a dream-like cadence.</p>
<p>“Call her Lady Luck if you like.” Kevin’s smile radiates through his voice. It sounds… warm. “Stochastos is her <em>Sunday Name.</em>”</p>
<p>Jim is now less than a metre and a half from the other end of the wall, and can see more of the Garden Throne and the gutter on which it bestrides. Now he can judge the depth and contours of the gutter more accurately. It almost looks like a sink, except inset into the ground, and instead of the back end finishing with a straight edge, it stetches back, under the four concrete ‘feet’ of the Garden Throne pillar, like the tail of a stingray.</p>
<p>Jim notices another feature on this end of the room. Opposite the bicycle helmet/tube contraption, on the opposing wall, an additional extra large, extra thick ceramic tile has been slotted against the wall, held in place by metal grooves on each side and below. The centre of this extra large, extra thick tile faces the centre of the tube holding the bicycle helmet.</p>
<p>“Take your throne,” says Kevin. “And I’ll adjust the height.”</p>
<p>Jim obliges, placing himself on the metal seat. There are arm rests with straps either side. Jim’s feet initially lay on the tile floor. Instinctively he swishes his feet forwards and backwards, like a child trying to escape gravity momentarily on a swing.</p>
<p>“For your safety,” says Kevin, “please place your arms within the security straps on each arm rest.”</p>
<p>Jim notices the arms are on top of the straps. Awkwardly he rearranges his limbs so the straps are above and the rests below.</p>
<p>“Now let’s get the right app up.” Kevin looks down at his tablet and swipes a few times, the edge of his tongue poking out one side of his mouth. “Ready now.” Kevin makes an assertive prod on his screen. The arm rests whirr and the straps tighten. They have some give, but not much. Jim now notices the impression of something, circular, indented, with a bit of give, beneath his right hand.</p>
<p>“Now let’s get the elevation sorted. (Unfortunately we can’t do pitch and yaw with this hot seat.)” Kevin chuckles to himself, stabs at his tablet. Servos whirr from below. Jim’s body shoots up, the top of his skull dabbing and now pressing, slightly uncomfortably, against the top of the helmet.</p>
<p>“This bit’s still manual. Let me help you.” Kevin walks up to Jim and the chair, his attention focused on the half metre strap that hangs and dangles from the pipe-end of the helmet. The tongue pokes out of the side of Kevin’s mouth again, and his brow furrows, as he reaches for the strap. “Hand-eye coordination. Never my strong suit.” Kevin mutters to himself, as he pulls and rotates the strap below and around Jim’s head. “Got it!”, Kevin says. The strap loops back down, back around Jim’s chin, and is secured a second time at its origin point. Kevin pulls down. Jim feels his head’s mobility has become much restricted. “Great,” says Kevin. “Safe and secure.” Kevin walks back and admires his manual labour.</p>
<p>“Now the next step: We just need to let the D Team know we’re ready for them.” Kevin pauses. “Luckily that’s just a button press as well, much like ordering a pizza.” Kevin looks at his tablet again, saccades, scrolls, jabs a couple of times, then theatrically moves his hand back, extends his forefinger, and presses firmly on the tablet one last time. Then, a couple of seconds later, he looks left, to the side of the room they did not enter from. Jim tries to do the same, but with his head secured only his eyes move.</p>
<p>Muffled sounds appear from behind the wall. It appears to be a conversation, though Jim cannot make out any words. Jim listens intently. The cadence sounds like a series of questions being asked, then answered with a simple affirmative or negative. The exchange lasts about twenty seconds. Then there is a pause, and then….</p>
<p><strong>Crunch! Thud!</strong></p>
<p><strong>Crunch! Thud!</strong></p>
<p><strong>Crunch! Thud!</strong></p>
<p><strong>Crunch! Thud!</strong></p>
<p><strong>Crunch! Thud!</strong></p>
<p><strong>Crunch! Thud!</strong></p>
<p>Six times! Each noise appears twice to Jim’s ears: in a muffled form, through the wall, to both ears. Then in a fainter, tinnier but oddly clearer form through the tube, through Jim’s right ear only. The sounds are ever so slightly out-of-sync, through clearly have the same origin.</p>
<p>“And six.” Jim notices that Kevin has been counting to himself. He’s smiling. Radiant with happiness even. Kevin notices that Jim has noticed him and offers a conspiratorial wink.</p>
<p>Kevin looks a picture of controlled mania in his expression, which he refuses to hide from Jim. “Unfortunately for this last big I’ve got to go back over there.” Kevin gestures at the room they came from. “Health and safety”, Kevin continues, as if quoting more than saying. “Ear damage,” he continues. “I even offered to sign a waiver…” Kevin drifts off. “But anyway, I’ve got to go back there.”</p>
<p>“Um, okay”, says Jim, trying to nod reassuringly, despite the strap under his chin.</p>
<p>Kevin makes a sheepish half-bow and steps back, turning and walking to the door, glancing back as he touches the handly, taking a cautious up-step to clear the threshold, bowing again through the door, turning, pulling the door through on the other side.</p>
<p>Jim hears the <strong>klang!</strong> of the door shutting, then the metallic scraping of the door mechanism being turned shut. Jim then hears some distant footsteps, behind the wall, moving towards him. Then he sees the curtains open up behind the viewing port. Kevin’s eyes are now looking at him behind the glass.</p>
<p>The eyes look down and sway slightly. A static jolt sounds through the room. Kevin’s voice follows.</p>
<p>“Hi Jim! Now, for this last bit you’ve just got to do a couple of things…”</p>
<p>“Erm, okay!” says Jim.</p>
<p>“Firstly, you should be able to feel a couple of things with your right hand. A couple of square-topped plastic things. You should just be able to see these too. They’re button covers.”</p>
<p>Jim glances down and feels with his hand. As described, both buttons are visible, both under clear plastic caps. Both buttons are lit from within, a bit like those fruit machines Jim remembers seeing in a museum. The left button is amber, the right button is red. Currently the left button is lit, shining a solid green light.</p>
<p>“The cover for the left button should now be flippable. Just take your first two fingers and feel for a catch just before the button itself. Press the catch in a bit and the cover should flip up, letting you press the button itself.”</p>
<p>Jim pauses. “Okay?”</p>
<p>Kevin pauses. “So can you press the catch release please?”</p>
<p>Jim does so. The catch springs up and away, revealing the green button as described.</p>
<p>Kevin’s mouth is not visible, but Jim can see from his eyes that he’s smiling. The tone of the voice in the intercom confirms this. “I’m sure you can guess the next step…”</p>
<p>“Open the other cover?” Jim asks.</p>
<p>“I guess I was wrong. No, next step is you <em>press</em> the green button.”</p>
<p>“Right. Sorry.” Jim’s forefinger reaches for the green button. Just like that antique fruit machine he feels the plastic surrounded by the metal ring. He presses the centre of the flat plastic surface down and feels a reassuring click. The light on the button changes instantly, from solid to flashing.</p>
<p>Then Jim hears something to his right. A rumbling rotary noise, clanging into action the moment Jim first pressed that button, then after a second whirring with what sounds (and feels) like an accelerating cadence. After about three more seconds the whirring sound has become a constant hum, speeding up no more. Jim listens to the rotary noise briefly. The hum flitters almost hypnotically, oddly reassuringly, almost a single tone, but not quite. Cycles within cycles.</p>
<p>“Great!” says Kevin through the intercom. Speaking with deliberate enunciation he continues. “Now just two last steps: open the right button’s catch, then press the button.”</p>
<p>Jim’s middle finger reaches for the cover catch on the right button’s cover, and presses down. Just like the first, the second button cover releases up and over. The unsheathed button is now flashing between two intensities of red light.</p>
<p>“Now press the red button. Or don’t. <em>It’s your choice!</em>”</p>
<p>Jim presses the button</p>


</section>

 ]]></description>
  <category>fiction</category>
  <category>satire</category>
  <category>thought experiments</category>
  <category>justice</category>
  <guid>https://jonminton.github.io/jon-blog/posts/fiction/its-your-choice/index.html</guid>
  <pubDate>Sun, 27 Jul 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>The Contestant</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/the-scapegoat/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/the-scapegoat/scapegoat-contestant.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The Contestant</figcaption>
</figure>
</div>
<p>As sites like <a href="https://ourworldindata.org/">Our World in Data</a> and books like <a href="https://en.wikipedia.org/wiki/The_Better_Angels_of_Our_Nature">The Better Angels of Our Nature</a> like to remind us, most of humanity has, materially, never had it so good. Gone are famine and infant mortality as experiential norms, gone even is the constant misery of tooth decay without effective dentistry. Through countless objective measures, for most of the world, for most of the twentieth and twenty-first century, the material conditions of life have continued to improve, the numbers of people alive to experience such improvements have continued to increase, and the gap between the poor and rich world (albeit as viewed on the logarithmic scale of dollars, tens of dollars and hundreds of dollars) has continued to decline.</p>
<p>But such evidence of continuing material progress - this decades-long Good News - seldom seems to be <em>felt</em> or to translate to clearly improved happiness and wellbeing amongst most of the population. Part of this relates to our perception of time and tendency to attend to the negative more than the positive: like climate change or the growth of a tree, material progress may just happen too slowly for us to see it; and evolutionarily it has been more adaptive to attend to the carnivorous predator than the juicy berries when both are in our environment. But much of this is likely related to hedonic adaptation and social comparison.</p>
<p>On hedonic adaptation: we <em>get used</em> to things maybe too quickly to appreciate how much better things are now than in the past. We get used to the world’s films and music being no more than a few clicks away on a magic brick, whereas our past selves would marvel at our current technology. The magic of the old becomes disenchanted and hum-drum, invisible to us except during its brief moments of failure: the wifi not connecting, the title being removed this week from the streaming service’s rota, and so on. We forget the technological magic of the present epoch, and so it quickly fails to make us happy.</p>
<p>Then there’s social comparison: mass media brought impressions of the rich, powerful, glamourous and beautiful onto the silver screen, then the living room, then the laptop, then to the palm of our hand. The lives and living standards of the most privileged fraction of a fraction of the top one percent of the world appear within touching distance. However, though we can see them, we can never be them. The screens through which we see their lives messes, in a profoundly harmful way, with our internal psychological architecture, encouraging ourselves to <em>compare ourselves with them</em>, and through this act of comparison almost always find ourselves lacking and wanting. Misery, the constant drip-feed misery of knowing how much less we are than them, emerges inevitably as a consequence.</p>
<p>Now, faced with this dilemma, those given to thought experiments - philosophers, effective altruists, other (often) autistic social systematisers - may be given to wonder the following: <em>what would happen if, instead of being constantly reminded of people with much more than us, we were instead constantly reminded of those with much less?</em> What if, instead of our ‘celebrities’ being persons whose lives we aspire to <em>attain</em>, instead our ‘celebrities’ were comprised exclusively of those whose lives we aspire to <em>avoid</em>?</p>
<p>Given our understanding of social comparison, we might might imagine a <em>hypothetical</em> world where our television and social media comprises accounts of the meek and miserable rather than the rich and glamourous as one where <em>almost everyone</em> would be happier. Why? Because <em>almost everyone</em>, no matter how hard life is for them, still has a better life than <em>that poor sod on the telly</em>. Mass media focusing on those with least, rather than those with most, would - from first principles - appear a <em>theoretically</em>, <em>hypothetically</em>, valid strategy for improving most people’s happiness without improving their material standing.</p>
<p>But here the thought experiment would end, because how else could this diet of misery and misfortune be sustained for the masses except by seeking out and keeping a few select people extremely miserable. What individuals, and what society, could tolerate inflicting and watching these anti-celebrities experience constant harm and hardship? Surely no civilised society would ever do this, or ever want to?</p>
<p>Well, that’s what I thought too: the anti-celebrity would forever (thankfully?) always remain a thought experiment. But then I saw a BBC documentary called <a href="https://www.bbc.co.uk/programmes/m002dt13">The Contestant</a>, which suggests that <em>in Japan, in the 1990s, the anti-celebrity thought experiment outlined above actually happened</em>!</p>
<p>The details of The Contestant are as described in the blurb linked to above. A young man, Tomoaki Hamatsu, ethnically Japanese but still ostracised in Japan due to his unusually long face, decides to try to lean into his distinct appearance and try to develop a public profile in Tokyo as a celebrity. He applies for a segment on a reality TV show that usually involves travelling in unfamiliar parts of the world, and is instead essentially kidnapped, taken to a very small apartment, and told to strip. The apartment includes thousands of blank postcards and aisle of magazines, and he is told he may not leave the apartment, and that the only food, clothes, or other items he can have access to are those he wins in magazine prizes.</p>
<p>The segment the contestant (unwittingly) stared in was called Life in Prizes, lasted over a year, and was routinely watched by over ten million Japanese people each week. Over this period, Hamatsu nearly dies of starvation and starts to go insane with loneliness. He is encouraged to document his thoughts and feelings on camera, and in a journal. The journals, describing his constant hunger and misery, his loneliness, his suicidal ideation, stretch to four volumes, and become best-sellers.</p>
<p>How could this have happened? Could it have happened anywhere else? I don’t know, but Hamatsu’s ordeal - and the absolute and unmitigated joy that tens of millions of Japanese felt at seeing his constant hardships week after week, does reinforce the idea for me that <em>Japan, amongst high income nations, is culturally distinct</em>. In Japan, at the time, was Haratsu’s ordeal considered <em>for the greater good?</em> One person’s suffering to make millions of people happier? Did Haratsu’s physical and psychological torture <em>actually</em> improve Japanese wellbeing, thus empirically verifying the results of what I thought could only ever be a thought experiment.</p>
<p>I just don’t know. Just that, unlike with most research, I hope this finding <em>doesn’t</em> get replicated.</p>



 ]]></description>
  <category>social comparison</category>
  <category>reality TV</category>
  <category>solidarity</category>
  <category>suffering</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/the-scapegoat/index.html</guid>
  <pubDate>Sat, 21 Jun 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Repeated Measures</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/handdrawn-stats/repeated-measures/index.html</link>
  <description><![CDATA[ 




<p><img src="https://jonminton.github.io/jon-blog/posts/handdrawn-stats/repeated-measures/mini-figure.png" class="img-fluid" alt="Title image"> I recently acquired a <a href="https://remarkable.com/products/remarkable-paper/pro">Remarkable Pro</a>, which for better or worse allows me to hand write and hand draw stuff for this blog, unconstrained by the dimensions of a physical page, and instantly turn those pages into images which I can put here.</p>
<p>Here’s what I’ve written about using random intercepts modelling for repeated measures data. (If there’s sufficient/any interest I’ll start tidying this up and converting some sections from handwriting to text.)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/handdrawn-stats/repeated-measures/Repeated Measures - page 1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">My ultra-long ‘page’</figcaption>
</figure>
</div>



 ]]></description>
  <category>statistics</category>
  <category>multi-level-modelling</category>
  <category>random-effects</category>
  <guid>https://jonminton.github.io/jon-blog/posts/handdrawn-stats/repeated-measures/index.html</guid>
  <pubDate>Mon, 16 Jun 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>No Longer Under-stand-ing</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/no-longer-understanding/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/no-longer-understanding/stand-new-ident.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The New Stand Ident</figcaption>
</figure>
</div>
<p>One of the few things Glasgow and Edinburgh share, other than latitude, is <a href="https://www.thestand.co.uk/">the Stand Comedy Club</a>, a chain of venues where both beginners can try their hand at stand-up comedy, and seasoned professionals can test out a minute or two of new materials to help decide whether it should make the cut and become part of a new set.</p>
<p>I’ve walked by both the Glasgow and Edinburgh venues many times, each time struck by their distinct ident, which looks as shown at the start of this post.</p>
<p>So, a goofy looking kid, dressed as a cowboy, grinning awkwardly in a harsh blue spotlight. The ident is familiar to me, but also not. It triggers, for me, my own variant of the <a href="https://www.britannica.com/science/Mandela-effect">Mandala Effect</a>, of distinctly remembering how the past used to be distinctly, definitively different to how it’s now presented as being and always having been.</p>
<p>Search online for The Stand (Edinburgh or Glasgow) and this same ident -the goofy, blue-light bathed cowboy kid - tends to get returned. It’s largely only my memory that tells me this ident wasn’t always this. It used to be different, in one specific but important way.</p>
<p>The Stand’s past has largely been erased. But not completely. <a href="https://www.bbc.co.uk/news/articles/cg3evpd5dvjo">This story from the BBC</a> shows how this ident used to be.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/no-longer-understanding/stand-old-ident.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stand Old Ident</figcaption>
</figure>
</div>
<p>This was the mural at the back of the stage. From memory (imperfect as it is) the bluetone ident was similarly different too. Originally, the ident for The Stand was a boy dressed as a cowboy, <em>with a revolver to his head</em>.</p>
<p>This one difference, to me, made all the difference. It said something, memorable engaging, harsh, arresting. And it said it instantly. What the original ident said to me was the following:</p>
<blockquote class="blockquote">
<p>If you go to The stand, you might see people <em>die</em> on stage. If you perform at the Stand, <em>you</em> might die on stage. You’ll die on stage because you weren’t prepared, because you’re just pretending to be able to do this to engage and entertain others - but you can’t really do this.. You are, in fact, just a cowboy. Not even a cowboy; a make-believe cowboy. However, because you’re just playing, don’t worry. You’re not a real cowboy, and what you’ve put up against your head isn’t a real gun, even if you do really put it up against your head and pull the trigger. You aim. You miss. You die on stage.</p>
</blockquote>
<blockquote class="blockquote">
<p>But you don’t actually die. After ‘dying on stage’, you’ll feel terrible. But then you get to slump off, put yourself together, and try to die a bit less next time. Eventually, you might even learn to become what you’re only pretending to be.</p>
</blockquote>
<blockquote class="blockquote">
<p>Perform at The Stand: The stakes are real. But they’re also just make-believe.</p>
</blockquote>
<p>Though I can understand why the revolver was deleted from the ident, all I can now think of when I see the new ident is the old ident: the ident that told a complex and arresting story in a single image, the ident that had meaning beyond its being a recognisable brand or identity. On its own merits, without its buried history, the new ident says or means very little, and isn’t something on its own I’d find very memorable. At most, I might just think “isn’t that just a cheap rip-off of <a href="https://www.tomrichmond.com/history-of-an-idiot/20/06/2017/">the Mad TV kid</a>?”</p>
<p><strong>Coda</strong>: <em>The Stand aren’t completely in denial about their past ident. I walked by the Edinburgh venue recently, and saw this poster. The clue’s in the cake!</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/no-longer-understanding/stand-cake.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stand in the Cake</figcaption>
</figure>
</div>



 ]]></description>
  <category>branding</category>
  <category>comedy</category>
  <category>edinburgh</category>
  <category>glasgow</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/no-longer-understanding/index.html</guid>
  <pubDate>Sat, 07 Jun 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Strangelove: On Love and (Civil) Warfare</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/on-love-and-civil-warfare/index.html</link>
  <description><![CDATA[ 




<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/on-love-and-civil-warfare/https:/resizing.flixster.com/D9xzJll3rjJVKP-7hJgTyRtBTVM=/fit-in/705x460/v2/https:/resizing.flixster.com/ETuDz44d0NgZuwQlOfh0NxJai1U=/ems.cHJkLWVtcy1hc3NldHMvbW92aWVzL2I5MTQ2Y2ExLWU3MTItNDExYy04ODkyLTI1NmY3NjZiYjRlNC5qcGc=" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Civil War (2024)</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/on-love-and-civil-warfare/https:/cms-assets.webediamovies.pro/cdn-cgi/image/dpr=1,fit=scale-down,gravity=auto,metadata=none,quality=85,width=2500/production/4756/6200035787b1cb331cda24eb60a9d18f.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Warfare (2025)</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p><strong>Warning</strong>: <em>Moderate spoilers for Civil War and Warfare</em>.</p>
<p>A few weeks ago I went to see Warfare, the latest film from Alex Garland, whose previous film, <a href="https://en.wikipedia.org/wiki/Civil_War_(film)">Civil War</a>, marked a departure from Sci-fi and towards more grounded speculative fiction. For Civil War, Garland want to achieve a strong sense of realism about the conduct and experience of war. Civil War was largely position from the margins of conflict, following a small team of war journalists trying to piece together enough of a sense of what was happening as to be able to report <em>something</em> informative and accurate to readers, a task challenging tiven the constant fog of confusion that had descended on the ‘United’ States, and hazardous becuase in this civil war there seemed to be no clear rules agreed about who was a legitmate target and who could peass peacefully.</p>
<p>A scene midway through the film brought both the confusion and hazard to focus: a small armed forces unit the team of journalists happens to be near gets fired upon from <em>somewhere over there</em>. Which side or faction the combat unit fights for isn’t clear; which side or faction the enemy forces represent also isn’t clear. For all the viewer knows (I <em>think</em>) this could be an instance of ‘friendly fire’. All we, the journalists, and the combat unit do know is that the bullets coming from <em>over there</em> represent a threat; and from the combat unit’s perspective it’s implicitly understood that such threats need to be mitigated or neutralised: years, months, or possibly weeks of training has drilled the unit into a standard response to such situations, a profocol for dealing with such situations has been triggered, and fire is returned.</p>
<p>The film ends with a military coup, an assault on the Capital and removal (read: execution) of a head of state some sides or factions consider legitimate and others not so. Throughout the film’s war scenes there is a focus on both experiential and procedural verisimilitude: combat units are well drilled professionals following well-rehearsed scripts for engagement. This was not the standard Hollywood Action fantasy in which one side who cannot aim is defeated by a one man army with preternatural luck and skill: Rambo is nowhere in this story. Instead, each troop undersands the inherent hazard in their job, but also proven tactics to mitigate such risks to their own side. Suppressive fire is employed so continually as to overwhelm the viewer’s senses, the sound design bringing out the explosive enormity of high caliber munitions, the sights and sounds of gunfire intended to minimise opportunity to return fire more so than take out specific targets: better a thousand of our rounds miss <em>them</em> than one of their rounds hits <em>us</em>. Once the White House is breached the nature of combat changes: a small team becomes a superorganism, wordless gestures turn training, troops and equipment into a mobile fortress, without blindspots, vigilant to threats from all directions.</p>
<p>To bring this sense of verisimilitude to Civil War, Garland employed Ray Mendoza, an Iraq War veteran, as military supervisor. Garland found Mendoza’s expertise in, for want of a better term, <em>warcraft</em>, and experiences of combat, so interesting and important as to lead to a wish for further collaboration. <a href="https://en.wikipedia.org/wiki/Warfare_(film)"><strong>Warfare</strong></a> was the result of this desire to collaborate further, with Mendoza co-writing and co-directing with Garland.</p>
<p>Whereas the scope for Civil War is continent-wide, and its story distopian speculation about a not-implausible future, Warfare’s scope is intentionally constrained and historically localised. The film defines itself as an attempt to recreate, as accurately as possible, an ‘incident’ of warfare, that was for a number of those involved life-altering in its mental and physical effects. The ‘incident’ took place in Iraq, in 2006, to a platoon that included Mendoza. Due in part to traumatic injuries suffered by many involved, and the effects such intense experiences can have on memory and the perception of events, the story is based on a tapestry of accounts and recollections from all involved, each individually partial and incomplete, but together likely the most accurate and authentic detailing of how events unfoled, and how they were experienced, it is likely humanly possible to reproduce.</p>
<p>The incident shows the results of when events don’t go as planned for the platoon, in some ways go from bad to worse. But iltimately, in some ways amazingly, and in large part due both to the troops’ ability both to execuate plans under the most challenging of circumstances, and to adapt and improvise when the situation demands it, there were no <em>platoon</em> fatalities, ‘only’ grievous and life-changing injuries.</p>
<p>Warfare is apolitical, which in the modern age may be an especially unpopular political position to take. The platoon are young men, set apart from the civilising and moderating influence of polite society. But they are also highly trained, highly drilled, and lavishly well resourced, professionals. As in Civil War, the sublimation of the individual, the conversion of individual soldiers into a Superorganism, is on full display. The troops are shown to have incredibly detailed understanding of the craft of warfare, the mastery and internalisation of processes and procedures, the if-then rules and memorised checklists of what ssteps to take, by whom, in the event of X, Y or Z. And as in Civil War, with access to overwhelming resource and firepower, the calculus again being that is is better to lose ten thousand bullets than a single platoon life, is shown to its full destructive extent.</p>
<p>Before watching the film, I heard <a href="https://www.youtube.com/watch?v=5k8vIyIVpTQ">a review from Mark Kermode</a>. In summary, Mermode offered a hackneyed three word cliche: “War is Hell”. Before watching the film I fully expected to draw the same conclusion. However, on seeing the film, and giving myself a little time to process the experience, my brain found itself drawn to a very different, albeit equally hackneyed, three word cliche: “Band of Brothers”.</p>
<p>Though it seemed to be a strange, even pathological, manifestation of it, the strongest underlying sentiment on display in the film was <em>love</em>. In particular, the psychological and emotional changes that can occur when a small group of young men are trained together, brought together, and find themselves in circumstances where they must survive together, or die together. In <em>Warfare</em>, the injury to one troop is experience as an injury to everone. In the most grevious, terrifying and chaotic of circumstances, ths strongest motivation that drives an individual to risking their own life was to save and preserve the life of a colleague. This - (pseudo-)fraternal love - was the hidden ingredient to the Superorganism behaviour first dispalyed in Civil War. Training and resourcing was a necessary but not sufficient condition for a group of hormonal teenabge boys and twenty-something men to become a cohesive fighting force, a Superorganism that puts its own survival, ultimately, ahead of all other aims and objectives. <sup>1</sup></p>
<p>This kind of love is not an unalloyed good, however. This kind of love is conditional and bounded: the love extends <em>only</em> to the platoon itself, not the Iraqi translators they work with, nor the innocent civilians whose houses the platoon requisition and ruin, nor the broader community that is shot at, nor their street which is turned into a rubbled warzone. This kind of love, together with the lavish resources that the platoon can call upon, can be an extremely powerful force, not necessarily for the good. At the end of the film, after the platoon has departed with most of their limbs and faculties intact, the residents and combatants, whose street the platoon had turned into a warzone, emerge from the devastation and rubble caused by the last hour of fighting. How many enemy compatant casualties has the platoon ‘scored’? It’s unclear. Have any of the residents’ ‘hearts and minds’ been converted by the platoon’s actions, and if so in which direction? The answer to this is probably clearer.</p>
<p>Warfare is an intentionally mypoic film telling an account - as good an account as can ever be told - of a particular incident from a particular point of view. This is by design, so cannot be a flaw if the film is taken on its own terms. There <em>is</em>, of course, a broader context to ‘the incident’, but these are well known and well rehearsed. Meshing the microscopic perspective of Warfare with the macroscopic perspective of whether it was ever wise to invade Iraq in the wake of 9/11 (especially when most of the ringleaders were from Saudi Arabia, which was never attacked) is a question orthogonal to that of whether those US troops who were sent to Iraq acted, by and large, with discipline, professionalism, and the myopic love of comradeship. Perhaps all we can conclude, ultimately, is that strategic misadventure and incompetence can be implemented with tactical precision and courage.</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In the film, the only time the platoon were are shown to breach standard operating procedure - to bend or break the rules - was to illegitimately authorise a second attempt to pick up the casualties.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>films</category>
  <category>war</category>
  <category>love</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/on-love-and-civil-warfare/index.html</guid>
  <pubDate>Fri, 23 May 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Three Computer Games for People who Don’t Play Computer Games</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/three-nongamer-games/index.html</link>
  <description><![CDATA[ 




<p>It’s a Bank Holiday. In my last few jobs - in the NHS, and in academia - Bank Holidays weren’t taken off by default. But in my current job Bank Holidays <em>are</em> holidays, though for my partner Bank Holidays are not. So, when we’re working differenet days, what better use of a free day than to bury oneself in a good game? Today I’ve mostly been playing a new game called The Blue Prince, which by no coincidence is a homophone on ‘blueprints’.</p>
<p>Many people don’t like computer games, both for good and bad reasons. Potentially good reasons include: the clear opportunity cost, the potential for motivation and energies that could be diverted more ‘productively’ to be instead vied to the mere shifting of electrons<sup>1</sup>; the predatory practices involved in profiting from many modern games, and in some cases their blending into gambling mechanics, especially mobile games; their contribution to snacking and physical inactivity<sup>2</sup>; the thematic preoccupation with violent power fantasies in many games. Some bad reasons include: the presumption that gaming develops no transferrable skills, and that gamers are mentally inactive; and that violent games lead to violent behaviour.</p>
<p>Amongst non-gamers, some of the above arguments can be shields, psychological defences against the lurking awareness that, if they were to start playing most games, they would likely be terrible at them, unable to know how to jump, move, interact with items, react quickly enough to events, and so on, and so would feel humiliated. So rather than risk facing humiliation, they denegrate an activity worth billions of dollars, and that entertains and brings a sense of joy and meaning to hundreds of millions of people.</p>
<p>The barriers to entry are genuine, however, and as games become faster and - in <em>some</em> ways - more sophisticated, they lead to the cultural divides between gamers and non-gamers only growing, to lived experiences and sources of joy and purpose becoming mutually incomprehensible.</p>
<p>Blue Prince, whose main ‘quest’ I managed to finish today, is one of just three games I can think of, from the last 20 or so years, that I can recommend wholeheartedly to non-gamers. Each of these three games is very different, but each presents a comprehensive, joyous and enriching experience to players, which crucially does not rely on the level of kinetic fluency, the ability to decode events and react very quickly - required to even tread water in the majority of games. So in an effort to bridge the New Two Cultures - the separation between gamers and non-gamers - here’s a brief overview of each of these three games:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Blue_Prince_(video_game)"><strong>The Blue Prince</strong></a>: The Blue Prince was made largely by one person, Tondor Ros, who was inspired by an obscure 1985 puzzle book called Maze. The book was a choose-your-own-adventure story involving a mysterious house that can only be traversed by following a series of cryptic clues, in which the adventurer must reach the 46th room of the 45 room house. The Blue Prince takes this core premise and adds atmospheric sound and graphics, arcane storytelling, layers and levels of puzzlesolving, and most importantly <em>stochasticity</em>,<sup>3</sup> meaning no game is exactly the same. The puzzles range from the clearly specified to the cryptically implied, from those which play out room-by-room to those which build up slowly across successive games, and from those that tax one’s linear and logical faculties to those which require creativity and lateral leaps. And although demanding on those faculties that might be exercised by players of sodoku puzzles and cryptic crossword, there are no demands on dexterity or reaction time, and no violent or graphic content.</li>
<li><a href="https://en.wikipedia.org/wiki/Disco_Elysium"><strong>Disco Elysium</strong></a>: Disco Elysium is a 2019 adventure game produced by a small Eastern European games company called ZU/AM, and based on lore and ideas developed in a book called <em>Sacred and Terrible Air</em> by its lead designeer Robert Kurvitz, itself based on complex gameworld he developed with friends over many years. It is not just a game: it is narrative art. It is a rich, creative, undisciplined, cutting, poignant, elegaic, bittersweet book disguished as a game, and uses magical realism to try to make sense of the Eastern European sociocultural experience of the 20th Century: the state of being an individual in a state that is always acted upon by outside forces and political ideologies, that is predominantly object and not subject in outside battles. It is also the story of a broken man, haunted by the past, both guided and misdirected by a chorus of Jungian archetypes who swell up from within his psyche, and who forever try and pull the protagonist towards their ideals. In moderation, balanced out by other archetypes, each voice within can offer wisdom. But if one voice within ever becomes too loud then it drowns out its peers, leading the protagonist to pathology, embarassment and harm.<sup>4</sup> Disco Elysium is the antidote to standard power fantasy cliches: the protagonist’s present and future boxed in by the chains of their personal biography from before, by grand sociopolitical and even metaphysical forces acting from without, and by the chorus howling from within. Disco Elysium is set on another world, with a painterly expressionist style throughout and elegaic instrumentals swelling softly as our broken hero trudges through a quietly broken world. But in terms of its treatment of psychology, and politics, and the links between the two, it’s one of the most realistic works of fiction I’ve ever encountered.</li>
<li><a href="https://en.wikipedia.org/wiki/Plants_vs._Zombies"><strong>Plants vs.&nbsp;Zombies</strong></a>: PvZ is a 2009 tower defence game. You are in charge of a house, a lawn, and some magical seeds, and you use the seeds to populate the lawn with various type of plant, with a view to holding off a very-slow moving, and very cute, zombie invasion. Although this is the only of the three games that can reasonably be described as ‘real time’, in that events occur to the player without the player causing them to happen, the pace is slow enough, and the controls simple enough, that the technical barriers to entry are very low. Of all the games I’ve ever played, PvZ is the only game my partner has played, and became enthusiastic about playing. For a few months many years ago, due entirely and exclusively to this game, my partner and I had gaming in common. What set up PvZ apart from other tower defence games includes the generousity and richness of what’s included with the game,<sup>5</sup> the comic premise and off-kilter humour, the gentle challenge of the gameplay, and the extremely charming music.</li>
</ul>
<p>So, three games I can recommend to non-gamers. Each accessible, each very different, each brilliant.</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Only a <em>potentially</em> good reason both because many forms of paid employment are, viewed from enough distance, also ‘just’ involve shifting electrons; and because similar opportunity costs are also present in many other, non-gaming and non-electronic hobbies, such as stamp collecting or going for hikes.↩︎</p></li>
<li id="fn2"><p>Again, not necessarily different to many desk jobs, especially those that are fully remote.↩︎</p></li>
<li id="fn3"><p>The name for games that are somewhat random in this way, in effect procedurally generated, is <em>roguelike</em>. For those of a certain age and background, a good shortcut for understanding The Blue Prince is <em>Roguelike Myst</em>.↩︎</p></li>
<li id="fn4"><p>And to the extent the protagonist can effectively die of shame, embarassment and harm can be one and the same.↩︎</p></li>
<li id="fn5"><p>Though nongamers over the age of fifty might assume the most harmful aspect of games might be moral corruption due to interactive portrayals of violence criminality, I think a much stronger case is the introduction of <em>fremium</em> mobile phone games, in which an initially ‘free’ game uses full-scale psychological warfare to effectively ‘trick’ gamers into ploughing hundreds of pounds, micropayment by micropayment, into games seldom worth more than ten pounds. Unfortunately these highly predatory and dangerous games are likely to look amongst the least objectionable and harmful, and are often marketed towards children. When did the Fremium Turn begin? Sometimes between 2009, when Plants vs Zombies was released, and 2013, when Plants vs Zombies 2 was released. Whereas PvZ was for home PCs, so players had to make a conscious and sustained decision to play it, PvZ was mobile only, making it much easier to start a game almost without realising it. And where as PvZ cost a fixed price, and game with a lot of content, PvZ 2 starts nominally ‘free’, but after a few hours of play pesters players with adverts to new characters and areas, each time ‘just’ costing a pound or two. If the player doesn’t part with real cash, the game then intentionally becomes tedious and bad until they change their mind. Between 2009 and 2013, between PvZ and PvZ2, the gaming industry’s moral compass got replaced with a legion of barbed iphone apps.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>games</category>
  <category>puzzles</category>
  <category>stories</category>
  <category>bank holidays</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/three-nongamer-games/index.html</guid>
  <pubDate>Sun, 04 May 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Mickey 17 and the Economics of Life</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/mickey-17-and-the-economics-of-life/index.html</link>
  <description><![CDATA[ 




<p>A few weeks ago I saw Mickey 17 at the local cinema. It’s a fantastically frustrating colloid of a film, combining some extremely interested philosophical and sociological concepts with some characterisations and performances that lack the verisimilitude of cartoon characters, and tiresome plot beats and action spectacles that seem the cost of doing business when producing a sci-fi film above a certain budget. The filmy separation between the profound and the ridiculous usually being Mark Ruffalo’s face. Ruffulo’s performances seem to channel Austen Powers era Mike Myers, but lack both Myers charisma and self-awareness, his every moment on screen causing my toes to curl and my perception of time to dilute towards infinity.</p>
<p>Setting aside the terrible aspects of the film - and I <em>am</em> trying to - at heart Mickey 17 follows some fascinating premises into some interesting places. In Mickey 17 a two-part solution to mortality has been invented. Bodies, and minds, can now be recorded and reproduced with perfect allacrity, the bodies manufactured by 3D bioprinters, the minds and memories constantly backed up and downloaded to newly fabricated bodies whenever the last living body happens to expire. Because of this new technology, nobody need ever die ever again.</p>
<p>So far, so sci-fi-standard-fare. What are Star Trek’s teleporters, for example, but mechanisms for making replicates of recently existng bodies and minds, albeit with the thrice coupled technology of perfect annihilation of the body in the original location - so as to skim over most of the awkward dilemmas and paradoxes raised by such a device?</p>
<p>Where Mickey 17 departs from the usual cliches, however, is in exploring the sociological ripples such a technology might produce. After initial enthusiasm, Humanity quickly turns hostile on the technology, its uses, and becomes focused on its potential for abuse. The legal ramifications of certain edge cases - such as who might be criminally liable when two or more copies of an individual are fabricated and coterminously exist - are judged too head-spinningly confusing, and so this existence-shattering Pandora’s Box, the solution to death itself, is by consensus and agreement firmly shut again, almost everywhere that humans call their home.</p>
<p>Almost, but not completely. There are some people for whom, and some places where, immortality is still permitted. Neither the places nor the people are envied. The places are the rough edges of civilisation; the people: the unerclass of these inhospitable frontiers.</p>
<p>Because, in Mickey 17, immortality is a <em>curse</em>, something only the indigent and desperate would ever agree to be exposed to. The title character, Mickey (or Mickey 1, perhaps), is deep in debt, and the creditors are impatient, violent, sadistic gangsters. Mickey needs money, and needs to be gone, and so volunteers to work on an advance party being assembled to settle a newly discovered ice planet. Each party member’s station on the ship and colony will be an exaggerated variant of their station at home. Mickey, with less than nothing on Earth will therefore have less than nothing many times over in the colony.</p>
<p>What does this look like? Well, Mickey signs a contract, to work the dirtiest and most dangerous jobs that need to be done, jobs so nasty, and so dangerous, than no one else will touch. Worse: not event death is considered a valid excusal from fulfilling the terms of the contract in full. If (when) Mickey dies, he’s simply reprinted and told to go back to work tomorrow. In the universe of Mickey 17, far from being a profoundly positive development, the solution to death has becomes a means of inventing something like the dalit class from the Indian caste system, and combining this with intentured servitude, creating opportunities for debt bondage so inescapable that even death itself cannot break it.</p>
<p>Though little is made in the film of this association, in Mickey 17 the value of a life seems to be determined by the laws of supply and demand. When life is finite and death is final, life is valuable and precious. By contrast, for the Immortal Space Dalits, for whom life is plentiful and death merely an inconvenience, life is very cheap and so very unimportant. Like any other commodity, therefore, the value of a life falls as its supply increases, such as to become worthless once its supply becomes infinite.</p>
<p>Skip forward from this premise one or two hours (to reiterate, time dilates whenever Mark Ruffalo starts chewing scenery) and the film ends. A social revolution has occurred on the colony, and Mickey regains his humanity. How? (<strong>SPOILER ALERT</strong>) By pressing down on a plunger that destroy’s the one remaining replicator, and with this his curse of immortality. Mickey, like everyone else, now has just one life, one precious and finite life, and commits to live it as best as he can.</p>
<p>Though featuring a mostly Anglo-American cast, Mickey 17 was written by a South Korean director. It is of course both reductive and fruitless to do so, but I do wonder whether the idea, that immortality could be more of a curse than a blessing, may be easier to entertain for someone not raised in a broadly Judeo-Christian culture than for someone who has. Abrahamic faiths have faith in the Soul, that Cartesian separation from the physical realm that is doctrinally considered the True, Immortal Self that only briefly inhabits a physical vessel, a vessel that, in Christian theology at least, is seen to bring the Soul only weakness and temptation. By contrast, my crude sense is that East Asian theology is much more centred around Animism and Ancestor Worship (notwithstanding Christianity’s popularity in South Korea), in which there seems less focus in immortality of the individual, because the individual themself is less fundamental to how people see themselves and the world they enter. Each individual already has something greater than themself to live in relation to, namely the family, their so-far immortal and unbroken chain of ancestors that lived before and gave rise to them, their household and their household of households. Or their Symbolic Family, whether it be Emperor and ethnonation, Corporation, or other form of Dear Leader. The need to serve - to work with diligence and loyalty towards the binding network of relations in which one was born - and to seek immortality through genes and other obdurate societal contributions made in life, rather than through the Immaterial Soul - is perhaps more readily assumed in such cultures than in the Anglo-American West.</p>
<p>Personally, I’ve never found the concept of a Soul even desirable, let alone scientifically plausible. What would or a could a soul even be but some kind of driver without a vehicle? Imagine possessing those qualities of consciousness, memory and sense of self, and with this the impulse to decide, but with absolutely no means of executing such decisions or expressing preference for doing one thing over another. And imagine this quality of being a bystander, to always see and think, but never to be able to act or change things from how they were always going to be, and imagine this being a state of existence that stretches from the Big Bang to the Heat Death of the Universe. Who would want that? Why would anyone want that, either for themselves or for those they knew?</p>
<p>The alternative - that the capacity for consciousness stops when the body stops - can’t be a <em>bad</em> alternative. It is of couse the state of consciousness that all but a near-infinitesimal fraction of the universe has or will ever manifest, and that for any configuration of matter that was or will ever be possessing of consciousness, will or has only possessed such a state for only an infinitesimally tiny fraction of the time it has existed. To consider non-being in this way as a bad state is to place a negative valence on almost the entirety of all that ever was, is, and will ever be.</p>
<p>And from what we now know about the quality of lived experience, we know that consciousness, in people, seems to be something of a sliding scale rather than a simple binary switch. Of course there’s the obvious case of sleep, especially non-REM sleep, where consciousness has subsided to near nothingness. But two other, contrasting, states of waking life are also illustrative: the Default Mode Network (DMN), and Flow States.</p>
<p>The Default Mode Network (DMN) describes the stereotypical patterns of coactivation and inhibition of brain regions observed while people are, for need of a better term, ‘idle’ or ‘doing nothing’, i.e.&nbsp;not engaged in a particular form of mental or physical activity. When in the DMN, people are in fact almost never ‘doing nothing’, their brains tend to be very active, very much in contrast to some states of sleep and meditation. And what tends to be the nature of this DMN activity? Put crudely: <em>running simulations</em>, imagining selves acting in the world, in different environments and with different people in those environments, in different ways, and imagining the different responses their actions will produce in each scenario. And then, after having simulated enough scenarios, trying to make decisions about how to act by comparing the expected outcomes of each scenario.</p>
<p>The Flow State, by contrast, defines how the brain works when engaged in total pursuit of a single task or activity, an activity that is teetering on the edge of an individual’s present abilities. The DMN and Flow State tend to be either-or: one’s brain and body cannot be ‘somewhere else’, planning and deciding about future things to be doing, when it is fully engaged in demanding activities in the current moment.</p>
<p>Crucially, the DMN and Flow State also tend to differ systematically both in terms of how <em>enjoyable</em> they are, and how <em>conscious</em> persons tend to be in each state. For most people, most of the time, the DMN is <em>not</em> an enjoyable or restful experince, but it is a very <em>conscious</em> experience. Often, though we may imagine the purpose of the DMN to be to make better decisions about the future, our simulations are about the past: about things that happened, where we acted a particular way and a particular outcome was realised, where instead we keep imagining ourselves having acted differently, and the outcomes turned out better. There’s a word for this: <em>regret</em>. The DMN is at least as much a state of regret and rumination as it is a state of planning and decision-making. The DMN is also perhaps the state in which we are <em>most</em> conscious, continually evoking the notion of the self, in order then to throw it into a series of simulated scenarios, most of which result in some degree of harm, frustration or insult.</p>
<p>Conversely, in Flow States, the degree of consciousness tends to be much lower. The self - that body and mind <em>doing</em> - is already <em>doing the thing</em>, and so does not need to be constantly evoked and attended to with the deliberative intensity of the DMN.</p>
<p>And in the Flow State, that state of being a <em>being doing</em> rather than <em>being deliberating</em>, affect tends to be highly positive rather than negative.</p>
<p>Once again, if there were an immaterial soul, a bundle of self-conscious consciousness, attending to itself and deliberating about itself constantly, the experience of such a soul would likely be closer to that of the DMN rather than the Flow State. This is broadly what I mean by stating that the soul should not be something we desire to be true, even if it were more scientifically plausible. (As an example of what such a state might be like, think of the chilling poetic justice meted out to the ultimately villainous and tragic protagonist in Being John Malkovich: a puppeteer without a puppet, forever to exist as a by stander, lacking even the agency to blink.)</p>
<p>Ultimately, then - and this may be another idea harder for those in Western Society to countenance - the continuation of a singular consciousness may not be a prize worth valuing and escalating to theological cornerstone. If so, what instead <em>is</em> something we should cherish and value, something that constitutes a more clearly positive quality that distinguishes the experience a member of the species <em>Homo Sapiens sapiens</em> in the Twenty-First Century?</p>
<p>I would suggest the answer in <em>memory</em>; more specifically, the layering of different kinds and qualities of memory available to us, including those that appear largely unique to Humanity.</p>
<p>Let’s start with the means of remembering we have in common with other animals: we have <em>brains</em>, and we have <em>genes</em>. For a single animal, a past expereince - at least those experiences that prove non-fatal, can be recalled - or re<em>felt</em> - leading to changes in future behaviour: once bitten, twice shy. It’s these past experience that populate the overgrown simulation machines in our pre-frontal cortices - that enables and often locks us into our DMNs. Both other animals have this form of memory, and to an extent also the capacity to deliberate on future actions given lived history.</p>
<p>And then there are genes, which reside in our bodies and propagate selectively based on the success with which they have solved those existential problems our ancestors repeatedly encounter, for hundreds, thousands, or even millions of years. The genes of humans and other animals are records of our deep past: they are what Richard Dawkins described as biological ‘books of the dead’, in his book <em>The Genetic Book of the Dead</em>. Dawkins made clear where the metaphor - of genes as books - needs qualifying. For the most part, Dawkins suggested, genes in organisms are <em>palimpsests</em>, in which the contents of pages are overwritten, rather than simply added or deleted. But genes <em>are</em>, <em>clearly</em>, a form of very deep memory.</p>
<p>Books, of course, bring us to our third form of memory: <em>cultural</em>. And it seems in our degree and variety of cultural memory and media that we really do seem unique by comparison with other andimals. Before there was the written word, there was the spoken word, and with this a means of human groups remembering for potentially hundreds of years, and so of some form of communication to occur between two people who never existed at the same time - such as a boy knowing something impactful, that once happened to his great, great, great grandmother, who died generations before the boy was born.</p>
<p>Oral records mutate, having much less fidelity than genes, and so the level of accuracy with which the generation 1 mother’s experiences are recalled to generation 5 boy is likely to be quite low. However the processes by which stories and their elements are conveyed intergenerationally is itself likely to be far from random. To the extent that factual accounts evolved through cultural transmission into myths, and myths tend to have points of commonality even where groups have been separated for hundreds of years, we can infer something about the human mind, and the central characteristics and aspects of stories that tend to be memorable and impactful, that ring out through the ages. The biases and distortions of oral storytelling tell us not so much about what happened a few dozen or hundred years ago, but about our common selves, and so an important axpect of our deep genetic heritage.</p>
<p>The written word, of course, allows for high fidelity communication and continuity over far more records than the spoken word allowed (at least, until the present era, where perhaps people born hundreds of years in the future will be able to see and hear exerpts of ourselves). The echoes of the past are partial - both in the sense that the symbols alone lose the texture of the context in which they emerged; and also because most people ahve been illiterate, and so largely voiceless through this medium. But the written word is a means through which polished thoughts, from minds in bodies that have long since perished, can live an active afterlife whose reach and influence can be orders of magnitude greater than were ever achieved by the author while alive.</p>
<p>And where words do contain knowledge, ways of better understanding the world, through either science or art, the written word, and other written accounts, mean that each new generation is able to start from a better place than the last. Written records, those obdurate living fossils of past struggles and solutions, those cystallised records of deep thought, are both what fundamentally separates Humanity from the species <em>Homo Sapiens sapiens</em>, and the <em>other</em> means, along with DNA, through which those who have died can continue to support and influence those whom they are survived by.</p>
<p>The written records isn’t just art and science, however, and indeed the most impactful form of written record that surve their originators may be neither. The oldest written records perhaps ever identified were inscriptions on clay tablets (I think?), which become knwon as Linear B. For decades after being unearthed the contents remained a mystery, because the language was too unrelated to anything previously decoded. Once this ancient sipher was finally cracked the records turned out to be neither philosophical treatis nor scientific theories, but <em>accounts</em>, detailing <em>who owned or owed what to whom</em>. Such records of ownership may sound like an anticlimax, but is is through such records that the fruits of enterprise (and, more often, luck) can be passed alongside genetic lineages: it is through knowing who owes and owns what, and once deceased how such assets should be allocated, that the Household emerges as an entity that self-refreshes and propagates through the generations. The Household is neither a purely genetic nor purely social construct, but a symbiosis of these two forms of deep memory: <em>genes</em>, and <em>logos</em>. The death of a household member <em>might</em> lead to the death or mortal wounding of a household. But with sufficient commitment to the principles of succession it need not do so. Like the Ship of Theseus, Households, and dynastic lineages thereof, can survive in one form or another for hundreds or thousands of years, bound together by both kinship, and conventions, and codefied legal documentation.</p>
<p>All of which is, in a roundabout way, my explantion for why I consider memory, rather than consciousness, to be the more important means through which the dead live beyond life. It’s perhaps also why the core tenet of Mickey 17 - that immortality, a lack of closure of the consciousness of an individual, may be not a prize worth striving for, and may even be a curse - was so intriguing for me.</p>
<p>For those precious few who’ve read this far, and the even fewer who read previous posts to this blog over the last few months, it should be clear enough that this post isn’t really a review of Mickey 17 at all (Although, to repeat, the premises really are fascinating, and Mark Ruffalo’s performance really is terrible). Instead, it is another of an occasional series of my attempts to think carefully about the life, death, and various forms of secular ‘afterlife’ left by my father, whom I suspect would, being more of a fan of space swashbucklers and the silliness they entail, have enjoyed Mickey 17 in a less ambiguous way than I did. The fundamental idea - that life is precious because rather than despite it being finite - is something I will try to remember, even if there are other aspects of the film I would prefer to forget.</p>



 ]]></description>
  <category>films</category>
  <category>sci-fi</category>
  <category>life</category>
  <category>economics</category>
  <category>soul</category>
  <category>memory</category>
  <category>genes</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/mickey-17-and-the-economics-of-life/index.html</guid>
  <pubDate>Thu, 17 Apr 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Time and (state) change</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index.html</link>
  <description><![CDATA[ 




<p><em>Things change.</em></p>
<p>That’s the essence of a whole range of phenomena that people want answers to, and so statisticians and data scientists need to model. More specifically, we’re interested in situations where something changes from <em>one thing</em> to <em>another thing</em>, and the main factor that causes this change is time.</p>
<p>In this post I’m going to outline some thoughts on different scenarios we might want to model involving things changing. This is very much an exercise in writing to think, so don’t expect what I’m going to cover to be exhaustive, nor necessarily organised how it would be if I weren’t exploring and developing ideas while I write them. Nonetheless, I hope this will be useful. Let’s begin.</p>
<section id="this-and-that-then-and-now" class="level2">
<h2 class="anchored" data-anchor-id="this-and-that-then-and-now">This and that; then and now</h2>
<p>Let’s start with four cells, arranged in a two-by-two table.</p>
<div id="tbl-two-by-two" class="anchored">
<table class="table">
<caption>Table&nbsp;1: Four cells; two by two</caption>
<thead>
<tr class="header">
<th></th>
<th>Y</th>
<th>Not Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>X</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>Not X</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>
</div>
<p>In Table&nbsp;1, we have four cells: <img src="https://latex.codecogs.com/png.latex?M%20=%20%7Ba,%20b,%20c,%20d%7D"> separated by a row margin <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5C%7B1,%200%5C%7D"> and a column margin <img src="https://latex.codecogs.com/png.latex?Y%20%5Cin%20%5C%7B1,%200%20%5C%7D"> . Imagine further these cell values take natural numbers, i.e.&nbsp;positive integers. How does this help us?</p>
<p>Well, imagine now that one of the margins relates to one of two consecutive time periods <img src="https://latex.codecogs.com/png.latex?T%20%5Cin%20%5C%7BT_0,%20T_1%5C%7D"> (Say, last week, and this week), and the other margin relates to two mutually exclusive states that a person can be, such as <em>sick</em> or <em>not sick</em>. In Table&nbsp;2 we now have some data arranged in a simple structure that allows us to model some data where time has an influence on state change.</p>
<div id="tbl-two-by-two-time" class="anchored">
<table class="table">
<caption>Table&nbsp;2: Four cells; two by two. One margin is time-based</caption>
<thead>
<tr class="header">
<th></th>
<th>Last Week</th>
<th>This Week</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sick</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>Not Sick</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>
</div>
<p>What sorts of model? Well, with aggregate cells like this, we can run something like the Fisher Exact Test or Chi-Squared Test. This will answer questions like, <em>was last week really any different to this week</em> in terms of probability of being or becoming sick? Implicitly, this will work towards answering the question <em>Are the odds of becoming sick this week (<img src="https://latex.codecogs.com/png.latex?b/d">) really any different from the odds of becoming sick last week (<img src="https://latex.codecogs.com/png.latex?a/c">)?</em> They will do so by calculating an <strong>Odds Ratio</strong> (OR) (<img src="https://latex.codecogs.com/png.latex?a/b/c/d">), and - for the Chi-Squared Test at least - comparing it to a theoretical distribution where no one margin has an excessive ‘pull’ on the value of cells in the other margin. This <em>can</em> be a useful thing to do. When the cells are small, just a few events can give the impression something has changed between last week and this week in terms of sickness ratios. But maybe nothing fundamentally has changed; we’ve just had some bad/good luck?</p>
<p>Let’s now think about pivoting from this two-by-two cell in two different ways:</p>
</section>
<section id="same-model-more-states" class="level2">
<h2 class="anchored" data-anchor-id="same-model-more-states">Same model; more states</h2>
<p>One simple expansion of the above scenario is when the number of mutually exclusive states across one of the margins is more than two. For example, if the number of mutually exclusive states that an individual can be in is more than two, then we might want to expand one of the margins, as in Table&nbsp;3:</p>
<div id="tbl-three-by-two-time" class="anchored">
<table class="table">
<caption>Table&nbsp;3: Six cells; three by two. One margin is time-based</caption>
<thead>
<tr class="header">
<th></th>
<th>Last Week</th>
<th>This Week</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Very Sick</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>Quite Sick</td>
<td>c</td>
<td>d</td>
</tr>
<tr class="odd">
<td>Not Sick</td>
<td>e</td>
<td>f</td>
</tr>
</tbody>
</table>
</div>
<p>The same tests we used before can also help on this occasion. Compared to last week, the proportion of people who become sick in any way this week ((b+d)/(b+d+f)) might not be any different to last week ((a+c)/(a+c+d)), but the proportion of those who are sick who become very sick (b / (b+d) compared with a / (a+c)) might have changed in appreciable and detectable way. For example, maybe the virus that caused the sickness has got no better or worse at infecting people, but it’s better adapted to people, so once it’s infected them it tends to make them less sick?</p>
<p>Once again, the same tests that work with two-by-two cells can also work with three-by-two cells. In fact they can work with an arbitrarily large number of cells; the only condition is that each margin partitioning the cells are mutually exclusive and exhaustive. So, they can work with three mutually exclusive time periods, leading to a three-by-three table shown in Table&nbsp;4:</p>
<div id="tbl-three-by-three-time" class="anchored">
<table class="table">
<caption>Table&nbsp;4: Nine cells; three by three. One margin is time-based</caption>
<thead>
<tr class="header">
<th></th>
<th>Two Weeks Ago</th>
<th>Last Week</th>
<th>This Week</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Very Sick</td>
<td>a</td>
<td>b</td>
<td>c</td>
</tr>
<tr class="even">
<td>Quite Sick</td>
<td>d</td>
<td>e</td>
<td>f</td>
</tr>
<tr class="odd">
<td>Not Sick</td>
<td>g</td>
<td>h</td>
<td>i</td>
</tr>
</tbody>
</table>
</div>
<p>In this example, the standard contingency table cells will ‘work’, though they might not be the best approaches to use anymore. There’s information we have that the modelling approach doesn’t incorporate. This is that the possible values each margin can take are <em>ordinal</em>: <em>very sick</em> is more sick than <em>quite sick</em>, and <em>quite sick</em> is more sick than <em>not sick</em>. Similarly, <em>last week</em> was more time ago than <em>this week</em>, and <em>two weeks ago</em> was more time ago than <em>last week</em>. So, we know that the margins are both <em>ordinal</em>, whereas most modelling approaches involving contingency tables (i.e.&nbsp;these tables to cells in margins) deal with <em>categorical data</em>. As <a href="https://en.wikipedia.org/wiki/Contingency_table">Wikipedia</a> states:</p>
<blockquote class="blockquote">
<p>The relation between ordinal variables, or between ordinal and categorical variables, may also be represented in contingency tables, although such a practice is rare. For more on the use of a contingency table for the relation between two ordinal variables, see Goodman and Kruskal’s gamma.</p>
</blockquote>
<p>Let’s now pivot things the other way.</p>
</section>
<section id="constant-change" class="level2">
<h2 class="anchored" data-anchor-id="constant-change">Constant change</h2>
<p>Let’s move back to a scenario where an observation can take only one of two mutually exclusive and exhaustive states, such such as sick or not sick. And say we’re fairly confident assuming that the probability of moving from one of these states to the other, over a fixed time period, doesn’t change over time. We can then start to think about modelling risks of something that accumulate over time.</p>
<p>More concrete: let’s say we think the risk of someone who’s healthy becoming sick each week is 2%, and we’re interested in understanding the proportion of a population who become <em>ever sick</em> over time. Although the weekly risk of becoming sick doesn’t change, the cumulative risk of becoming ever sick keeps growing.</p>
<p>Let’s adapt our thinking, and so our categories, slightly, to model this kind of question. Let’s start by imagining a population of people who are healthy at the start of a period of time, <img src="https://latex.codecogs.com/png.latex?T%20=%200"> AKA <img src="https://latex.codecogs.com/png.latex?T_0">. Let’s say there are 10,000 people who start off healthy at <img src="https://latex.codecogs.com/png.latex?T_0">. With a weekly risk of becoming sick of 2%, we know by <img src="https://latex.codecogs.com/png.latex?T%20=%201"> 2% of the 10,000 have become sick. They’re now no longer part of the ‘never sick’ (since the start of the observation period <img src="https://latex.codecogs.com/png.latex?T=0">) population, so the never sick population has declined by 2%. Now as we move to the next time period, <img src="https://latex.codecogs.com/png.latex?T%20=%202">, the weekly risk of becoming sick has stayed the same, but the population size of ‘never sick’ has fallen. To work out the proportion of the initially never sick population who were never sick we now need to apply the 2% getting sick risk to the <em>remaining</em> never-sick population. For later time periods we have to repeat, each time a constant percentage risk applying to an ever-diminishing never-sick population ‘stock’. Let’s call <img src="https://latex.codecogs.com/png.latex?N_0"> the initial population of never-sick persons, <img src="https://latex.codecogs.com/png.latex?N(t)"> the number never-sick at time period <img src="https://latex.codecogs.com/png.latex?t">, and <img src="https://latex.codecogs.com/png.latex?p"> the proportion who become sick each time period.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?N(0)">: <img src="https://latex.codecogs.com/png.latex?N_0"></li>
<li><img src="https://latex.codecogs.com/png.latex?N(1)">: <img src="https://latex.codecogs.com/png.latex?N_0%20(1%20-%20p)"></li>
<li><img src="https://latex.codecogs.com/png.latex?N(2)">: <img src="https://latex.codecogs.com/png.latex?N_0%20(1%20-%20p)(1%20-%20p)"></li>
<li><img src="https://latex.codecogs.com/png.latex?N(3)">: <img src="https://latex.codecogs.com/png.latex?N_0%20(1%20-%20p)(1%20-%20p)(1%20-%20p)"></li>
<li><img src="https://latex.codecogs.com/png.latex?N(4)">: <img src="https://latex.codecogs.com/png.latex?N_0%20(1%20-%20p)(1%20-%20p)(1%20-%20p)(1%20-%20p)"></li>
</ul>
<p>etc.</p>
<p>Another way of presenting this is in terms of a process being applied to the last state:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20N(t)%20=%20N(t-1)(1%20-%20p)"></p>
<p>For <img src="https://latex.codecogs.com/png.latex?t%20%5Cge%201">, and <img src="https://latex.codecogs.com/png.latex?N(0)%20=%20N_0">. Here <img src="https://latex.codecogs.com/png.latex?N(t-1)"> refers to the value at the last state, and <img src="https://latex.codecogs.com/png.latex?(1%20-%20p)"> happens to be the process applied to the last state for each time period.</p>
<p>And a third way involves simply recognising that all of the five statements in the expanding block above can be represented as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20N(t)%20=%20N_0%20(1%20-%20p)%5Et%20"></p>
<p>Each of the three above representations of the process over time highlight something different: the first makes it clearer that there’s a growing (expanding) influence of history on each further time period after <img src="https://latex.codecogs.com/png.latex?t%20=%200">, as the number of terms involved in calculating each future period’s terms gets larger. The second makes it clearer that, conditional on knowing the last period’s value, and the starting value, the rule for calculating future values is consistent and straight forward. And the third representation has the benefit of algebraic simplicity and neatness; on this occasion the algebra are such that, even without having the calculate all intermediate values in the series, we can calculate <img src="https://latex.codecogs.com/png.latex?N(t)"> for any value of t.</p>
</section>
<section id="forgetting-deep-history" class="level2">
<h2 class="anchored" data-anchor-id="forgetting-deep-history">Forgetting (Deep) History</h2>
<p>Of the three representations shown above, the type that suggests an approach generalisable to other phenomena involving the influence of time is the second. I described this as representing ‘a process applied to the last state’, which we can represent in more general terms as something like the following:</p>
<p><img src="https://latex.codecogs.com/png.latex?N(t)%20=%20f(.)N(t-1)"></p>
<p>Here <img src="https://latex.codecogs.com/png.latex?N(t)"> represents the state of something now, <img src="https://latex.codecogs.com/png.latex?N(t-1)"> the state of something in the recent past, and <img src="https://latex.codecogs.com/png.latex?f(.)"> represents the process applied to the recent past, such as to generate the present state. I’ve included a dot as a placeholder in this process function to make it clear that, potentially, this process can be heterogeneous in its effects, rather than, as with the present example, always the same over time. The process could, for example, be varying with regards to population characteristics <img src="https://latex.codecogs.com/png.latex?X">, such as when different population subgroups are at different risk of becoming sick. It could also be varying over time, <img src="https://latex.codecogs.com/png.latex?t">, such as a risk that either grows, declines, or varies non-monotonically with regards to time. This algebraic chassis is quite flexible in terms of the specific types of phenomena it can be used to model.</p>
<p>The important feature of this kind of equation is that, to represent the state at any time <img src="https://latex.codecogs.com/png.latex?t">, only the state at time <img src="https://latex.codecogs.com/png.latex?t-1"> needs to be known. This means that, from the perspective of the equation itself, the influence of history more than one chain or iteration in the past, <img src="https://latex.codecogs.com/png.latex?t-2">, <img src="https://latex.codecogs.com/png.latex?t-3"> and so on, is known only through the value at time <img src="https://latex.codecogs.com/png.latex?t-1">. In a sense, the equation has no longer term memory beyond the recent past; it takes things as they are and evolves them just one step further.</p>
<p>There’s a name for this kind of process: <strong>Markovian</strong>, with a process of modelled change that represents the near future only in terms of the present, or the present only in terms of the recent past, being described as having <em>the Markov property</em>. If the Markovian assumption can be made, then the computation of future states can proceed mainly through short, simple steps of iterative influence along a chain. The computation burden becomes relatively small, with a trade-off being that the memory burden of tracking the chains generated by this process through time become much larger. This is even more so the case when working, as statisticians need to, with <em>stochastic processes</em> involving <em>uncertainty</em>. Both inherent stochasticity in a process of evolving change, and uncertainty about the true/best value to place inside the process part of the equation <img src="https://latex.codecogs.com/png.latex?f(.)">, mean uncertainty and variation in the process being applied. For example, instead of the proportion becoming sick each cycle being exactly 2%, it could be some proportion that is 2% <em>on the average</em> (i.e.&nbsp;its <em>expected value</em> is 2%), but some times is higher, and sometimes is lower. This means that on each occasion chain is built connecting <img src="https://latex.codecogs.com/png.latex?t=0"> to <img src="https://latex.codecogs.com/png.latex?t=T">, the period for which we want to estimate <img src="https://latex.codecogs.com/png.latex?N(.)">, the chain will be different. Cute analytic solutions, such as the formula <img src="https://latex.codecogs.com/png.latex?N(t)%20=%20N_0%20(1%20-%20p)%5Et">, won’t be readily available to help us, because, in this example, <img src="https://latex.codecogs.com/png.latex?p"> is now a series of draws from a distribution, rather than a fixed value. Because of this variation in the process function <img src="https://latex.codecogs.com/png.latex?f(.)"> being applied each time, the go-to approach for representing a plausible range of expected values of <img src="https://latex.codecogs.com/png.latex?N(T)"> is to generate a large number of chains from <img src="https://latex.codecogs.com/png.latex?t=0"> through to <img src="https://latex.codecogs.com/png.latex?t=T"> and summarise the range of the distribution of <img src="https://latex.codecogs.com/png.latex?N(T)"> produced, such as to show the median, mean, standard deviation, and 95% empirical intervals (the values 2.5% from the bottom and 2.5% from the top of the distribution of estimates).</p>
<p>What we have here, in this part of the discussion, is a reintroduction to <strong>time series</strong> modelling, as covered extensively in previous posts. The simple autoregressive model <code>AR(1)</code> is a clear example of a Markovian process, but so are other specifications in the ARIMA family. ARIMA models, as discussed, can be more or less ‘forgetful’: they can have terms for states two or more periods ago, rather than just the last period, and with the SARIMA extension, they can also accommodate seasonal patterns in the data too. But at heart they all start with the kind of equation at the start of this section: a process was applied to how things were in the recent past, to make things as they are now.</p>
</section>
<section id="to-transition-or-to-absorb" class="level2">
<h2 class="anchored" data-anchor-id="to-transition-or-to-absorb">To transition or to absorb?</h2>
<p>Let’s return to the example where there are three mutually exclusive states that an observation can take for each time period. And say we also believe the probability of <em>moving to</em> each state at time T, <em>conditional on knowing the state</em> at time T-1, is non-varying. Let’s call <img src="https://latex.codecogs.com/png.latex?Y(t)"> the state at time <img src="https://latex.codecogs.com/png.latex?t">, and <img src="https://latex.codecogs.com/png.latex?Y(t-1)"> the state at time <img src="https://latex.codecogs.com/png.latex?t-1">. And let’s say <img src="https://latex.codecogs.com/png.latex?Y(.)%20%5Cin%20%5C%7Ba,%20b,%20c%5C%7D">, i.e.&nbsp;that all observations of Y, for all time periods, will always be one of either state a, state b, or state c.&nbsp;</p>
<p>To start to turn this into a model of state change, we need some data arranged in something like a contingency table (Table&nbsp;5), where one margin shows the possible states last period, the other margin shows the possible states this period, and the cells therefore show the counts of cells that were in the last period margin, and are in the this-period margin.</p>
<div id="tbl-three-by-three-markov" class="anchored">
<table class="table">
<caption>Table&nbsp;5: Nine cells; three by three. Cells are counts; row margins are last period; column margins are this period</caption>
<thead>
<tr class="header">
<th></th>
<th>a</th>
<th>b</th>
<th>c</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a</td>
<td><strong><img src="https://latex.codecogs.com/png.latex?n_%7Baa%7D"></strong></td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bab%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bac%7D"></td>
</tr>
<tr class="even">
<td>b</td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bba%7D"></td>
<td><strong><img src="https://latex.codecogs.com/png.latex?n_%7Bbb%7D"></strong></td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bac%7D"></td>
</tr>
<tr class="odd">
<td>c</td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bca%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?n_%7Bcb%7D"></td>
<td><strong><img src="https://latex.codecogs.com/png.latex?n_%7Bcc%7D"></strong></td>
</tr>
</tbody>
</table>
</div>
<p>If we refer to the row margins by the index <img src="https://latex.codecogs.com/png.latex?i">, and the column margins by the index <img src="https://latex.codecogs.com/png.latex?j">, then the subscripts of the cells are of the form <img src="https://latex.codecogs.com/png.latex?n_%7Bij%7D">. This means that <img src="https://latex.codecogs.com/png.latex?n_%7Bba%7D">, for example, is shorthand for ‘number of observations who were in state <img src="https://latex.codecogs.com/png.latex?b"> last period, and are in state <img src="https://latex.codecogs.com/png.latex?a"> this period’.</p>
<p>Note there are fundamentally two different things that can happen over these two time periods: either the state can <em>stay the same</em>, or it can <em>change</em>. In the above, the cells <img src="https://latex.codecogs.com/png.latex?n_%7Baa%7D">, <img src="https://latex.codecogs.com/png.latex?n_%7Bbb%7D">, and <img src="https://latex.codecogs.com/png.latex?n_%7Bcc%7D">, which are on the top-left-to-bottom-right-diagonal of the matrix, are examples where the state did not change between the two time periods, whereas all other cells, where the two subscripts are of different letters, represent <em>transitions</em> from one state to another.</p>
<p>We can go from observed counts (the <img src="https://latex.codecogs.com/png.latex?n">s) to <strong>transition probabilities</strong> by summing up the row margins, then dividing the cell counts by these margins. We can define these margins as follows:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?N_%7Ba%7D%20=%20n_%7Baa%7D%20+%20n_%7Bab%7D%20+%20n_%7Bac%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?N_%7Bb%7D%20=%20n_%7Bba%7D%20+%20n_%7Bbb%7D%20+%20n_%7Bbc%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?N_%7Bc%7D%20=%20n_%7Bca%7D%20+%20n_%7Bcb%7D%20+%20n_%7Bcc%7D"></li>
</ul>
<p>The transition probabilities for each cell indexed <img src="https://latex.codecogs.com/png.latex?%5C%7Bi,%20j%5C%7D"> are therefore the cell values divided by the corresponding row margin, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?p_%7Bij%7D%20=%20n_%7Bij%7D%20/%20N_i">. By definition, the sum of probabilities across any row is 1.</p>
<p>The result of calculating all transition probabilities in this way, while preserving them in the three-by-three square matrix presented above, is called a <strong>transition matrix</strong>. Let’s call this <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7BP%7D">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctextbf%7BP%7D%20=%0A%5Cbegin%7Bpmatrix%7D%0Ap_%7B1,1%7D%20&amp;%20p_%7B1,2%7D%20&amp;%20p_%7B1,3%7D%20%20%5C%5C%0Ap_%7B2,1%7D%20&amp;%20p_%7B2,2%7D%20&amp;%20p_%7B2,3%7D%20%20%5C%5C%0Ap_%7B3,1%7D%20&amp;%20p_%7B3,2%7D%20&amp;%20p_%7B3,3%7D%0A%5Cend%7Bpmatrix%7D%0A"></p>
<p>The transition matrix is something we can use with our process evolution equation <img src="https://latex.codecogs.com/png.latex?N(t)%20=%20f(.)N(t-1)"> introduced earlier, substituting in for <img src="https://latex.codecogs.com/png.latex?f(.)">. To set it running, we need to specify a starting population <img src="https://latex.codecogs.com/png.latex?N_%7B0%7D">, which on this occasion is not a single value, but a <em>vector</em> of values of length equal to the dimensions of <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7BP%7D">; in this case, three:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AN_0%20=%20%5C%7Bn_%7B1,%200%7D,%20n_%7B2,%200%7D,%20n_%7B3,%200%7D%20%5C%7D%0A"></p>
<p>With this initial population state specified, we now have a working version of the process evolution equation that we can iteratively apply to successive outputs in order to project the population distribution out to an arbitrarily large number of iterations ahead. This relies on some matrix algebra. In the code above I’ll try to provide an example of this in R</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-2"></span>
<span id="cb1-3"></span>
<span id="cb1-4">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb1-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb1-6">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb1-7">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, </span>
<span id="cb1-8">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb1-9">    ), </span>
<span id="cb1-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb1-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb1-12">)</span>
<span id="cb1-13"></span>
<span id="cb1-14">N_0 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> init_pop</span>
<span id="cb1-15"></span>
<span id="cb1-16">N_1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> N_0 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Note %*% is matrix multiplication</span></span>
<span id="cb1-17">N_2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> N_1 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix </span>
<span id="cb1-18">N_3 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> N_2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix </span>
<span id="cb1-19">N_4 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> N_3 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix </span>
<span id="cb1-20">N_5 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> N_4 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix </span>
<span id="cb1-21"></span>
<span id="cb1-22">states_over_time <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbind</span>(N_0, N_1, N_2, N_3, N_4, N_5)</span>
<span id="cb1-23"></span>
<span id="cb1-24">states_over_time</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       [,1]    [,2]    [,3]
N_0 700.000 200.000 100.000
    630.000 210.000 160.000
    583.000 221.000 196.000
    552.300 230.100 217.600
    532.630 236.810 230.560
    520.203 241.461 238.336</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rowSums</span>(states_over_time)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> N_0                          
1000 1000 1000 1000 1000 1000 </code></pre>
</div>
</div>
<p>In the above, the first column shows the projected number in state a at the time period indicated by the row, with the first row being the initial population composition, the second the projected composition at T=1, and so on. The call to <code>rowSums()</code> confirms that, within each time period, the total population size stays the same, even though the subpopulation in each state keeps changing.</p>
<p>The above process of iteratively evolving the subpopulation composition over time can be repeated an arbitrarily large number of times, which may lead to compositions converging towards a final state or equilibrium that depends much more on the transition matrix than the initial composition. In the code below I’m going to attempt to run the above for 100 cycles, rather than just five, and then plot the changing composition as an area chart.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb5-2"></span>
<span id="cb5-3">init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb5-4"></span>
<span id="cb5-5"></span>
<span id="cb5-6">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb5-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb5-8">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb5-9">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, </span>
<span id="cb5-10">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb5-11">    ), </span>
<span id="cb5-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb5-13">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb5-14">)</span>
<span id="cb5-15"></span>
<span id="cb5-16">pop_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb5-17">pop_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> init_pop</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"C"</span>)</span>
<span id="cb5-20"></span>
<span id="cb5-21">N_periods <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(pop_matrix)</span>
<span id="cb5-22"></span>
<span id="cb5-23"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N_periods){</span>
<span id="cb5-24">    pop_matrix[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb5-25">}</span>
<span id="cb5-26"></span>
<span id="cb5-27">pop_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-28">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-29">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-30">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb5-31"></span>
<span id="cb5-32"></span>
<span id="cb5-33">pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>state)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-35">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_area</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-markov-nonabsorbing" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-markov-nonabsorbing-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Nonabsorbing three state Markov model</figcaption>
</figure>
</div>
</div>
</div>
<p>In Figure&nbsp;1 we can see that the proportion in each of the three mutually exclusive states converges to an equilibrium level fairly soon after the simulation has started, after around 10 of the 100 cycles in the model have run. It is usually the case, with Markov modelling, that in the long term the transition matrix matters more for the long-term population distribution than the initial population. As an example, here’s the same model run again, but where all of the population initially start off in state C:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb6-2"></span>
<span id="cb6-3">init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb6-4"></span>
<span id="cb6-5"></span>
<span id="cb6-6">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb6-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb6-8">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb6-9">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, </span>
<span id="cb6-10">        <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb6-11">    ), </span>
<span id="cb6-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb6-13">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb6-14">)</span>
<span id="cb6-15"></span>
<span id="cb6-16">pop_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb6-17">pop_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> init_pop</span>
<span id="cb6-18"></span>
<span id="cb6-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"C"</span>)</span>
<span id="cb6-20"></span>
<span id="cb6-21">N_periods <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(pop_matrix)</span>
<span id="cb6-22"></span>
<span id="cb6-23"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N_periods){</span>
<span id="cb6-24">    pop_matrix[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb6-25">}</span>
<span id="cb6-26"></span>
<span id="cb6-27">pop_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-28">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-29">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-30">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb6-31"></span>
<span id="cb6-32"></span>
<span id="cb6-33">pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>state)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb6-35">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_area</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-markov-nonabsorbing-alt-init" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-markov-nonabsorbing-alt-init-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Three state non-absorbing Markov model with different initial population distribution</figcaption>
</figure>
</div>
</div>
</div>
<p>Once again, the 100 cycles over which the simulation runs is more than enough for the effect of the initial population composition to ‘wash out’. (This is, by the way, similar to much Bayesian modelling relying on Markov Chains, in which an initial set of possible values for each of the parameters to be estimated has to be specified, the first ‘prior’, and there is a hope or expectation that, regardless of the initial values specified, parameter model chains will converge on the same distribution. For this reason it is common practice with Bayesian modelling to perform Bayesian modelling on multiple chains, each with different starting value sets, and check that the chains generated from each starting value have converged to the same distribution.)</p>
<section id="absorbing-states" class="level3">
<h3 class="anchored" data-anchor-id="absorbing-states">Absorbing states</h3>
<p>Let’s now adapt the initial population vector and transition matrix very slightly, to include a 4th state, <img src="https://latex.codecogs.com/png.latex?D">. Look carefully at the code below to see how the transition matrix this time differs from the transition matrix used previously.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb7-2"></span>
<span id="cb7-3">init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span> , <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb7-4"></span>
<span id="cb7-5">pAD <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span></span>
<span id="cb7-6">pBD <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span></span>
<span id="cb7-7">pCD <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb7-8"></span>
<span id="cb7-9">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb7-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb7-11">        (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, pAD,</span>
<span id="cb7-12">        (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, pBD,</span>
<span id="cb7-13">        (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pCD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pCD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pCD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, pCD,</span>
<span id="cb7-14">        <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-15">    ), </span>
<span id="cb7-16">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, </span>
<span id="cb7-17">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb7-18">)</span>
<span id="cb7-19"></span>
<span id="cb7-20">pop_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb7-21">pop_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> init_pop</span>
<span id="cb7-22"></span>
<span id="cb7-23"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"C"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D"</span>)</span>
<span id="cb7-24"></span>
<span id="cb7-25">N_periods <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(pop_matrix)</span>
<span id="cb7-26"></span>
<span id="cb7-27"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N_periods){</span>
<span id="cb7-28">    pop_matrix[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb7-29">}</span>
<span id="cb7-30"></span>
<span id="cb7-31">pop_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-32">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-33">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb7-35"></span>
<span id="cb7-36"></span>
<span id="cb7-37">pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-38">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>state)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb7-39">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_area</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-fourstate-markov-oneabsorbing" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-fourstate-markov-oneabsorbing-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Four state Markov model with one absorbing state</figcaption>
</figure>
</div>
</div>
</div>
<p>For Figure&nbsp;3 I’ve doubled the number of cycles, from 100 to 200. The initial population composition is exactly the same as in the example two chunks ago. But over time the proportion of the population that exists in the new state, D, keeps growing. If the number of cycles were increased further still, then by the end pretty much everyone would be in state D. Why is this?</p>
<p>Let’s look carefully at the 4th row in the transition matrix, corresponding to the transition probabilities of moving to each of the four states in the next cycle conditional on being in state D in the current cycle. This row is written as <img src="https://latex.codecogs.com/png.latex?%5C%7B0,%200,%200,%201%5C%7D">, meaning the conditional probability of moving from state D to any other state is 0. This wouldn’t matter, except there’s a <em>nonzero</em> (albeit low) probability of moving <em>to</em> state D from any other state. D is a state that, each cycle, some of the population can enter. But like the Hotel California, once they’ve checked into this state they can never leave.</p>
<p>The technical term for a state with D’s transition matrix properties is an <strong>absorbing state</strong>; by this definition all other states can be referred to as <strong>nonabsorbing states</strong>. A more intuitive way of representing state transition relationships is through a diagram, where each state is represented as a circle or similar, and each transition probability represented as a line connecting the circles. For example, a diagram of the three state example, with no nonabsorbing states, would look something like this:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<div>
<pre class="mermaid mermaid-js">%%{
    'theme': 'darkMode'
}%%
    flowchart TD
        A --&gt;|pAA| A 
        A --&gt;|pAB| B 
        A --&gt;|pAC| C  
        B --&gt;|pBA| A
        B --&gt;|pBB| B  
        B --&gt;|pBC| C  
        C --&gt;|pCA| A  
        C --&gt;|pCB| B 
        C --&gt;|pCC| C 
</pre>
</div>
</div>
</div>
</div>
<p>By contrast, the four state version, with absorbing state D, would look more like the following:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<div>
<pre class="mermaid mermaid-js">%%{
    'theme': 'darkMode'
}%%
    flowchart TD
        A --&gt;|pAA| A 
        A --&gt;|pAB| B 
        A --&gt;|pAC| C  
        A --&gt;|pAD| D
        B --&gt;|pBA| A
        B --&gt;|pBB| B  
        B --&gt;|pBC| C
        B --&gt;|pBD| D  
        C --&gt;|pCA| A  
        C --&gt;|pCB| B 
        C --&gt;|pCC| C
        C --&gt;|pCD| D
        D --&gt;|pDD = 1| D 
</pre>
</div>
</div>
</div>
</div>
<p>Here we can see that, though there are arrows going into D, the only arrow going out of D then goes to.. D, and has a probability of 1. State D takes, but never gives back.</p>
</section>
</section>
<section id="survival-at-its-simplest" class="level2">
<h2 class="anchored" data-anchor-id="survival-at-its-simplest">Survival at its simplest</h2>
<p>A transition model can be specified with just two states - one absorbing; the other nonabsorbing - and with an initial population entirely in the nonabsorbing state. Let’s look at the following example of this:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb8-2"></span>
<span id="cb8-3">init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb8-4"></span>
<span id="cb8-5">pAB <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span></span>
<span id="cb8-6"></span>
<span id="cb8-7">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb8-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb8-9">        <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAB, pAB,</span>
<span id="cb8-10">        <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-11">    ), </span>
<span id="cb8-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, </span>
<span id="cb8-13">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb8-14">)</span>
<span id="cb8-15"></span>
<span id="cb8-16">pop_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb8-17">pop_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> init_pop</span>
<span id="cb8-18"></span>
<span id="cb8-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>)</span>
<span id="cb8-20"></span>
<span id="cb8-21">N_periods <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(pop_matrix)</span>
<span id="cb8-22"></span>
<span id="cb8-23"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N_periods){</span>
<span id="cb8-24">    pop_matrix[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb8-25">}</span>
<span id="cb8-26"></span>
<span id="cb8-27">pop_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb8-28">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb8-29">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb8-30">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb8-31"></span>
<span id="cb8-32"></span>
<span id="cb8-33">pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb8-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>state)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-35">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_area</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-survival-as-markov" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-survival-as-markov-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Simple survival modelling using Markov models</figcaption>
</figure>
</div>
</div>
</div>
<p>Does this look familiar? It should, because it’s the same scenario described in the Constant Change section above. There are two states: A and B. Everyone (10,000 people) starts off in state A, each cycle there’s a 2% probability of transitioning from A to B, and B is an absorbing state. The state transition model above is just another way of representing the same phenomena, even though it’s seldom used in this way.</p>
<p>And what’s the canonical example of a phenomena where the above properties hold: i.e.&nbsp;everyone starts off in one state, there are only two states, one of which is absorbing, and each time period there’s a probability of going from the nonabsorbing to the absorbing state? Well, that would be when we label the two states as follows:</p>
<ul>
<li><strong>A</strong>: <em>Alive</em></li>
<li><strong>B</strong>: <em>Dead</em></li>
</ul>
<p>So, a two state transition model with one absorbing state <em>is</em> a simple case of survival modelling.</p>
<p>Survival modelling, contrary to inital expectations, does not have to be applied only to matters of life and death; it can be applied to any two state scenario where one state <em>can be considered</em> absorbing. The operative term here is <em>can be considered</em>. Look carefuly again at the phrasing I used in the Constant Change section above:</p>
<blockquote class="blockquote">
<p>More concrete: let’s say we think the risk of someone who’s healthy becoming sick each week is 2%, and we’re interested in understanding the proportion of a population who become <em>ever sick</em> over time. Although the weekly risk of becoming sick doesn’t change, the cumulative risk of becoming ever sick keeps growing.</p>
</blockquote>
<p>Although health and sickness are transient, non-absorbing states, by defining the problem in terms of an initially healthy cohort of persons who become <em>ever sick</em>, I reframed the scenario into one in which survival modelling is appropriate. <em>Ever sick</em> is an <em>absorbing state</em>, because the alternative to this is <em>never sick</em>, and once someone has become sick once they are never <em>never sick</em> again, even though if their health were tracked again they would likely enter and leave periods of better and worse health.</p>
<p>This reframing of transient events into absorbing states allows survival modelling to be applied to, of all things, events like becoming a parent. Imagine a cohort of 10,000 25 year old women, all initially childless (so not parents), and follow them for 10 years. Each year, some proportion have a child, and so become parents. Once they become a parent, they can never <em>un</em>become a parent again, even if over this decade some proportion become have one, two, three or even more children (whereas others have no children); in the binary gaze of the absorbing state a parent of three children is no more or less of a parent than a parent of one child.</p>
<p>So, any transient event can be modelled using survival modelling by treating defining an absorbing state as occurring when that transient event <em>first</em> occurs. In the case of death, this clearly makes sense, as - brief moments of heart or brain death followed by successful heroic intervention notwithstanding - death truly is an absorbing state. In the case of becoming a parent the idea of treating this like an absorbing state - an event from which there’s no turning back - also makes quite a lot of sense, with parenthood being for most people who experience something that changes their lived experiences, attitudes and behaviour in an irreversible way. For other first events, the theoretical jusitifications may be less compelling: Is voting in an election something that irreconcilibly alters someone, for example? What about first getting a full time job? First getting a driving licence? First owning a house? For each of these defining an absorbing state as the first time a transient or repeated event occurs can be done, but does it always make as much sense, conceptually, to think about phenomena with survival modelling in mind?</p>
</section>
<section id="thin-slicing-from-probabilities-to-risks-and-hazards" class="level2">
<h2 class="anchored" data-anchor-id="thin-slicing-from-probabilities-to-risks-and-hazards">Thin-slicing: from probabilities to risks and hazards</h2>
<p>The Markov model structure is a nice framework with which to approach a lot of state change phenomena, and I think may be too little used pedagogically. But it has two downsides when it comes to survival modelling proper. Firstly, by default it assumes constant transition event probabilities, whereas the probabilities of entering an absorbing state may in reality change over time. Secondly, it involves defining a fixed cycle period, such as one week or one year.</p>
<p>Regarding the first downside, there is a potential workaround: instead of having single transition matrix, there could be a slightly different transition matrix for each time period. For example, for an event risk that increases over time, the first transition matrix could apply an event probability of 0.001; the 100th transition matrix apply an event probability of 0.01, and each intermediate transition probability could be a linear (or log linear) interpolation between these two extreme event probabilities, such that each cycle the event probability is increased relative to the previous cycle. This would be an example of an <strong>accelerating risk</strong> model; and if the risk were successively lower in each cycle, then it would be a <strong>decelerating risk</strong> model. It <em>could</em> be done with Markov models, but it’s hardly ideal. Instead of having a single transition matrix, which contains <img src="https://latex.codecogs.com/png.latex?K%5E2"> cells (where <img src="https://latex.codecogs.com/png.latex?K"> is the number of states), we now have a third dimension, <img src="https://latex.codecogs.com/png.latex?TK%5E2"> (where T is the number of cycles): our pithy little square of cells has become a long and inelegant cuboid.</p>
<p>Regarding the second downside: we know that many events don’t occur in or on a fixed schedule. If make the cycle length too large - such as per decade - than an individual may go from state A to state B to state C then back to state B within a single period, so which of the states it would be appropriate to define the individual as being in during that period is a bit arbitrary. Conversely, if the cycle length is too small - such as the millisecond or minute - then almost all cycles will be ones in which almost nothing occurs: the on-diagonal cells, <code>pkk</code> (where k is the state indicated by row k and column k in the transition matrix), will all be close to 1, and it will take a huge number of cycles - so a lot of computing power and memory - to simulate processes over enough of a time period to understand how things are likely to change over time. What can we do?</p>
<p>When it comes to survival modelling, where there are just two states and one is absorbing, we can trade off the flexibility of the transition matrix in terms of representing more than two states for analytic solutions which solve both of the above issues. In the simplest example, in which the event risks neither increase nor decrease over time, we can instead make use of an <strong>exponential model</strong>. The intuition and derivation of the exponential model comes about by recognising there’s a certain arbitrariness in the choice of time interval implicit in the <strong>constant change</strong> section above. We’ve discussed ways of expressing an outcome for one time period in terms of the value of that state in the last time period; we’ve not discussed the length of the time period itself. Let’s call our time interval <img src="https://latex.codecogs.com/png.latex?%5Ctau">, and let’s imagine what would happen to our model if we kept altering <img src="https://latex.codecogs.com/png.latex?%5Ctau">; in particular, reducing it, until it <em>approaches</em> 0. This kind of thought experiment, where we take finite intervals and try to think what they would look like if they became infinitesimally small, is the domain of calculus. For a finite time interval, we have a <em>probability</em> of something happening in a <em>time interval</em> bounded by <img src="https://latex.codecogs.com/png.latex?t"> and <img src="https://latex.codecogs.com/png.latex?t%20+%20%5Ctau">. By contrast, as we make the time interval, the size of the time box, infinitesimally small, then we no longer speak in terms of <em>probabilities</em>, but instead <strong>hazards</strong>, and <strong>hazard rates</strong>. A hazard is the instantaneous analogue of a risk, a force of change occurring <em>right now</em>, not from time 1 to time 2. Over time, over any valid and specifiable period of time, some proportion of a stock of a susceptible population will have succumbed to this hazard. And when this hazard, that applies at all times, does not itself vary over time, then we can say (see section 7.1.2 of <a href="https://grodri.github.io/glms/notes/c7.pdf">this guide</a>, for example):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(t)%20=%20e%5E%7B-%20%5Clambda%20t%7D%0A"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?S(t)"> is known as the <em>survival function</em>, and defines the share of the initially susceptible population that has not succumbed to the absorbing state between the start of a period of population and the time specified by <img src="https://latex.codecogs.com/png.latex?t">. The only parameter other than time in this equation is <img src="https://latex.codecogs.com/png.latex?%5Clambda">, which is the hazard. Unlike with the fixed interval Markov-style approaches discussed so far, this equation can be used to estimate survival proportions at any specifiable time period, and does not involve iteratively rerunning the same equation multiple times to get this cumulative probability.</p>
</section>
<section id="constantly-changing-hazards" class="level2">
<h2 class="anchored" data-anchor-id="constantly-changing-hazards">(Constantly) Changing hazards</h2>
<p>The survival function equation above is a specific case of a more generalisable form, <img src="https://latex.codecogs.com/png.latex?h(t;%20%5Calpha)%20=%20%5Clambda"> (where <img src="https://latex.codecogs.com/png.latex?h(.)"> refers to ‘hazard function’). Here I’ve listed time <img src="https://latex.codecogs.com/png.latex?t"> and additional parameters <img src="https://latex.codecogs.com/png.latex?%5Calpha"> as additional inputs that the hazard function could include, even though in the exponential case it’s just a single constant <img src="https://latex.codecogs.com/png.latex?%5Clambda">. One simple extension of the hazard function would be if we assume the hazard either increases or decreases over time. This can be achieved using the <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull Distribution</a>, which has up to three parameters - scale, shape, and location - for representing more complicated patterns of change in hazard over time. The way the Weibull distribution is represented mathematically, including whether the default distribution has two or three parameters, differs between fields of research and application. Regardless, it’s through the <em>shape parameter</em> that increasing or decreasing hazards can be representing, with (depending on parameterisation) values greater than 1 indicating *increasing hazards** over time, values less than one indicating <em>decreasing hazards</em> over time, and a value of 1 indicating constant hazard, i.e.&nbsp;the assumption implicit in the exponential distribution.</p>
<p>As an example of this, the figure below shows the cumulative probability of a Weibull distribution, where t varies from 0 to 10, where the shape parameter is either set to <code>1</code>, indicating a constant hazard (black line); to <code>0.5</code>, indicatign a decreasing hazard (red line); or to <code>2.0</code>, indicating an increasing hazard (blue line). For reference, the exponential distribution is drawn with a green line (As this is identical to the Weibull distribution with shape = 1, the green line is drawn thicker than other lines so the black line is also visible).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">xlim</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fun =</span> pweibull, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">args =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">shape =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fun =</span> pweibull, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">args =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">shape =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fun =</span> pexp, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linewidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fun =</span> pweibull, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">args =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">shape =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-7">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb9-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>,</span>
<span id="cb9-9">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cumulative probability'</span>,</span>
<span id="cb9-10">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Effect of shape parameter on cumulative probability of event in a Weibull distribution'</span>,</span>
<span id="cb9-11">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Green: exponential. Black: Weibull(1). Red: Weibull(0.5). Blue: Weibull(2) '</span></span>
<span id="cb9-12">    )</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-weibull" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-weibull-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Examples of Weibull models with constant, accelerating and slowing hazards</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="lifetables" class="level2">
<h2 class="anchored" data-anchor-id="lifetables">Lifetables</h2>
<p>The Weibull function allows for hazards that vary over time, but the flexibility of the function is not unlimited. They are an example of a <em>parametric</em> model. <a href="https://en.wikipedia.org/wiki/Life_table">Lifetables</a>, by contrast, are an example of a <em>nonparametric</em> model, that can show more complex patterns of variation between time and hazard; though the term ‘model’ may itself be giving the approach too much technical credit.</p>
<p>A lifetable is, unsurprisingly, a table, with at least two columns: one for age, <img src="https://latex.codecogs.com/png.latex?x">; and one for probability of reaching the next age, which we’ll call <img src="https://latex.codecogs.com/png.latex?p(x)">. Like Markov models, lifetables represent time in discrete time intervals (unlike Markov and exponential models, where time is treated continuously); these intervals are often, but not always, of a fixed distance apart from each other. They are used in demography, public health, and the actuarial sciences, and have been used for hundreds of years in one form or another.</p>
<p>To get familiar with lifetables, we’ll use the UK lifetables file available <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/lifeexpectancies/datasets/nationallifetablesunitedkingdomreferencetables">here</a>. Within this, the latest lifetable available for males in the UK looks as follows:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">require</span>(readxl)</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># getwd()</span></span>
<span id="cb10-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># list.files()</span></span>
<span id="cb10-5">lifetable_male_latest <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> readxl<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_excel</span>(</span>
<span id="cb10-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># path = 'posts/glms/one-off/time-and-change/nltuk198020203.xlsx',</span></span>
<span id="cb10-7">   <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">path =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nltuk198020203.xlsx'</span>,</span>
<span id="cb10-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sheet =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019-2021'</span>,</span>
<span id="cb10-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">range =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A6:F107'</span></span>
<span id="cb10-10">)</span>
<span id="cb10-11"></span>
<span id="cb10-12">lifetable_male_latest</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 101 × 6
     age       mx       qx      lx    dx    ex
   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     0 0.00431  0.00430  100000  430.   78.7
 2     1 0.000224 0.000224  99570.  22.3  78.0
 3     2 0.000137 0.000137  99548.  13.6  77.1
 4     3 0.000107 0.000107  99534.  10.7  76.1
 5     4 0.000071 0.000071  99523.   7.1  75.1
 6     5 0.000073 0.000073  99516.   7.3  74.1
 7     6 0.000077 0.000077  99509.   7.6  73.1
 8     7 0.00007  0.00007   99501.   7    72.1
 9     8 0.000068 0.000068  99494.   6.8  71.1
10     9 0.000065 0.000065  99487.   6.4  70.1
# ℹ 91 more rows</code></pre>
</div>
</div>
<p>The ‘Notation’ tab decodes the above terms as follows:</p>
<ul>
<li><strong>mx</strong>: the central rate of mortality</li>
<li><strong>qx</strong>: the mortality rate between age x and (x + 1), that is the probability that a person aged x exactly will die before reaching age (x + 1)</li>
<li><strong>lx</strong>: is the number of survivors to exact age x of 100,000 live births of the same sex who are assumed to be subject throughout their lives to [the mortality hazards presented in the lifetables ]</li>
<li><strong>ex</strong>: is the average period expectation of life at exact age x, that is the average number of years that those aged x exact[ly] will life thereafter based on [the lifetables]</li>
</ul>
<p><strong>mx</strong> and <strong>qx</strong> are subtly different, with <strong>qx</strong> a more empirical quantity, and <strong>mx</strong> a quantity slightly more dependent on model assumptions. Both are in practice very similar, except at the earliest ages. For our illustrations we’ll focus on <strong>qx</strong>, as this is more conceptually similar to the kinds of transition probabilities being modelled by Markov models and similar. If we plot age (<img src="https://latex.codecogs.com/png.latex?x">) against qx (<img src="https://latex.codecogs.com/png.latex?q(x)">) then we get the following:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(age, qx)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-lifetable-qx-against-x" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-lifetable-qx-against-x-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6: qx against x (age), for UK male lifetables for years 2019-2021.</figcaption>
</figure>
</div>
</div>
</div>
<p>This in practice looks largely like an exponentially increasing probability of mortality with age. However we can also see an elevated mortality risk in the first age. If the relationship is largely exponential then it should look more like a straight diagonal line, rather than a curve, if we use a log scale for the y axis; doing this might also reveal some other patterns in the data:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1">lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(age, qx)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_log10</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-lifetable-qx-against-x-logy" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-lifetable-qx-against-x-logy-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7: qx against x (age), for UK male lifetables for years 2019-2021. Log y axis</figcaption>
</figure>
</div>
</div>
</div>
<p>For most ages in adulthood, from around about age 35 years onwards, the relationship does indeed look like a diagonal straight line, consistent with exponentially increasing risk. (i.e.&nbsp;something that a Weibull model with accelerating risk should be able to represent.) However once in the mid 70s the risk appears to increase a bit faster, and at some of the oldest ages appears then to slow down a bit again. The risk in the first year of age is much higher than a straight line relationship would project; the risk in much of childhood is much lower; and the risk in early adulthood is a bit higher. In the figure below I’ve extrapolated the line drawn through ages 40 to 80 both leftwards to younger ages, and rightwards to older ages.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1">lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(age, qx)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stat_smooth</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(age, qx), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">inherit.aes =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>, </span>
<span id="cb14-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">between</span>(age, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>)),</span>
<span id="cb14-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lm'</span>,</span>
<span id="cb14-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">se =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>,</span>
<span id="cb14-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fullrange =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_log10</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-lifetable-risk-extrap" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-lifetable-risk-extrap-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: UK male lifetable qx with extrapolation from ages 40 to 80 years inclusive to earlier and later ages.</figcaption>
</figure>
</div>
</div>
</div>
<p>So in Figure&nbsp;8 we have an empirical relationship that largely has features consistent with an assumption of simple exponential growth, but with some important differences. For some ages, and for some problems, therefore, a modelled stylisation of the relationship might be adequate; for other problems and ages it would not be.</p>
<p>Implicitly, lifetables alone treat age and time as synonymous for the purposes of calculating life expectancies and so on. This comes both from issues of data availability (a topic we’ll focus on later), and also from the undeniable fact that individuals <em>age one year per year</em>. So, for example, a 50 year old in 1980 would be a 51 year old in 1981, a 52 year old in 1983, and so on. More symbolically: if <img src="https://latex.codecogs.com/png.latex?x"> becomes <img src="https://latex.codecogs.com/png.latex?x%20+%20%5Ctau">, then <img src="https://latex.codecogs.com/png.latex?t"> must become <img src="https://latex.codecogs.com/png.latex?t%20+%20%5Ctau">. Given this assumption (and it can be a strong assumption), we can use <img src="https://latex.codecogs.com/png.latex?q(x)"> (or its slightly nerdier cousin <img src="https://latex.codecogs.com/png.latex?m(x)">) to calculate cumulative risk of death over the lifecourse if nothing happens over time except our getting older. This is largely what the quantity <img src="https://latex.codecogs.com/png.latex?l(x)"> shows (technically, it’s the opposite of this). Let’s try to calculate this cumulative hazard directly, and compare it with the pre-calculated quantity. (This is, incidentally, something a little bit easier to do with a spreadsheet, but easy enough to do with R too.)</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Take just the two variables we need</span></span>
<span id="cb15-2">mini_lifetable <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb15-3">    lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb15-4">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> age, qx)</span>
<span id="cb15-5"></span>
<span id="cb15-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of age periods </span></span>
<span id="cb15-7">N <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(mini_lifetable)</span>
<span id="cb15-8"></span>
<span id="cb15-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cumulative survivorship vector</span></span>
<span id="cb15-10">S_x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">vector</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'numeric'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">length =</span> N)</span>
<span id="cb15-11"></span>
<span id="cb15-12"></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Everyone's alive at the start </span></span>
<span id="cb15-14">S_x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb15-15"></span>
<span id="cb15-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply each age's hazard to the surviving population</span></span>
<span id="cb15-17"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N){</span>
<span id="cb15-18">    S_x[i] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> S_x[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mini_lifetable<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>qx[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>])</span>
<span id="cb15-19">}</span>
<span id="cb15-20"></span>
<span id="cb15-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Everyone is either alive or dead, so everyone who's not alive by a given age must be dead</span></span>
<span id="cb15-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cumulative mortality vector</span></span>
<span id="cb15-23">H_x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> S_x</span>
<span id="cb15-24"></span>
<span id="cb15-25">mini_lifetable <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb15-26">    mini_lifetable <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-27">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">S_x =</span> S_x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">H_x =</span> H_x)</span>
<span id="cb15-28"></span>
<span id="cb15-29">mini_lifetable</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 101 × 4
       x       qx   S_x     H_x
   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
 1     0 0.00430  1     0      
 2     1 0.000224 0.996 0.00430
 3     2 0.000137 0.995 0.00453
 4     3 0.000107 0.995 0.00466
 5     4 0.000071 0.995 0.00477
 6     5 0.000073 0.995 0.00484
 7     6 0.000077 0.995 0.00491
 8     7 0.00007  0.995 0.00499
 9     8 0.000068 0.995 0.00506
10     9 0.000065 0.995 0.00513
# ℹ 91 more rows</code></pre>
</div>
</div>
<p>Let’s look at the cumulative survivorship curve:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1">mini_lifetable <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb17-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(x, S_x)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb17-6">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cumulative proportion alive by age x'</span>,</span>
<span id="cb17-7">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age x'</span>,</span>
<span id="cb17-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Our cumulative survivorship'</span></span>
<span id="cb17-9">    )</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s now compare this with the quantity <img src="https://latex.codecogs.com/png.latex?l(x)">:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1">mini_lifetable <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">left_join</span>(</span>
<span id="cb18-3">        lifetable_male_latest <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-4">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> age, lx)</span>
<span id="cb18-5">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">S_x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> S_x) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-7">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(x, S_x, lx) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cols =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(S_x, lx), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'variable'</span>,) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-9">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> value, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> variable, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> variable)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb18-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">shape =</span> variable)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb18-11">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb18-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb18-13">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Self-calculated and pre-generated cumulative survivorship'</span>, </span>
<span id="cb18-14">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age x'</span>, </span>
<span id="cb18-15">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cumulative survivorship by age x'</span></span>
<span id="cb18-16">    )</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see that these quantities are effectively identical. Additionally, they are both a type of survival function <img src="https://latex.codecogs.com/png.latex?S(t)">, showing cumulatitve survival probability from time 0 through to time t, so long as we assume (again, a <em>strong</em> assumption) that x and t are effectively the same. The lifetable <img src="https://latex.codecogs.com/png.latex?l(t)"> is therefore an example of a <em>nonparametric</em> survival function <img src="https://latex.codecogs.com/png.latex?S(t)"> that operates with discrete time intervals (as with a Markov model), even though they are often used and applied by different fields to those where survival models are the bread-and-butter, leading to different terms and symbols often being used.</p>
</section>
<section id="absorption-is-inevitable.-understanding-censoring-in-survival-data" class="level2">
<h2 class="anchored" data-anchor-id="absorption-is-inevitable.-understanding-censoring-in-survival-data">Absorption is Inevitable. Understanding Censoring in Survival data</h2>
<p>Let’s circle back and join together a couple of points discussed previously:</p>
<ul>
<li>Back in Figure&nbsp;3 we first saw an example of a process being simulated forwards with one absorbing state. This was simplified further to the two state example of Figure&nbsp;4, with one absorbing state. In both examples we saw that, as time marches on, the proportion of the population in the absorbing state keeps increasing. Given a long enough period of time, what proportion can we expect to be in the absorbing state? Well, clearly 100%.</li>
<li>In the section on lifetables, we mentioned we are making a strong assumption in assuming age and time are equivalent, i.e.&nbsp;that the age-specific annual mortality probabilities as recorded are those that will be experienced by real-life cohorts of people.</li>
</ul>
<p>From the first point we can conclude that, for a two-state scenario with one absorbing state, we can describe the two possible states up to a particular time period either as:</p>
<ul>
<li>Absorbed</li>
<li>Not Absorbed</li>
</ul>
<p>Or <em>equivalently</em> as:</p>
<ul>
<li>Absorbed</li>
<li>Not Absorbed <em>yet</em>.</li>
</ul>
<p>The distinction between the first and second framing is subtle, slight, but important for understanding distinct feature of survival data structures and the models they are applied to. This feature is known as <strong>censoring</strong>, and is a reason survival modelling often <em>looks</em> more distinct, from many other types of model, than it really is.</p>
<p>Let’s think again about the lifetable example. <em>For which birth cohort do the lifetable’s estimates of life expectancy and other conditional and cumulative survival estimates apply?</em> Technically, the answer is <em>no birth cohort that has ever lived, or ever will</em>. The lifetable’s estimates are for what’s known as a <em>synthetic cohort</em>, even though every estimate is produced using real-world data. Additionally, the unconditional (as in starting at birth) and conditional (as in starting from other ages) life expectancies are technically known as <em>period life expectancies</em>. This is in contrast to <em>cohort life expectancies</em>, which would be life expectancies that relate to specific, real-world birth cohorts. Ideally, we would like to know these cohort life expectancies. But unfortunately by the time we do they have stopped being useful. Why?</p>
<p>To illustrate, let’s think about the amounts of data available to calculate age-specific mortality for three birth cohorts: the 1930 birth cohort, the 1960 birth cohort, and the 1990 birth cohort. For the 1930 birth cohort, we have observed their annual age-specific mortality probabilities for each complete year of age up to age 94 (2023 - 1930); for the 1960 birth cohort we have observed their annual age-specific mortality probabilities up to age 64; and for the 1990 birth cohort we have observed these values up to age 34. An implication of this is that we can <em>know</em> (rather than simply estimate) the mortality probability between ages 50 and 51 years (quantity <img src="https://latex.codecogs.com/png.latex?q(50)"> in lifetable jargon) for the 1930 and 1960 birth cohorts, but not the 1990 birth cohort. We have <img src="https://latex.codecogs.com/png.latex?q(20)"> for all three birth cohorts; we have <img src="https://latex.codecogs.com/png.latex?q(80)"> for only one of the birth cohorts (the 1930 birth cohort).</p>
<p>The above is a sense a convoluted way of saying <em>we cannot know the future</em>, but also a way of thinking about how to frame it as a special kind of <em>missing data problem</em>, known as <strong>censoring</strong>.</p>
<section id="censoring-and-other-types-of-missingness-a-cinematic-analogy" class="level3">
<h3 class="anchored" data-anchor-id="censoring-and-other-types-of-missingness-a-cinematic-analogy">Censoring and other types of missingness: A cinematic analogy</h3>
<p>There are different classes of missing data. Imagine you’re watching a film in a cinema, and part way through someone with two-foot bouffant hair sits right in front of you, blocking your view. However - both fortunately and not - Mr or Mx Bouffant can’t keep still, so a lot of the time you can see what’s on the screen; Bouffant’s not blocking. From the time Bouffant first sits in front of you, some of images will be missing to you. Worse: Bouffant is also a talker, or maybe a loud muncher, so there’ll also be times when you can’t hear the film either; sometimes you can neither hear nor see the film. Poor you!</p>
<p>If the bits of the film you cannot hear, or see, the film are related in some way to the contents of the film itself, then (perhaps counterintuitively) Bouffant’s presence mean that, from your perspective, the bits of the film (sound and vision) that are missing to you are <strong>Missing at Random</strong> (MAR). For example, maybe Bouffant tends to munch a lot during establishing shots, or to sit up straight (<em>definitely</em> blocking your view) when there are car chases. In either case, there are bits of information you have access to (such as the visuals of the establishing shots, or the sounds of the car chases) that help you infer (more technically <em>impute</em>) the bits of information you’re not seeing or hearing.</p>
<p>Missing at Random (MAR) is the more optimistic scenario. If instead there was absolutely no relationship or link between Bouffant’s obstructions of your sights and sounds of the film, and the film itself, then this is called <strong>Missing complately at random</strong> (MCAR). In this latter scenario there’s no pattern between what you’ve observed and not observed that you can use to work out what you might have missed. (In practice there’s little we can use to determine whether this kind of missingness is determined by a MAR or a MCAR process; often it seems to be assume missingness is MAR and hope it’s not MCAR!)</p>
<p>The type of missingness covered by censoring, however, is different. Imagine, 70 minutes through a 110 minute film, the projector breaks down; the 40 minutes at the end of the film are <strong>censored</strong>. The missingness is all in one big lump at the end. You can <em>guess</em> what happens in the last third of the film, based on what happened during the first two thirds, but you can’t <em>know</em>.</p>
<p>When it comes to survival modelling, you always know <em>what</em> will happen: eventually, everything gets absorbed into the absorbing state. But if you don’t have all the data, you can’t know <em>when</em> what will eventually, inevitably, happen will happen. You can’t know whether the hazard of absorption gets more or less severe over time, or exhibits (as with mortality data) a more complex pattern.</p>
</section>
<section id="popping-and-stopping" class="level3">
<h3 class="anchored" data-anchor-id="popping-and-stopping">Popping and Stopping</h3>
<p>Let’s start with another film-adjacent example: imagine you’re making popcorn. You pour 1000 unpopped kernels into a hot pan, and close the lid. Then you wait 30 seconds.</p>
<p><em>None of the kernels have popped</em>.</p>
<p>Does this mean the kernels will never pop? Of course not. You can assume that, so long as constant heat gets applied, then with more time one of the kernels will pop, then another, then another… until eventually pretty much all of the kernels will be popped.</p>
<p>Now let’s imagine you’re a bit more patient. You’ve now weighted exactly five minutes, and you’ve made records of exactly when you heard a pop (say using a sound recorder). Initially it was just one pop, then a few seconds later another; at a certain time you hear a cacophony of popping; then the rate of popping starts to slow down. By the time you’ve stopped recording at five minutes the previous pop had been 10 seconds ago. Only 965 of the 1000 kernels have popped by the time you stop, though you’re confident if you waited even longer all 1000 kernels would pop eventually.</p>
<p>If you turned the popcorn popping recording into survival modelling data, and even more magically/horrifically had tracked the time to popping of each individual kernel, your data might have something like the following structure:</p>
<div id="tbl-surv-popcorn-example" class="anchored">
<table class="table">
<caption>Table&nbsp;6: Popcorn popping hypothetical data in Survival data structure</caption>
<thead>
<tr class="header">
<th>kernel_id</th>
<th>time (seconds)</th>
<th>status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>5</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>50</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>297</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>197</td>
<td>1</td>
</tr>
<tr class="odd">
<td>5</td>
<td>300</td>
<td>0</td>
</tr>
<tr class="even">
<td>6</td>
<td>204</td>
<td>1</td>
</tr>
<tr class="odd">
<td>7</td>
<td>199</td>
<td>1</td>
</tr>
<tr class="even">
<td>8</td>
<td>241</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>In this example, even kernel contributes exactly one observation, even though the kernels were evaluated as many different timepoints. Attached to each kernel is a time value, called <code>time</code>, and a binary flag, called <code>status</code>. Another, pithier, way this same data might be presented is:</p>
<blockquote class="blockquote">
<p><code>5, 50, 297, 197, 300+, 204, 199, 241</code></p>
</blockquote>
<p>In this pithier form the absence of a <code>+</code> appended to a time value indicates a status of <code>1</code>, whereas the presence of a <code>+</code> indicates a status of <code>0</code>.</p>
<p>In either case the time is clearly a time <em>until</em>… <em>something</em>. What is this <em>something</em>? Well, if status is 1, the time is the time until the absorbing event occurred - in this case the kernel popping - whereas if the status is <code>0</code> the time recorded is the <em>time until censoring</em>. Five minutes is 300 seconds, and so no kernels were observed longer than 300 seconds. To reiterate: the kernel that didn’t pop by 300 seconds is not immune to heat and time. It’s not unpoppable; it just hasn’t popped <em>yet</em>.</p>
<p>So, how is this kind of information useful for survival models? Well, knowing that a kernel hasn’t popped by 300 seconds is more of a testament to its survivability to popping than knowing that a kernel hasn’t popped by 30 seconds, and knowing that it hasn’t popped by 600 seconds would be more of a testament still. Although censored observations still don’t tell us when the absorbing event will happen, they do give us a lower bounds on when the event hasn’t happened by. Knowing that a kernel hasn’t popped by 300 seconds at least tells us that, when the pop does occur, it will occur after 300 seconds.</p>
</section>
<section id="dripfeeding-kernels" class="level3">
<h3 class="anchored" data-anchor-id="dripfeeding-kernels">Dripfeeding kernels</h3>
<p>In the above example, because the popping trial is stopped after 5 minutes (300 seconds), if the absorbing event hasn’t been observed yet, the censoring time will be identical for all kernels: 300 seconds. This is because in this first example we assumed all kernels entered the ‘trial’ (by fire) at exactly the same time. Now let’s think of a slightly modified scenario: imagine that, instead of all the kernels being dumped into the popcorn maker at the same time, they have to be added in more gradually, through a small funnel. If we say that t=0 is the time the machine is first turned on, then maybe the first kernel enters the machine at t=1.3, then the second at t=1.5, the third at t=1.6, and the forth at t=2.0. Let’s also imagine that, of the 1000 kernels poured slowly into the machine, the last kernel enters the machine at t=160.5 seconds. And let’s also imagine that, as in the earlier example, the trial (by fire) is stopped after exactly 5 minutes (300 seconds).</p>
<p>If we imagine both the first and last kernel that entered the trial are unpopped, what does this tell us? Well, for the first kernel, we know that it did not pop in 298.5 seconds. And for the last kernel, we know that it did not pop in 160.5 seconds. Our survival data structure records for these two kernels would look like <code>298.5+, 160.5+</code> in the more concise form, and in the tabular form would look as follows:</p>
<div id="tbl-surv-popcorn-example-2" class="anchored">
<table class="table">
<caption>Table&nbsp;7: First and last kernel unpopped data structure</caption>
<thead>
<tr class="header">
<th>kernel_id</th>
<th>time (seconds)</th>
<th>status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>298.5</td>
<td>0</td>
</tr>
<tr class="even">
<td>1000</td>
<td>160.5</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="real-world-relevance" class="level3">
<h3 class="anchored" data-anchor-id="real-world-relevance">Real-world relevance</h3>
<p>This latter scenario, with the dispersed and gradual entry to the trial, is closer to the usual kinds of data generating processes for which survival modelling is likely to be used in practice. Imagine you are running a clinical trial, in which a surgical device is fitted, and you want to know the rate at which the device fails over a 10 year period. And for this trial you need 200 subjects. Of course, even if every subject could be recruited at the same time, not everyone could have the operation at the same time; it will depend on the limited availability of both the subjects, the surgical staff, and the operating rooms. So, each subject’s start date will be different, perhaps by weeks, or by months, or by years. Like the small funnel in the second popcorn maker these logistical factors mean the times subjects start their participation in the study are staggered. And as with any real life evidence like this it may often be the case that the effective censored dates are different too: a subject may move, and not give a forwarding address, so becomes last observed after two years; another subject may consent at one and five years, but withdraw their participation after seven years; in either case the subject is still able to contribute some data to the trial, even if it’s for a shorter duration than expected. Regardless of the complex variation in when subjects start and end their participation in a study, with the survival data structure - time, and status - usable information can be acquired from every subject’s participation.</p>
</section>
</section>
<section id="its-one-thing-or-another-competing-absorbing-states" class="level2">
<h2 class="anchored" data-anchor-id="its-one-thing-or-another-competing-absorbing-states">It’s one thing or another: competing absorbing states</h2>
<p>Although most applications of survival modelling are of scenarios where there is a single absorbing state, and one non-absorbing state which a population exists in intially, we saw from the contingency tables and Markov models near the start - and know from our own experience - that there can be multiple absorbing states. Now, when there are multiple absorbing states, <em>the</em> outcome as we move through time is no longer inevitable, though <em>an</em> outcome is.</p>
<p>As a more concrete example, in a healthy-sick-dead model, there is one absorbing state - dead - and so the final composition of the population is knowable in advance, regardless of initial population composition or individual transition state parameters. In the long run, to paraphrase Keyes, we’re all dead.</p>
<p>This changes if we partition dead into two or more substates that are mutually exclusive but both still absorbing. For example, consider this four state model:</p>
<ul>
<li>non-smoker</li>
<li>smoker</li>
<li>dead - lung cancer</li>
<li>dead - not lung cancer</li>
</ul>
<p>There are now <em>two</em> absorbing states - dead-lung cancer; and dead - not lung cancer - and two non-absorbing states: smoker and non-smoker. We likely have some strong intuitions about the relative transition probabilities linking these states. For example, we might expect both the non-smoker and smoker states to be quite ‘sticky’, meaning the probabilities of remaining in each state in each cycle is high. We might also expect the probability of entering dead-lung cancer from smoker to be higher than dead-lung cancer from non-smoker.</p>
<p>In this latter, two absorbing state, example we both have the same kind of <em>structural certainty</em> we did when there was one aborbing state, but also much more <em>contingent uncertainty</em> about the exact proportions ending up in each absorbing state. More concretely: we know the entire population will eventually enter <em>an absorbing state</em>, but we cannot know from just looking at the scenario exactly what proportion will end up in each of the absorbing state. This will depend on other factors, such as the initial population composition (like the relative proportion of smokers and non-smokers), and the transition probabilities in the transition matrix. If we want to get the final relative proportions, we’ll likely have to build and run the model.</p>
<p>As an example, let’s run a Markov model where the transition matrix is kept the same (see the code for the transition probabilities), and everyone starts off alive, but either (A) 10% of the population are smokers; or (B) 50% of the population are smokers. This is shown in Figure&nbsp;9, with the code and comments in the code fold just before it.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb19-2"></span>
<span id="cb19-3">scenario_A_init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">900</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb19-4">scenario_B_init_pop <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb19-5"></span>
<span id="cb19-6"></span>
<span id="cb19-7">pAC <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># probability of non-smoker dying of lung cancer: 1% </span></span>
<span id="cb19-8">pAD <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.04</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># probability of non-smoker dying of other causes: 4% </span></span>
<span id="cb19-9"></span>
<span id="cb19-10">pBC <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.20</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># probability of smoker dying of lung cancer: 20%</span></span>
<span id="cb19-11">pBD <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># probability of smoker dying of other causes: 5%</span></span>
<span id="cb19-12"></span>
<span id="cb19-13"></span>
<span id="cb19-14">x_matrix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb19-15">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb19-16">        (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAC <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.98</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAC <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pAD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, pAC, pAD, </span>
<span id="cb19-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Each cycle, a non-smoker who does not die has a 2% probability of becoming a smoker </span></span>
<span id="cb19-18">        (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBC <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.98</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBC <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pBD) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, pBC, pBD, </span>
<span id="cb19-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Each cycle, a smoker who does not die has a 2% probability of becoming a non-smoker</span></span>
<span id="cb19-20"></span>
<span id="cb19-21">        <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># First absorbing state: lung cancer death</span></span>
<span id="cb19-22">        <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Second absorbing state: other death</span></span>
<span id="cb19-23">    ), </span>
<span id="cb19-24">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, </span>
<span id="cb19-25">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb19-26">)</span>
<span id="cb19-27"></span>
<span id="cb19-28">pop_matrix_scenario_A <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb19-29">pop_matrix_scenario_A[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> scenario_A_init_pop</span>
<span id="cb19-30"></span>
<span id="cb19-31">pop_matrix_scenario_B <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb19-32"></span>
<span id="cb19-33">pop_matrix_scenario_B[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> scenario_B_init_pop</span>
<span id="cb19-34"></span>
<span id="cb19-35"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix_scenario_A) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alive:NonSmoker"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alive:Smoker"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dead:Lung"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dead:NonLung"</span>)</span>
<span id="cb19-36"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(pop_matrix_scenario_B) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alive:NonSmoker"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alive:Smoker"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dead:Lung"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dead:NonLung"</span>)</span>
<span id="cb19-37"></span>
<span id="cb19-38">N_periods <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(pop_matrix_scenario_A)</span>
<span id="cb19-39"></span>
<span id="cb19-40"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N_periods){</span>
<span id="cb19-41">    pop_matrix_scenario_A[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix_scenario_A[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb19-42">    pop_matrix_scenario_B[i,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> pop_matrix_scenario_B[i<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1</span>,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> x_matrix</span>
<span id="cb19-43">}</span>
<span id="cb19-44"></span>
<span id="cb19-45">pop_df_scenario_A <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix_scenario_A <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-46">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-47">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-48">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb19-49"></span>
<span id="cb19-50">pop_df_scenario_B <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_matrix_scenario_B <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-51">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rownames =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'t'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-52">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(t)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-53">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'state'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n'</span>)</span>
<span id="cb19-54"></span>
<span id="cb19-55">pop_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb19-56">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bind_rows</span>(</span>
<span id="cb19-57">        pop_df_scenario_A <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">scenario =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>),</span>
<span id="cb19-58">        pop_df_scenario_B <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">scenario =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>)</span>
<span id="cb19-59">    )</span>
<span id="cb19-60"></span>
<span id="cb19-61"></span>
<span id="cb19-62">n_prop_scen_A <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-63">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(t <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, scenario <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>, state <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dead:Lung'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(n) </span>
<span id="cb19-64"></span>
<span id="cb19-65">n_prop_scen_B <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-66">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(t <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, scenario <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>, state <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dead:Lung'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(n) </span>
<span id="cb19-67"></span>
<span id="cb19-68">pop_df <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb19-69">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>state)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb19-70">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_area</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb19-71">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> scenario, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-fourstate-markov-twoabsorbing" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index_files/figure-html/fig-fourstate-markov-twoabsorbing-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Four state Markov model with two absorbing states. Two scenarios</figcaption>
</figure>
</div>
</div>
</div>
<p>In this example, in scenario A, where there are fewer smokers initially, 267 of the 1000 persons in the cohort are dead with lung cancer; in scenario B, where there were more smokers initially, 322 of the 1000 persons are dead with lung cancer.</p>
</section>
<section id="finally..-smooth-transitions-discrete-event-simulation-des" class="level2">
<h2 class="anchored" data-anchor-id="finally..-smooth-transitions-discrete-event-simulation-des">Finally.. Smooth Transitions: Discrete Event Simulation (DES)</h2>
<p>The above example, using Markov models, of course assumes non-varying transition probabilities over time, with no evolution over time between state transitions, and no allowance for prior characteristics of the population (such as different propensities to smoke, or to die, between males and females); as with other Markov it also assumes a fixed cycle length. However, we saw with Weibull modelling that the fixed cycle length assumption can potentially be dropped, along with the fixed hazard rate assumption. And we saw with the lifetable example that transition probabilities and hazards vary in a systematic but complex way with age (as well as, implicitly, by sex). So, how can models incorporating multiple absorbing states <em>also</em> work with continuous time (rather than fixed time cycles), and allow for more complex evolution of hazards with population characteristics (such as age), and time?</p>
<p>A general purpose framework for relaxing the fixed cycles and fixed probability assumptions of Markov models, and the one-absorbing-state assumption of most survival modelling, is through extending the latter to model competing risks. And a fairly good framework for getting useful information out of such competing risks models is through <strong>discrete event simulation (DES)</strong>. Rather than attempt a formal definition at this stage, let’s dive in with an example.</p>
<p>We saw from lifetable data (e.g. Figure&nbsp;7) that there is a high mortality hazard at the earliest ages, which then declines rapidly at an exponential rate from birth; and also a more steadily increasing mortality risk, which increases exponentially with a more gradual slope, from early adulthood onwards. These form, respectively, the <em>left side</em> and the <em>right side</em> of the bathtub curve. Further, we can imagine there being a constant, background mortality risk, of deaths due to accident. We can give different names to these three components of death: <strong>infantile death</strong>, on the left side; <strong>senescent death</strong>, on the right side; and <strong>accidental death</strong>, forming the underside. This is shown graphically in the following sketch.</p>
<div id="fig-compete-schedule-sketch" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/competing-schedules.jpeg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Competing schedules</figcaption>
</figure>
</div>
<p>We can see these three forms of mortality as <em>competing causes</em>: someone who dies from accidental causes has not died of infantile or senescent causes; someone who dies of infantile causes has not died of accidental or senescent causes; and someone who dies of senescent causes has not died of infantile or accidental causes. For this approach to modelling to work, we can also assume there is at least a theoretical hazard of dying of any of the three causes of death within any age range: someone between the ages of two and three years of age has <em>some</em> definable (if very small) risk of dying of accidental or senescent causes, as well as infantile causes; someone between the ages of 80 and 81 has some theoretical risk of dying of infantile or accidental causes as well as senescent causes.</p>
<p>At a first approximation, each of these three competing causes can be represented by its own Weibull model: the infantile causes schedule by a model with declining hazard; the senescent causes schedule by a model with accelerating hazard; and the accidental causes schedule by a model with a Weibull model with invariant hazard (i.e.&nbsp;an exponential model).</p>
<p>To create a DES using this model we would do the following:</p>
<ul>
<li>For each of (say) 10,000 times:
<ol type="i">
<li>Generate a predicted value of x from H1 (the infantile model), a predicted value of x from H2 (the accident model), and a predicted value of x from H2 (the senescent model). For iteration <img src="https://latex.codecogs.com/png.latex?i"> in the loop let’s call this choice set <img src="https://latex.codecogs.com/png.latex?S_i%20%5Cin%20%5C%7Bx_%7Bi,%201%7D,%20x_%7Bi,%202%7D,%20x_%7Bi,%203%7D%5C%7D"></li>
<li>Assign the time and end state of individual <img src="https://latex.codecogs.com/png.latex?i"> to the <em>minimum</em> <img src="https://latex.codecogs.com/png.latex?x"> in the choice set <img src="https://latex.codecogs.com/png.latex?S_i">.</li>
</ol></li>
<li>Produce summary statistics of the distribution of simulated times and states as appropriate.</li>
</ul>
<p>This <em>select-the-minimum-from-the-set</em> rule at step (ii) should make some intuitive sense. When all states being modelled are absorbing states then the first state that the individual enters is also the last state they will end up in. Implicitly, each row i in the loop above will tell a very simple and depressing story: “Individual 1: born, then dies of infantile causes age 1.3. Individual 2: born, then dies of accidental causes age 46. Individual 3: born, then dies of senescent causes age 73.2”, and so on.</p>
<p>In this simplest case, where the first event after birth is the last event, each simulated individual’s ‘life story’ will be of identical length in terms of <em>numbers of transitions</em>, each involving a single transition. But DES can also be extended to cover two or more non-absorbing states. In such cases the select-the-next-event-from-the-choice-set rule will still apply, but for any individual the model sets may need to be re-run many times. For example, if the two non-absorbing states are alive-nonsmoker and alive-smoker, then we can assume everyone starts at age x = 0 as an alive-nonsmoker, but it’s quite possible that for some, or many, individuals their <em>next event</em> is to transition, at some age, to becoming an alive-smoker. Say an individual becomes an alive-smoker at age 22: they are now no longer at risk of dying of any cause of death <em>before</em> the age of 22. So, the models of competing absorbing and non-absorbing states need to be rerun, updated with the information that the individual being simulated is now age 22, and now a smoker, and a <em>new choice set</em>, from which the <em>next</em> step in their discrete event journey, can now be simulated. It could be that the next state is to the other non-absorbing state (alive-nonsmoker in this example), or it could be to an absorbing state. And because there are now multiple non-absorbing states the potential variation in - for want of a better term - the ‘narrative complexity’ of each simulated event journey can vary. For example, the first five simulated event journeys might look as follows:</p>
<ul>
<li><strong>Person 1</strong>: alive-nonsmoker age 0-18; alive-smoker age 18-52; alive-nonsmoker age 52-56; dead-accidental age 56: sequence length 4.</li>
<li><strong>Person 2</strong>: alive-nonsmoker age 0-81; dead-senescent age 81: sequence length 2.</li>
<li><strong>Person 3</strong>: alive-nonsmoker age 0-2; dead-infantile age 2: sequence length 2.</li>
<li><strong>Person 4</strong>: alive-nonsmoker age 0-14; alive-smoker age 14-21; alive-nonsmoker age 21-28; alive-smoker age 28-30; alive-nonsmoker age 30-76; alive-smoker age 76-81; dead-senescent age 81: sequence length 7.</li>
<li><strong>Person 5</strong>: alive-nonsmoker age 0-91; dead-senescent age 91: sequence length 2.</li>
</ul>
<p>Note in the above examples what I’m calling the <em>sequence length</em> is not the longevity of each individual, but rather the number of events which mark transitions between discrete states. One person could live a long but (from this perspective) uneventful life, leading to a short sequence length; another person can live a shorter but more eventful life, leading to a long sequence length. The sequence length is the minimum amount of information required to record what was simulated on each occasion.</p>
<p>Within fields like health economics, both Markov models (more commonly) and DES (less commonly) involve associating the simulated amount of time a cohort, and individuals within the cohort, spend in different times with cost and utility ‘tarrifs’: In a healthy-sick-dead model, for example, the time spent in a healthy state might have a cost of 0 and utility of 1; the time spent in a sick state might have a cost of 1000 and a utility of 0.6; and the time spent in the dead state a cost of 0 and a utility of 0. Given different conditional transition probabilities (in Markov models) or hazard rates (DES), associated with the presence or absence of a treatment of interest or similar, such simulations can then be used to estimate the lifecourse costs and benefits (utilities) of a treatment of interest, ultimately producing estimates of the Incremental Cost Effectiveness Ratio (ICER) used to help make determinations about whether a new treatment (‘health technology)’ is likely to be judged ‘cost effective’ or not by NICE and similar institutions.</p>
</section>
<section id="concluding-comments" class="level2">
<h2 class="anchored" data-anchor-id="concluding-comments">Concluding comments</h2>
<p>This long post (in the blog) or page (in the website) has discussed a series of approaches for thinking about phenomena where ‘things change over time’, between discrete states. A subset of such phenomena include those with one absorbing and one non-absorbing state, which is the bread-and-butter of survival modelling. However the aim in this piece has been to think about a much wider family of phenomena that meets the above conditions. This has involved some phenomena and methods which are more the purview of medical statisticals; others which are more the purview of demography and the actuarial sciences; others which are more common in health economics and microsimulation; and others (such as the introductionary contingency tables) which are too simple and generic to have a single home.</p>
<p>The aim has been to offer breadth in this piece, and so some specific modelling approaches and the phenomena they are suited for have either not been discussed in much depth (such as how to actually implement a DES), or at all (such as proportional hazards models). These are known oversights, and there are doubtless unknown oversights, as well as possible misinterpretations too. Feedback - especially constructively critical - is very welcome in order to better see and understand this broad and complicated nexus of modelling approaches.</p>
<p>However, I hope the breadth of the discussion, and the attempts to show possibly underappreciated connections between different modelling approach and strategies, have been useful food for though for the reader, which rewards your patience in following along with my galaxy brain sensibilities on such matters. As a stretch goal I hope the piece has occasionally been entertaining and engaging at times too!</p>


</section>

 ]]></description>
  <category>statistics</category>
  <category>modelling</category>
  <category>survival modelling</category>
  <category>Markov modelling</category>
  <category>absorbing states</category>
  <guid>https://jonminton.github.io/jon-blog/posts/glms/one-off/time-and-change/index.html</guid>
  <pubDate>Sun, 30 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Brother Lee the Antimonk</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/brother-lee-the-antimonk/index.html</link>
  <description><![CDATA[ 




<p>I watched the film <a href="https://en.wikipedia.org/wiki/Queer_(film)">Queer</a> last week. (Or at least I think it was last week; over the Twixmas break time starts to blur.) A fairly random choice, made mainly because I had a free film ticket expiring, there was a showing with a reasonable start time, and I’d heard fairly positive reviews about the film. I still don’t know what I think about film. I do know that, after watching it, I felt <em>unclean</em>, inside and out.</p>
<p>Most scenes in Queer have, as background decoration, the grimy aftermath of hedonism pursued relentlessly and habitually. William Lee, Burrough’s thinly concealed narrative alterego, played by Daniel Craig, looks by turn affectless or predatory, sitting in bars, surrounded by fellow travellers in the pursuit of bodily pleasures, well-to-do and learned exiles from polite society, surrounded by cigarette butts, shot glasses, spent spirit bottles, by smoke and ash and musk, the implied miasma of bodily effluvia, looking forever impatient and bored and lost in thought and… and looking hungrily at that pretty young man, and <em>that</em> pretty young man, and <em>that</em> pretty young man, pursuing sexual encounters with the same instrumental imperative as a junkie seeking his fix.</p>
<p>Eventually, Lee manages to persuade one of the pretty young men to stick with him,<sup>1</sup> to follow him on a druggie’s sacred quest for what Lee calls ‘telepathy’. In a south american jungle Lee and The Boy engage in what might now be called Chemsex, using a now well-known shamanic psychedelic. Then, in magical realist fashion, they drift apart and lose two years. Lee is back to his starting haunt. Nothing, fundamentally, has changed.</p>
<p>Watching Queer reminded me of distant memories catching a few minutes, late night, of <a href="https://en.wikipedia.org/wiki/Naked_Lunch_(film)">Cronenberg’s 1991 adaptation of Naked Lunch</a>, in which Peter Weller plays Lee; in particular, of the talking insect typewriter with its pulsating fleshy orifice. A day or so later, I decided to watch the film again. Carnal pursuits and pleasures, shown largely ‘straight’ (ironically?) in Queer are instead rendered as carefully crafted magical realist latex monstrosities in Naked Lunch. Whereas Queer is languid and episodic, the narrative structure of film noir is used in Naked Lunch to give the suggestion, at least, that Lee’s adventures in Interzone - his self-imposed exile from justice<sup>2</sup> - are those in which, if one squints, the protagonist can be perceived as a tragic hero battling forces of darkness, rather than a relatively well-heeled flaneur pinballing from desire to desire.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/unpop/brother-lee-the-antimonk/https:/blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidZ4m4KN-YfO7vEVjANpXtPkg4ty8B58I3pwERUATHY57bO7DjKXy9awDy0tyYxE73tSgxRiA1oP3qv5uySWwj5qDWDR94n1ixBQebbYeZPwgzcFPM_pStxDhLjkPEXGGpYi-s94ZYo4BY/s640/5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Insect Typewriter</figcaption>
</figure>
</div>
<p>Down the rabbit hole a bit further. I decided to <em>read</em> <a href="https://en.wikipedia.org/wiki/Naked_Lunch">The Naked Lunch</a>. I’m currently about half way through, though I don’t know which half, as the book - more like Queer and less like the film adaptation - also lacks an underlying plot and structure, and comprises a series of strange, dark, dank, dirty, lustful, fantastical vignettes linked more by a tone and sensibility than by a common narrative scaffold.</p>
<p>In terms of the experience of <em>reading</em> The Naked Lunch, the film adaptation of Queer seems to better capture the sense of restless uncleanliness, whereas the film The Naked Lunch appears to better capture the quality of dark, monsterous imagination that pervade the tracts. Somewhere between the two films, for better or worse, seems to be the grimy essence of the book.</p>
<p>The book, The Naked Lunch, also reminded me of not one, but two, fictional books that featured in episodes of South Park. <a href="https://en.wikipedia.org/wiki/The_Tale_of_Scrotie_McBoogerballs">In one episode</a>, the child protagonists decide to write a deliberately disgusting and offensive book as a prank.<sup>3</sup> The book causes readers to vomit violently, but at the same time critics herald it as a literary masterpiece. <a href="https://en.wikipedia.org/wiki/Cherokee_Hair_Tampons">And in another episode</a>, the children’s teacher decides to write a romance novel, in which his sexual preoccupations find themselves on full display, with over six thousand references to male genitalia. Somewhere between these two fictional books, for better or worse, seems to be the essence of the real book, The Naked Lunch.</p>
<p>The enduring appeal, sympathy and romantic tint shown towards Burroughs as a literary and cultural figure should surprise us almost as much as <a href="https://en.wikipedia.org/wiki/William_S._Burroughs">Burroughs’ managing to live into his eighties despite his lifestyle</a>.<sup>4</sup> Pigeonholed and cordoned, likely more in retrospect, into a movement called <a href="https://en.wikipedia.org/wiki/Beat_Generation">The Beats</a>, the radical honesty, free living, and apparent rejection of orthodoxy and orthodox values professed and lived by Burroughs and other Beats figureheads in the forties and fifties laid the groundwork for <a href="https://en.wikipedia.org/wiki/Hippie#Origins">the Hippies</a> in the sixties and seventies (as well as being why the Beatles are called the Beatles and not the Beetles). And in this freedom, this rejection of old orthodoxies, this looking within and listening go and following of bodily desires, there was an expectation that progressive economic, political and sociological change would follow. Put simply: both the Beats (and by extension Burroughs) and the Hippies were coded as chaotic agents of the radical Left, bringing hope of liberation to the many.</p>
<p>But the economic base supporting Burroughs’ hedonistic lifestyle cannot be ignored. Burroughs was born to a very wealthy and privileged family: <a href="https://en.wikipedia.org/wiki/William_Seward_Burroughs_I">his grandfather</a> was the inventor of a patented technology, analogue business computers, that made him fabulously wealthy, and so Burroughs’ own parents were also very wealthy. And Burroughs’ parents used a portion of their wealth to send Burroughs <a href="https://en.wikipedia.org/wiki/William_S._Burroughs#Harvard_University">a generous monthly stipend to him</a>, whereever he was in the world, to do with as he pleased. Burroughs, in effect, lived off his affluent parents for decades. And it is with their largesse, an accident of pure privilege, that Burroughs was able to pursue a lifestyle that, for those less economically fortunate, would almost inevitably have led to the desperate crimes of those feeding all-consuming addictions - burglaries and robberies, prostitution - followed by imprisonment, homelessness, overdose and early death. Burroughs’ economic privilege, which was likely further compounded by him living in middle income countries, where the dollar stretched further, meant his experiences as an addict, of bodies and substances that can enter bodies, grimy and dank as they are, were likely always somewhat rareified and unrepresentative of the typical consequences of pursuing the lifestyle he chronicalled and mythologised.</p>
<p>Which brings me to the title of this post: <em>Brother Lee the Antimonk</em>. Because the need to be either gainfully employed, or to be locked in a cycle of desperate acquisitive crime to feed expensive habits, was partially or entirely removed from Burroughs for long stretches of his life, he could pursue the calls of the body and flesh with greater purity than the majority of ‘junkies’. Much as the lifelong room and board of a monk at a monestary, supported by the charity of lay members, allows a monk to devote his life to a vocation of spiritual contemplation and denial of the flesh, so Burroughs’ life appears almost as a mirror of the Christian monk’s vocation: a life devoted entirely to the present, to hedonism, to bodily pleasures and experiences, no matter how sodden or rotten or extreme.<sup>5</sup></p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>One audience review of Queer I read complained that The Boy’s character was underdeveloped. I agree, but think this lack of interest in the minds and personalities of Lee’s quarries came from Burroughs himself.↩︎</p></li>
<li id="fn2"><p>Burroughs was convicted <em>in absentia</em> of manslaughter for shooting his wife in her temple, and sentenced to two years imprisonment. Which I believe he never served.↩︎</p></li>
<li id="fn3"><p>In the episode, the children write the book because they are disappointed that J.D. Salinger’s <em>The Catcher in the Rye</em> does not live up to its notoriety. I am sure if they had read <em>Naked Lunch</em> they would not have been similarly disappointed.↩︎</p></li>
<li id="fn4"><p>Tragically, <a href="https://en.wikipedia.org/wiki/William_S._Burroughs_Jr.">William S. Burroughs’ identically named and neglected son</a> was similarly afflicted by addictive impulses, but died before his father, aged just 33.↩︎</p></li>
<li id="fn5"><p>A magical realist caricature of Burroughs may therefore be <a href="https://en.wikipedia.org/wiki/Cenobite_(Hellraiser)">Clive Barker’s Cenobites</a>!↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>beats</category>
  <category>hedonism</category>
  <category>nihilism</category>
  <category>counterculture</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/brother-lee-the-antimonk/index.html</guid>
  <pubDate>Sat, 04 Jan 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>First website update since 2023!</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/website-update/index.html</link>
  <description><![CDATA[ 




<p>I’ve updated my website for the first time since September 2023. Unlike this blog, which tends to be updated at least monthly, I hadn’t touched the website in 2024, even though there were a few important things to update on.</p>
<p>The reasons for this are mainly that, as this blog is built using <a href="https://quarto.org/">Quarto</a>, and Quarto is a form of markdown, there’s just much less web dev scaffolding to attend to. I can largely focus on figuring out what I want to write, rather than - for example - how to style and display text, graphics and other elements in a way that looks pleasing or professional.</p>
<p>By contrast, the website is made using <a href="https://react.dev/">React</a>, a javascript static site framework, and styled from scratch using many dozens of custom CSS styles I developed after marinating and confusing myself with around fifty hours of online website development courses, mainly through <a href="https://www.youtube.com/@DaveGrayTeachesCode">Dave Gray’s excellent youtube channel</a>.</p>
<p>Anyway, changes made include:</p>
<ul>
<li>Update footer copyright date to 2025 (skipping 2024!)</li>
<li>Updated to include my new job as a senior statistician at Smith &amp; Nephew, which I’ve been doing since September.</li>
<li>Opened up some present but previously hidden information about the kinds of things I do in my current and previous roles. (These were stored as json data structure elements, where I’d already written the content, but then not told react to do anything with it!)</li>
<li>Added mentions of statistics as a distinct area of expertise. (As distinct from data science)</li>
<li>Added links to the statistics website I developed, which grew out of sections of this blog.</li>
</ul>
<p>Anyway, the updated website, like the previous website, is available <a href="https://jonminton.net">here</a>.</p>



 ]]></description>
  <category>updates</category>
  <category>website</category>
  <category>react</category>
  <guid>https://jonminton.github.io/jon-blog/posts/website-update/index.html</guid>
  <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Weaponising the Empathy Machine: On Escape at Dannemora</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/escape-at-dannemora-weaponising-the-empathy-machine/index.html</link>
  <description><![CDATA[ 




<p>The film critic Roger Ebert <a href="https://www.rogerebert.com/features/memoriam-feature-2023">famously described films as ‘empathy machines’</a>, and indeed they are. The combination and synchronisation of sight and sound, and over a century’s development and refinement of techniques for conveying a sense of ‘being there’- from shot/reverse shot onwards - means perhaps there is no other medium in which the sense of feeling embodied and experientially coterminous with a protagonist is so effortless for a viewer to experience and, for better or for worse, so difficult to resist.</p>
<p>In <a href="https://en.wikipedia.org/wiki/Brave_New_World">Brave New World</a>, which extrapolated and parodied the sociological consequences of then-emerging early twentieth century technologies, the utopian successor to ‘movies’ are called ‘feelies’, in which this sense of experiential coterminousness reaches its theoretical apex. Though we do not use the term, many contemporary films, especially those which place theme-park-ride-like spectacle over conventional narrative structure, are already in effect ‘feelies’, even if in such cases the intent is more to make the viewer <em>feel</em>, rather than <em>feel like</em> any of the film’s protagonists.</p>
<p>By convention movies and television aim to promote empathy towards the protagonists, who are heroic, and amnity (reverse empathy) towards the antagonists, who are villainous. But this choice of in which direction to fire the empathy machine is ultimately just a convention. Films and television can choose to bring an equinimity of empathy to characters whose aims are in conflict with each other: both ‘cop’ and ‘robber’ in <a href="https://en.wikipedia.org/wiki/Heat_(1995_film)">Heat</a>, for example. But generally, empathy is directed and hoarded, not radiated and shared. Showing empathy for all characters in a story, whose aims are in irreconcilible conflict, can bring to the viewer the realisation that reality, itself, is fundamentally tragic: there is seldom a clear choice between good and evil, so much as a need to constantly try, and often fail, to find the lesser of two evils. Films that share the empathy too widely, and show both the light and darkness in all conflicting parties, tend to win awards but not viewers, who would rather feel only happiness for the eventual victor, without also experiencing the heartache of the loser.</p>
<p>All of which is a preamble for sharing my thoughts - and feelings - on watching <a href="https://en.wikipedia.org/wiki/Escape_at_Dannemora">Escape at Dannemora</a>, a 2018 true crime biopic based on <a href="https://en.wikipedia.org/wiki/2015_Clinton_Correctional_Facility_escape">a (partially) successful prison escape in 2015</a> (and seemingly about the only newish programme on Paramount+ that’s not about cowboys). The mini-series makes great use of the convention of the programme format, of being around six to ten one hour episodes long, and quite slow, to play with and weaponise film as an empathy machines.</p>
<p>In stories of David vs Goliath, of the man against the machine, of the few against the many, there’s an overwhelming instinct to side with the underdog. And indeed over half of Escape at Dannemora - the first four of the seven episodes - seem devoted to telling the story of the escape, its meticulous planning and execution, very much from the escapees’ perspectives. We can’t help but find something about the escapees’ fortitude, initiative, resilience, creativity and grit admirable, even inspirational.</p>
<p>But, though Escape from Dannemora is a programme of seven episodes, it’s more fundamentally a programme of <em>three sections</em>.</p>
<p>Section one comprises the first four episodes, as mentioned, tell the story of the planning and execution of the escape. And as mentioned, the viewer can’t help but empathise strongly with the escapees.</p>
<p>Section three comparises the last two episodes, which document the authorities’ attempts to recapture the escapees.</p>
<p>And between the first four episodes set before the escape and the last two episodes set after the escape, is section two, comprising a single episode: episode five. And episode five isn’t set <em>before</em> the escape, or <em>during</em> the escape, but <em>way before</em> the escape. Episode five shows, after four episodes developing empathy for the two main protagonists, exactly why that empathy may be misplaced. Episode five shows, in graphic detail, why the prisoners, whom the show has been implicitly encouraging viewers to will and wish out of prison, are in prison, and <em>deserve to be</em> in prison.</p>
<p>So, episode five, section two of the three section series, turns the first four episodes of the series, section one, into <em>an empathy trick</em>. And because section one comparises four of the seven episodes, episode five therefore turns the majoarity of the programme itself into an empathy trick. By episode five, the viewer - like another of the key protagonists - was seduced by two barbaric murderers into feeling that they’re <em>the good guys</em>, and that the aspirations and aims of the protagonists are coterminous with that of the viewer.</p>
<p>Film and television are empathy machines. And to my mind no television show has been more effective and masterful at weaponising these machines to play an <em>empathy trick</em> on its viewers. It got me right in the feelies. And then it got me.</p>



 ]]></description>
  <category>prison</category>
  <category>crime</category>
  <category>escape</category>
  <category>empathy</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/escape-at-dannemora-weaponising-the-empathy-machine/index.html</guid>
  <pubDate>Mon, 30 Dec 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Wham! forever: On cultural debraiding and the end of Cultural progress</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/unpop/wham-forever-cultural-debraiding/index.html</link>
  <description><![CDATA[ 




<section id="wham-again" class="level2">
<h2 class="anchored" data-anchor-id="wham-again">Wham! (again)</h2>
<p><a href="https://www.bbc.co.uk/news/articles/c9dp6y31qppo">According to BBC News</a>, Wham!‘s single, Last Christmas, first released in 1984, is now Christmas Number One for 2024, as well as having previously been the number one single last year as well. The 40 year old song isn’t even the oldest entry in the top ten, with other entries including Rockin’ Around The Christmas Tree (1958), and Jingle Bell Rock (1957).</p>
</section>
<section id="the-charts" class="level2">
<h2 class="anchored" data-anchor-id="the-charts">The ‘Charts’?</h2>
<p>If music pundits from the 1980s or 1990s were to have access to the Christmas Number Ones from today, and the last decade, they would likely be surprised, especially if album or single sales were taken into account. Something strange has happened, profoundly strange, given both how much familiar and repetitive the entries that keep appearing in these lists are, and secondly likely by how few records have been bought and sold.</p>
<p>Part of the reason for this strangeness from an 1980s or 1990s perspective is that the Christmas Number One chart is itself profoundly anachronistic. Very few songs are purchased as records, housed in physical information storage devices (vinyls, tapes, CDs and so on), which the purchasers then own. Instead most of these ‘sales’ comprise ‘streamed listens’, the number of times a device from a streaming service to which people subscribe, like Apple Music or Spotify, is beamed to that device and emanates through often small and tinny speakers. At Christmas time, more of these users are likely to select playlists of Christmas Songs, and its on these playlists that these decades-old songs are included. To continue producing song charts, various tariffs or conversion factors are employed: the streaming of a given number of songs from an album a given number of times is considered <em>equivalent to</em> the purchase of that album, even if the subscriber to the service isn’t even aware of the album’s existence, and neither seeks out or hears many of the songs on the album. For singles the need for conversion factors or tarrifs is less, though there are likely issues of equivalency when different versions of the same song are streamed. Instead a song is more likely to reach a top ten spot mainly by dint of being included in a larger number of more popular playlists. Again, the listeners take a more passive role in the proceedings: after initially agreeing to purchase a streaming surface the subscription payments are automated, and the ‘choice’ to listen to Wham!’s 1984 classic can involve as little as tapping a couple of buttons on a phone, not even searching for this particular single.</p>
</section>
<section id="the-new-normal" class="level2">
<h2 class="anchored" data-anchor-id="the-new-normal">The New Normal</h2>
<p>The thing is, for most of us living through the last five or ten years, none of this is at all surprising. It’s simply how things are now. For anyone younger than middle-aged, the very sense that things were ever not thus is at most a distant and unreliable echo of a memory. Even cinephiles who used to have shelves full of VHSes or DVDs, or audiophiles whose shelves strained under CDs and vinyl records, are likely - some hipsters notwithstanding - to have sold most of their physical collection at a small fraction of the purchase price in exchange for a monthly subscription service to a tech behemoth. At every stage, in every way, the streaming service was just more <em>convenient</em>, the once essential effort of having to make a choice of an album and the labour involved in removing a CD from a player (and worse, having to find the CD case that contained it) and replacing it with another one, all spontaneously considered and discovered to be activites simply too effortful and involved to stick with. Even if, over the course of a few months and years, the results of moving from owning to renting access to music meant spending hundreds or even thousands of pounds with nothing in the long-term to show for it, the <em>convenience</em> of not having to decide what to listen to, and of reducing one’s affordances with music technology - from looking, opening, extracting, pressing and turning; to tapping and prodding on a single screen - has made the transition almost thoughtlessly easy and complete.</p>
<p>But that transition happened over a decade ago, with the introduction of smartphones - cultural Everything Devices - in the late 2000s. The transition - from owning to renting, from matter to electrons - was a profound shift in <em>how culture is experienced and consumed</em>, but is not in itself <em>a cultural experience</em>. There is nothing intrinsically uniting about <em>what</em> people experience and consume when they use smartphones and streaming services, just a similarity in <em>how</em> people receive media.</p>
</section>
<section id="the-decades-that-time-forgot" class="level2">
<h2 class="anchored" data-anchor-id="the-decades-that-time-forgot">The Decades that Time Forgot</h2>
<p>Which brings me to <a href="https://www.youtube.com/watch?v=NkAJtRiOAxk&amp;t=14s">this argument</a>, made by comedian Michael Spicer in a video called ‘Nothing has changed since 1999’. Although presented with a comic spin, and containing a number of skits, the argument itself appears to be serious:</p>
<blockquote class="blockquote">
<p>The early 2000s were really weird. And what’s weirder about them is they haven’t gone anywhere. We are still living in the early 2000s. Nothing’s changed. Nothing’s shifted. Nothing’s moved forward.</p>
</blockquote>
<blockquote class="blockquote">
<p>There’s no such thing as a dead genre of music. … And this is the crux of why nothing has changed culturally in the last 20 years. Because the internet, and social media, has seen to it that every single group, no matter how small, has their space online. There’s no underground anymore. There’s no overground. It’s just everything, everywhere, all at once (!).</p>
</blockquote>
<blockquote class="blockquote">
<p>So, the world is not going to be gripped collectively by a cultural phenomenon anymore. Whether that’s TV, music, fashion or film. That is over. You are not watching, or reading or listening to the same things that I am. We can just split off and absorb whatever we want online. We’re not limited to one particular cultural shift. The days of everyone in the country sitting down to watch the same programme at the same time every week are gone.</p>
</blockquote>
<blockquote class="blockquote">
<p>We don’t experience culture collectively anymore. We branch off in our own little pockets of interest. And that’s why, weirdly, it doesn’t feel like we’re moving forwards. We’re moving forwards in terms of techological advancement. But in terms of culture we’re just… floating.</p>
</blockquote>
<blockquote class="blockquote">
<p>That’s why you can watch a film from 2004 and it won’t dawn on you that it’s twenty years old until you spot a piece of old technology[.]</p>
</blockquote>
<p>I think Spicer’s diagnosis is broadly correct. But also that the sense of progress and change that Spicer was looking to itself emerged from the confluence of social and technological changes that ‘only’ a handful of generations of humans experienced, and that was highly anomalous in the long stretches of human existence.</p>
</section>
<section id="bmb-emb-amb" class="level2">
<h2 class="anchored" data-anchor-id="bmb-emb-amb">BMB, EMB, AMB</h2>
<p>To simplify to the point of abject caricature, let’s divide the nature of cultural experience into three very loose epochs:</p>
<ol type="1">
<li>Before the epoch of mass broadcast;</li>
<li>The epoch of mass broadcast;</li>
<li>After the epoch of mass broadcast.</li>
</ol>
<p>What do I mean by mass broadcast? Simply a series of widely used and adopted technologies that <em>transmit</em> the same engaging messages, through the same engaging media, via a small and finite number of channels, to a large and geographically disparate number of individuals. As with most attempts to represent the continuous as discrete, mass broadcast was a process, not an event.</p>
</section>
<section id="the-centuries-that-time-forgot" class="level2">
<h2 class="anchored" data-anchor-id="the-centuries-that-time-forgot">The Centuries that Time Forgot</h2>
<p>Let’s say, however, that before there was mass broadcast, there was <em>geographic cultural heterogeneity</em>, as well as that the geographical contours within which humans found themselves had a profound effect on how much cultural variation exists across space, and where these cultures change. Two persons living half a mile away are likely to share much of the same culture if they are separated only by easily traversable plains or steppe, but could be profounding different - even speaking mutually indescipherable languages - if they are separated by large bodies of water or earth. The less easily traversable a terrain - think thick forest compared with open plains - the faster the culture changes between places a fixed distance apart. A clue to the reason for this is contained in the tendency for people, still, to describe distance in terms of time: <strong>how far?</strong> <em>20 minutes</em>. <strong>How far?</strong> <em>We can get there in a day but we’d have to rise early; probably better to stay overnight</em>.</p>
<p>Which brings us to the surprisingly timeless concept of a <em>time budget</em>, meaning the amount of time each day (or each week, or month, or season or year), people will be willing to <em>spend</em> on different kinds of activities, including that of travelling. In general most people won’t tend to want to spend more than, at the limit, a couple of hours a day travelling from place to place, with the optimal daily time budget for transport likely being around fifteen to thirty minutes. So, most of the people people have known, for almost all of human history and pre-history, have been within around half an hour of where they live. And before there was mass broadcast, this half hour radius likely largely determined <em>one’s culture</em>. With walking speed around 5 km per hour, this implies that most people’s culture, for most of the time that people have existed, was likely largely within a 2-3km radius. With the domestication of the horse, which could perhaps comfortably travel at 30 km per hour, this potential radius of common cultural influence likely expanded to around a 15 km radius (though only amongst those elites able to afford a horse), perhaps an eight-fold increase. And with a steam-powered train, a half-hour away could be perhaps 40km away, a both faster and more affordable two-and-a-bit-fold increase in the range of cultural exchange over the horse.</p>
</section>
<section id="mass-broadcast" class="level2">
<h2 class="anchored" data-anchor-id="mass-broadcast">Mass Broadcast</h2>
<p>Each of these transportation technologies allowed for the geographic range of <em>two-way</em> cultural exchange to increase. But by <em>mass broadcast</em> I mean <em>one-way</em> cultural transmission instead. The messenger on horseback and the Town Cryer, the telegraph, the newspaper (in literate populations), the radio: all examples of mass broadcast. Suddenly <em>the few</em> could communicate to <em>the many</em>, and through this <em>some small but growing aspect</em> of the cultural experiences of <em>the many</em> came to become more similar. As a result of these technologies, people came to think of themselves as - amongst other things - part of the same nation: to be British or Scottish or Irish or French, rather than just as thatchers or coopers or people who live near that hill near that stream.</p>
<p>And as <em>mass broadcast</em> technologies improved, so the cultural sway they had on ever more people increased. With moving images, people came to see people who they were told were or were not like them doing things they could imagine themselves doing, such as fighting in wars overseas. People separated by hundreds or thousands of miles came to see the same stories on screen, and so to become ever more wedded and united by ever more common cultural experiences. People heard themselves referred to on the wireless as a single people, and to think of themselves as such.</p>
</section>
<section id="culture-and-technological-progress" class="level2">
<h2 class="anchored" data-anchor-id="culture-and-technological-progress">Culture and Technological Progress</h2>
<p>But then technology begot technology, and prosperity begot prosperity, and change begot change, and so, much as people became used to thinking of themselves as a single nation, they also came to identify differentiation along generational lines: the world as older generations knew was no longer the world as younger generations were coming to understand. The norms were changing, the expectations were changing, the rules were changing. And so, as each generation entered adulthood, they came to realise that if they learned from their elders how to live in the world their elders lived in, they would be poorly equipped to live in the world as it would be for them. So, each new burgeoning adult generation sought to replace <em>vertical cultural transmission</em> (from the old-to-young) with <em>horizontal cultural transmission</em> (from peer-to-peer).</p>
<p>With this switch from <em>vertical cultural transmission</em>, based on local extra-familial networks, to <em>horizontal cultural transmission</em>, what many of us now think of Culture (big C) began. Each generation had its own Culture: its own way of dressing, its own way of speaking, its own set of rules and expectations. Each new generations sought, through the missives of mass media, to learn what it meant to be <em>a child of the 1950s</em> or of <em>the 1960s</em>, or <em>the 1970s</em>, or <em>the 1980s</em>, or <em>the 1990s</em>.</p>
<p>And it was these broadcast and telegraphed sempahores of cultural distinction - the changing hairstyles or hemlengths, or musical tastes - of successive cohorts of persons born over the 20th century, that - I think - people like Michael Spicer (and by instinct, myself) are looking for, and failing to find, when making the declaration that <em>there has been no (cultural) progress since 1999</em>. What someone of my age, or Spicer’s age, or almost any older living age, are looking for are signifiers that <em>the 2000s were about X</em>, <em>the 2010s were about Y</em>, and <em>the 2020s look to be about Z</em>.</p>
<ul>
<li>The 1950s were about rockabilly and teddy boys</li>
<li>The 1960s were about peace and love and rebellion and counterculture and hippies</li>
<li>The 1970s were about anger and prog rock and punks</li>
<li>The 1980s were about electropop and yuppies and performative androgyny</li>
<li>The 1990s were about grunge and Britpop and new lads and ladettes</li>
<li>The 2000s were about raunchy pop singers and corporate malaise, and then about 9/11</li>
<li>The 2010s were about ????</li>
<li>The 2020s are about ????</li>
</ul>
<p>In this sense, the <em>nothing has changed culturally</em> argument comes from a much lower ability to effectively stereotype young adults than was the case for about 50 years previously. But this inability to settle on a stereotype itself comes from a <em>much lower level of intra-generational cultural homogeneity</em> amongst youth generations of the last 20-25 years, whereas the <em>desire to stereotype</em> in this way comes from norms and expectations that persons born between around (say) 1940 and 1990 would have found easy to believe, but were likely not default expectations amongst older generations, and are likely also not default expectations amongst newer generations.</p>
<p>Why? Because the epoch of mass broadcast is <em>over</em>.</p>
</section>
<section id="what-now" class="level2">
<h2 class="anchored" data-anchor-id="what-now">What Now?</h2>
<p>What’s it been replaced with? <strong>Algorithmic cultural segmentation</strong>.</p>
<p>i.e., as described by Spicer, the ever more precise segmentation of pseudo-personalised content into disparate and algorithmically determined customer groupings. <em>If you bought X, you’re more likely to buy Y</em>. <em>If you watch X, you’re likely to watch Y</em>. There is no Culture; there are <em>cultures</em>. The cultural homogeneity of the epoch of mass broadcast has been replaced by cultural heterogenity. But whereas previously geography was the prime determinant of this heterogeneity, now the prime determinant is the algorithmic cluster to which individuals have been assigned based on their observed preferences for different types of content. This means, on the one hand, that two people separated by hundreds of miles can be of the same culture, but on the other hand that two people living in neighbouring houses, or even in the same household, can potentially be of very different cultures, potentially so different as to be almost mutually intelligible.</p>
</section>
<section id="girls-and-boys-parallel-cultures" class="level2">
<h2 class="anchored" data-anchor-id="girls-and-boys-parallel-cultures">Girls and Boys: Parallel Cultures</h2>
<p>One tell of this kind of algorithmic cultural fissuring is in the increasing divide in political and social views amongst boys and girls at school, and young men and young women after compulsory education has ended. According to <a href="https://www.brookings.edu/articles/the-growing-gender-gap-among-young-people/">this article</a>, for instance, sex differences in political and social attitudes are greater for Generation Z than all previous generations. According to <a href="https://www.theguardian.com/us-news/ng-interactive/2024/aug/07/gen-z-voters-political-ideology-gender-gap">this article</a>, the sex gap in political preferences (Democrat or Republican, in the US context) roughly doubled between 2000 and 2024, due more to changes in young women’s than young men’s shift in preference. The relationship between sex and the type of social media boys and girls, and young men and women, have consumed since around 2008 have also been argued to explain trends in <a href="https://www.amazon.co.uk/Anxious-Generation-Rewiring-Childhood-Epidemic-ebook/dp/B0CGWS3JQ6">mental health</a> and, even more controversially, <a href="https://en.wikipedia.org/wiki/Irreversible_Damage">gender identity</a>.</p>
<p>But if culture is now determined primarily through algorithmic segmentation then even accommodating and acknowledging growing within-generation sex differences may not do justice to the extent of cultural heterogeneity that exists within previously identified sociodemographic segments. Hence, again, the difficulty older generations (including my own) have with identifying broad characteristics and trends within the last fifteen so years as were apparent in previous decades. To the extent there is some agreement on a stereotype as applied by the old to the young, it’s that contemporary younger generations are somewhat more cautious, more anxious, more attuned to injustice and offence, and so more censorious than previous generations at the same age. But as discussed this ‘snowflake’ characterisation seems partial at best, and to the extent it applies at all, seems to applies much more to girls and women than boys and men. Again, this stereotype perhaps reflects more a desire amongst older generations to apply a mass broadcast framework for thinking about culture in a post mass broadcast epoch.</p>
</section>
<section id="my-segment" class="level2">
<h2 class="anchored" data-anchor-id="my-segment">My Segment?</h2>
<p>To take my own reflected algorithmic segment on Youtube as an example. Currently it appears a strange mix of the following: sociopolitical video essays; long form interviews; videos on cookery and especially pizza making techniques; playthroughs and retrospectives on games from the 1980s and 1990s; and morbidly fascinating videos of Americans shooting things in slow motion with weaponry of various calibres. What culture, if any, does this weird admixture of video recommendations place me in? I’m really not sure, though think it vanishingly unlikely that anything as hyperspecialised would have become been programmed for the masses on the BBC, ITV, or even Channel 4.</p>
</section>
<section id="generation-zimmer" class="level2">
<h2 class="anchored" data-anchor-id="generation-zimmer">Generation Zimmer</h2>
<p>And what, now, does terrestrial television largely comprise of? An increasing share of programming on the above channels seems to be based around feeding the nostalgic instincts of the mass broadcast generations. Recently, for example, I chanced upon an interview between Alan Titchmarsh (prominent in the 1990s) and Moira Stuart (prominent in the 1980s) where they shared fond reminiscences about working with Ronnie Corbet (prominent in the 1970s); <a href="https://www.itv.com/watch/love-your-weekend-with-alan-titchmarsh/10a0437/10a0437a0154">other guests on the same show</a> included Anita Dobson (most prominent in the 1980s) and Ben Miller (a relative newcomer, whose programmes were first televised in the early 2000s).</p>
<p>The draw of cosy nostalgia even pervades those channels that previously positioned themselves as edgy or countercultural: Back in late 2000 I remember watching <em>Have I Got News For You</em> (still being shown, with two of the same panellists), where a joke made at the time - in reference to the weeks-long litigation about the US presidential results - was that “news is currently just Bush and Gore… much like Channel 5”. The joke was in reference to the then new terrestrial channel, which in a bid to attract viewers did, indeed, have a post watershed schedule almost entirely comprised of documentaries about sex workers and serial killers. Look to same timeslots now, however, and you’re more likely to see documentaries about… the 1960s, 1970s and 1980s, featuring very familiar talking heads from the periods being reminisced about. Even Channel 4, which has a legal remit to provide an Alternative offering, increasingly comprises shows (like Countdown) that have run continuously for decades, and other cosy offerings in which well known and long established celebrities go for walks, take trains, or travel by narrowboat slowly across the British Isles, reminiscing fondly about their salad days from decades gone by.</p>
<p>Both the cause and consequence of terrestrial television’s steady descent into cosy nostalgia is that, by viewer demographics, it’s both <em>old</em> and <em>ageing quickly</em>. By old I mean the average age of viewers is considerably older than the UK median age, 61 years of age for the BBC based on <a href="https://community.sony.co.uk/t5/the-lounge-room/average-age-of-bbc1-viewers-is-now-61/td-p/2313835">this 2017 report</a>, and so likely older still now. And by ageing quickly I mean that, although the average age of the UK population is itself ageing, it’s likely the demographics of terrestrial television are ageing faster still. Although persons only have one alternative to ageing one year per year, populations <em>can</em> age faster or slower than this rate: London, for example, has long had a near static average age over time, because so many people migrate to the region in their late teens or early twenties, then from the region once they get to their twenties and thirties. By contrast certain regions in Northern England age much faster than one year per year, or the UK average rate of population ageing, because young adults tend to move elsewhere (such as to London). The broad magisteria of live TV viewership can also be thought of as a population, with ‘tuning in’ and ‘switching off’ (both archaic terms) somewhat like in- and out-migration, and the effects of these patterns of in-flow and out-flow largely causing this rapid ageing.</p>
<p>And of course, not all people of the same age will have the same preferences, abilities with, or appetite for new technology and new developments. The forty-somethings, fifty-somethings and sixty-somethings who leave broadcast television will likely be those more technologically savvy than those they leave behind in front of the television. And so, the persons still watching - or primarily watching - live broadcast television will not only be <em>old</em> in chronological terms, but also <em>old at heart</em> in terms of their relative preferences for the old over the new.</p>
</section>
<section id="conclusion-sort-of" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-sort-of">Conclusion (Sort of)</h2>
<p>All of which, in a very roundabout way, hopefully explains why the BBC still cares to tell its viewers, readers and listeners that there is a Christmas Number One (because it used to be a Big Deal last millennium), and also why this Christmas Number One is forty years old, and doing battle with songs that are just about of pensionable age.</p>


</section>

 ]]></description>
  <category>social media</category>
  <category>culture</category>
  <category>christmas</category>
  <category>music</category>
  <category>fashion</category>
  <category>progress</category>
  <guid>https://jonminton.github.io/jon-blog/posts/unpop/wham-forever-cultural-debraiding/index.html</guid>
  <pubDate>Sat, 21 Dec 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Poecilia parae: A lover, and a fighter</title>
  <dc:creator>Jon Minton</dc:creator>
  <link>https://jonminton.github.io/jon-blog/posts/gentes-lover-and-a-fighter/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/gentes-lover-and-a-fighter/figures/gentes.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Five Boys</figcaption>
</figure>
</div>
<p>I went to see Richard Dawkins, <em>in conversation</em>, in Glasgow, on 31 October, as part of a tour to promote his latest book, <em>The Genetic Book of the Dead: A Darwinian Reverie</em>, <span class="citation" data-cites="dawkins2024">(Dawkins and Lenzová 2024)</span> beautifully illustrated by Jana Lenzova, who previously translated <em>The God Delusion</em> to Slovak. The talk was… fine. But as the tour was to promote the book, I thought I’d buy that alongside the ticket. And the book is much better than fine. It’s fantastic. Dawkins is a good speaker, a sometimes gauche tweeter (or is it now Xer?), but an excellent writer of long-form content.</p>
<p>Though he did not play up the association, or possibly did not even notice or consider it important, there is a fascinating link between a chapter framed around cuckoos (chapter 10: The Backward Gene’s Eye View, pp 214-238), and the subsequent chapter (chapter 11: More Glances in the Rear-View Mirror, pp 240-259), which includes the following (slightly fanciful and highly simplified) genetic tree showing the level of common ancestry between humans and our closest living relatives.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jonminton.github.io/jon-blog/posts/gentes-lover-and-a-fighter/figures/chimpanzees.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Family Tree</figcaption>
</figure>
</div>
<p>This figure suggests that, on average, chimps and bonobos are the closest living relatives of each other, as well as the closest living relatives of humans. This is relatively well known, and the reason why Jared Diamond referred to humans as ‘the third chimpanzee’ in one of his most famous books <span class="citation" data-cites="diamond_third_2006">(Diamond 2006)</span>.</p>
<p>The social differences between chimps (as labeled here) and bonobos are often played up by popular science writers focused on our evolutionary endowment, especially in relation to questions of humans’ innate propensity to violence and to gender inequality. Chimps and bonobos are sometimes presented competing ideal types, with something like a moral refrain that we should be <em>more like</em> the peaceful bonobos, and <em>less like</em> the warmongering chimps. The steps of reasoning, as I understand them, are something as follows:</p>
<p>The reproductive success of an individual animal, and so its genes’ probability of being replicated along the germline, is influenced both by <em>natural selection</em>, ‘fitness’ to the broader environment, and <em>sexual selection</em>, that ‘game-within-a-game’ in which the specific reproductive challenges of the individual are the mate-guarding propensities and mate-selecting preferences of same- and opposite-sex members of the same species. Sometimes, natural selection and sexual selection can exert competing influence on the ‘fitness’ of different genes through the phenotypes they encode. Most famously, the exuberant, iridescent and expensive plumage of the male peacock tilts its phenotype against something optimised for the broader environment, making it both more visible to and harder to escape from predators. But exuberant plumage increases its success in the subgame of sexual selection, making it more likely to be selected by the (comparatively dull) female peahen (slightly paradoxically in part because the ability to survive the natural environment <em>despite</em> the handicap of unwieldy plumage itself to some extent suggests master of the natural environment and the capacity to find surplus calories).</p>
<p>In most mammal species, females have larger gametes, and much larger minimal parental investment, which militates towards greater choosiness in mate selection. If gross differentials in minimal parental investment tend to militate towards females as ‘choosers’, then this forms the first layer of sexual selection pressures within a species. But mate guarding behaviours amongst males then emerge as a subsequent layer in this game. Mate guarding is when a male of a species acts so as to limit the choice of females, by keeping other males away. This is usually achieved by a male being larger and (often) more aggressive than other males, with an incidental outcome of this being that, in species that practice mate guarding, males are also somewhat larger than females. Especially visible and notable examples of mate guarding occur in elephant seals (p.&nbsp;242), in which an extreme minority of especially large and violent male ‘beachmasters’ impregnate the vast majority of females.</p>
<p>I think it was within Diamond’s <em>The Rise and Fall of the Third Chimpanzee</em> that the argument was made that, if an evolutionary biologist from another planet were to appear on earth, knowledgeable of evolutionary theory but not of the specifics of earthly fauna, they would be able to reasonably estimate the relative influence of mate-guarding-based sexual selection in a species by comparing the average size of males to females within a species: the larger the male is relative to the female, on average, the greater the role of mate-guarding-based sexual selection in genetic selection. Based on this, I think the argument went, as human males are perhaps a fifth larger than human females on average, with even larger relative differentials in upper body strength, there is clear evidence of at least some level of mate-guarding based sexual selection in humans.</p>
<p>The sex-based size disparity is even larger in chimpanzees, with chimpanzee males being on average around a third larger than females, compared with the one fifth difference in humans, suggesting an even larger degree of mate-guarding based sexual selection in this distant ‘cousin’ of ours. Similarly, male chimpanzees appear even to have an even stronger tendency towards violence than humans. To the extent the term is useful, chimpanzee groupings or bands can be thought of as patrilineal, even patriarchal.</p>
<p>By contrast, there is no apparent sex difference in sizes between male and female bonobos: males and females are roughly the same size. And relatedly, there is in bonobos no clear evidence of male mate-guarding in the usual sense. Bonobos are also considered to have a much lower propensity to violence more generally than chimpanzees. Their groupings or bands tend to be matrilineal, even matriarchal.</p>
<p>Although male bonobos aren’t larger overall compared with female bonobos, their is one part of their anatomy that is disproportionately large given their size. Male bonobos have disproportionately large testicles, containing disproportionately large amounts of sperm, and they have disproportionately large amounts of sex with a disproportionately large variety of female bonobos.</p>
<p>So, the contrast as implied in the above account is between the patriarchal, violence-prone <em>fighter</em> species of the chimpanzees; and the matriarchial, matrilineal <em>lover</em> species of the bonobos. The slightly elegaic refrain then follows: why can’t we be more like the bonobos, and less like the chimpanzees? Evolutionary arms races went down the big bodies and violence route for the chimpanzee, and the big balls and free-love route for the bonobo, and though humans are neither bonobo nor chimpanzee, the fifth-larger size of average males compared with females, and even more disproportionate sex differentials in upper body strength, suggests that humans are somewhat more biased towards the chimpanzee path than the bonobo path.</p>
<p>So, in chimpanzees, bonobos, and humans, evolution made choices for us regarding sexual selection, which reinforced and imprinted themselves on our bodies and behaviours: fighter males <em>or</em> lover males. The two options are <em>mutually exclusive</em>. But what chapter 10 of the same book revealed is that, in some species, the <em>lover/fighter</em> male strategy split is <em>not mutually exclusive</em>, but instead can coexist.</p>
<p>The coexistence of apparently mutually exclusive phenotypes can occur in species if one of the sexes exhibits a number of discrete categories of phenotypic form, and these categories of form tend not to converge or blend over time. Imagine a species where males tend to either be all red, all green, or all blue; if a child is born of a red ancestral and blue ancestral parent, however, they will not be purple (a colour mix of the two parents), but instead either fully red or fully blue. The primary colours - these phenotypic forms - tend not to diminish or blend in the ways they are expressed. Instead, if one were to monitor the relative proportions of reds, greens and blues over time, one would see some degree of fluctuation over time, but likely around a stable relative proportion: say one-third red, one-third green, and one-third blue.</p>
<p>The factor which determines the category of phenotypic variation of a child is the <em>gens</em> of one of its parents, and which of its parents - male or female - is always the same. A <em>gens</em> (plural <em>gentes</em>), as I understand it, is a cluster of sex-specific genetic instructions that produce a series of phenotypic features that ‘work’ together, but which instruct and exist only in one sex of a <em>gentes</em>-exhibiting species. When comparing across species, such clusters of genetic instructions and phenotypic features are easier to think about: long canines and short intestines and front-facing eyes are three phenotypic features that ‘work’ together to produce a <em>carnivore</em> phenotype; whereas short canines and banks of molars and long intestines and side-facing eyes are alternative phenotypic features that ‘work’ together to produce a <em>herbivore</em> phenotype. But with standard speciation, the clustering of features that ‘work’ together, and so co-selection of particular selections of genes, tends to lead to the entire species towards strategic exclusivity: either optimise gene selection for the carnivore phenotype, or for the herbivore phenotype, but don’t try to mix-and-match. The fitness landscape across multiple features tends to feature many more hills and mountains than broad plateaus and aqueducts.</p>
<p>The opening example of a <em>gentes</em>-exhibiting species given by Dawkins is the Cuckoo. Cuckoos have an overall strategy that involves laying eggs that impersonate the eggs of other species, but there are many other species, and so many styles and patterns of eggs to try to impersonate. In cuckoos, it’s the females that are the <em>gentes</em>-exhibiting sex in the species, as they produce the eggs that need to blend in with the other eggs of the species in whose nest they have laid. Say there are two types of ‘victim’ birds: V1, who lays grey speckled eggs, and V2, who lays blue unspeckled eggs. Female cuckoos then, over many generations, specialise into two separate <em>gentes</em>: one <em>gens</em> that optimises towards impersonating V1’s eggs, and other <em>gens</em> that optimises towards impersonating V2’s eggs. Male cuckoos do not discriminate in mate selection in females from different <em>gentes</em>: a male whose mother was from the V1-optimised lineage will freely mate with females from the V2-optimised lineage, and vice-versa. We can think of the female <em>gentes</em> as distinct vertical columns, becoming no closer or further apart from each other, whereas the male cuckoos’ genetic contributions as like darting diagonal strings that either wrap around (V1/V1, V2/V2) or dart between (V1/V2, V2/V1) the columnar female <em>gentes</em>. It’s the males’ cross-mating between <em>gentes</em> that keeps the cuckoos a single species, despite so much variation in egg phenotype.</p>
<p>Which brings me to a remarkable <em>gentes</em>-exhibiting species of fish, <em>Peocilia parae</em>. Unlike the cuckoo, the <em>gentes</em>-exhibiting sex is male, not female: the males are the columns, and the females are the string binding them together. And although Dawkins’ description - reproduced below, in Dawkins’ typically non-diplomatic tone - focuses initially on colour variation between male <em>gentes</em>, it’s clear the phenotypic differences from <em>gens</em> to <em>gens</em> affect overall size and behaviour too:</p>
<blockquote class="blockquote">
<p>One species, <em>Poecilia parae</em>, has a remarkable colour <em>polymorphism</em>, which affects only the males. Polymorphism means that there are different genetically determined colour types coexisting in the population (in this case five colour patterns) and the proportions of the different types remain stable in the population through time. All five male morphes can be found swimming together in South American streams. There’s only one female morph: females look alike.</p>
</blockquote>
<blockquote class="blockquote">
<p>Since the polymorphism affects only one sex, we can call them five gentes, by analogy with the cuckoos, with the difference that in these fish it’s the males who are separated by gens. The picture shows the five male types plus a female at the bottom. Three of the five male types have two long stripes like tramlines. Between the tramlines there is colour, and I’ll call them reds, yellows, and blues respectively. These three ‘tramliners’ can, for many purposes, be lumped together. The fourth type has vertical stripes. They’re officially named ‘parae’, but confusingly that’s also the name of the whole species. I’ll call them ‘tigers’. The fifth type, ‘immaculata’, is relatively plain gray, like females but smaller, and I’ll call them ‘greys’.</p>
</blockquote>
<blockquote class="blockquote">
<p>Tigers are the largest. They behave aggressively, chasing rival males away, and copulating with females by force. Greys are the smallest, and they manage to copulated only by occasionally sneaking up on females opportunistically. When they can get away with it, it seems to be because otherwise aggressive males mistake them for females, which they do indeed resemble. Greys have the largest testes, presumably capable of producing the most sperm, perhaps to take advantage of their scarce opportunities to use it. Red, yellow, and blue tramliners are of intermediate size. Rather than rape or sneak, they court females in a civilised manner, displaying their respective coloured flanks.</p>
</blockquote>
<p>pp 228-230</p>
<p>Although Dawkins used brusque and somewhat damning language in contrasting the ‘Tigers’ and the ‘Greys’, the descriptions suggest that the ‘Tigers’ come from a <em>gens</em> optimised on a <em>fighter</em> phenotype, including its larger size and more aggressive behaviour, whereas the ‘Greys’ from from a <em>gens</em> optimised on a <em>lover</em> phenotype, including is comparatively diminutive size and, crucially, larger testes.</p>
<p>So, although it seems the choice between <em>fighter</em> and <em>lover</em> male phenotypes in humans and primates is mutually exclusive, and essentially locks in a species’ genetic endowment towards pursuit of just a single strategy, there’s at least one species of fish that is both a lover <em>and</em> a fighter.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-dawkins2024" class="csl-entry">
Dawkins, R., and J. Lenzová. 2024. <em>The Genetic Book of the Dead: A Darwinian Reverie</em>. Bloomsbury Publishing. <a href="https://books.google.co.uk/books?id=87sBEQAAQBAJ">https://books.google.co.uk/books?id=87sBEQAAQBAJ</a>.
</div>
<div id="ref-diamond_third_2006" class="csl-entry">
Diamond, J. M. 2006. <em>The <span>Third</span> <span>Chimpanzee</span>: <span>The</span> <span>Evolution</span> and <span>Future</span> of the <span>Human</span> <span>Animal</span></em>. P.<span>S</span>. HarperCollins. <a href="https://books.google.co.uk/books?id=9TVNmDojtzUC">https://books.google.co.uk/books?id=9TVNmDojtzUC</a>.
</div>
</div></section></div> ]]></description>
  <category>evolution</category>
  <category>dawkins</category>
  <category>sex differences</category>
  <category>natural selection</category>
  <category>sexual selection</category>
  <guid>https://jonminton.github.io/jon-blog/posts/gentes-lover-and-a-fighter/index.html</guid>
  <pubDate>Sat, 07 Dec 2024 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
