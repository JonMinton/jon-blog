{
  "hash": "b4788509994151f22b8daa1f8f533b98",
  "result": {
    "markdown": "---\ntitle: \"Tidy Tuesday: Women's Football\"\ndate: \"2024-07-17\"\nauthor:\n    - \"Kate Pyper\"\n    - \"Brendan Clarke\"\n    - \"Kennedy\"\n    - \"Imran\"\n    - \"Abram\"\n    - \"Jon\"\ntopics: [statistics, tidy tuesday, sports, football]\n---\n\n\nAfter a bit of a (in Jon's view) dearth of interesting datasets within Tidy Tuesday, this week brought something worth looking at to the table: datasets on women's football over the last few years, including changes in its popularity, as measured by attendance. \n\nKate led this session. \n\n## Setting up \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(broom)\n\ntuesdata <- tidytuesdayR::tt_load(2024, week = 29)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n--- Compiling #TidyTuesday Information for 2024-07-16 ----\n--- There are 3 files available ---\n--- Starting Download ---\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDownloading file 1 of 3: `ewf_appearances.csv`\n\tDownloading file 2 of 3: `ewf_matches.csv`\n\tDownloading file 3 of 3: `ewf_standings.csv`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n--- Download complete ---\n```\n:::\n\n```{.r .cell-code}\newf_appearances <- tuesdata$ewf_appearances\newf_matches <- tuesdata$ewf_matches\newf_standings <- tuesdata$ewf_standings\n```\n:::\n\n\n## Questions, questions...\n\nFirstly, we decided to look at growth attendance over time: \n\n\n::: {.cell}\n\n```{.r .cell-code}\newf_matches %>% \n  group_by(season) %>% \n  summarise(attendance = median(attendance, na.rm = TRUE)) %>% \n  ggplot() +\n  geom_col(aes(x = season, y = attendance)) +\n  theme(axis.text.x = element_text(angle = 90))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nFor *some* reason, there was no attendance in the 2020-2021 season. Definitely something unexpected that we should investigate further, as 2020 was a completely normal year in every way\n\nWhat about trends in season, e.g. are the first matches more popular than the rest, much like the first episodes of TV series tend to be watched more than the rest of the series? \n\n\n::: {.cell}\n\n```{.r .cell-code}\newf_matches %>% \n  group_by(season) %>% \n  mutate(match_no = order(date)) %>% \n  ggplot(aes(x = match_no, y = attendance, colour = season, group = season)) +\n  geom_point() +\n  facet_wrap(~ tier, scales = \"free\") +\n  scale_y_log10()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1188 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nNote we used a log y scale as attendance seems to be very variable between matches. However we couldn't see any obvious trend within season.\n\nWe also decided just to focus on tier 1 \n\n\n::: {.cell}\n\n```{.r .cell-code}\newf_matches %>% \n  filter(tier == 1) %>% \n  group_by(season) %>% \n  mutate(match_no = order(date)) %>% \n  ggplot(aes(x = match_no, y = attendance, colour = season, group = season)) +\n  geom_point() +\n  scale_y_log10()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 178 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n## Modelling \n\nWe then decided to try to model factors that could predict (log) attendance. First a model predicting log-attendance on home team id, match number, and season, but without interaction terms. And then a model with interaction terms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\newf_matches %>% \n  filter(tier == 1) %>% \n  group_by(season) %>% \n  mutate(match_no = order(date)) %>% \n  lm(log10(attendance) ~ home_team_id + match_no + season, data = .) ->\n  mod1\n\newf_matches %>% \n  filter(tier == 1) %>% \n  group_by(season) %>% \n  mutate(match_no = order(date)) %>% \n  lm(log10(attendance) ~ home_team_id + match_no + season + season*match_no, data = .) ->\n  mod2\n```\n:::\n\n\nHow to compare? Well, as `mod1` can be considered as a *restricted* version of `mod2` (the interaction term coefficents set to 0) we can use ANOVA to see if the additional complexity of the unrestricted model, `mod2`, is 'worth it':\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: log10(attendance)\n                 Df Sum Sq Mean Sq F value    Pr(>F)    \nhome_team_id     17 63.340  3.7259 42.4441 < 2.2e-16 ***\nmatch_no          1  4.241  4.2414 48.3166 6.604e-12 ***\nseason           12 56.470  4.7058 53.6073 < 2.2e-16 ***\nmatch_no:season  12  1.508  0.1257  1.4314    0.1453    \nResiduals       982 86.203  0.0878                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nanova(mod1, mod2) # same as above but pulls out specific test that we are interested in\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: log10(attendance) ~ home_team_id + match_no + season\nModel 2: log10(attendance) ~ home_team_id + match_no + season + season * \n    match_no\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1    994 87.711                           \n2    982 86.203 12    1.5079 1.4314 0.1453\n```\n:::\n:::\n\n\nWe concluded: \n\n    Interaction term not significant - proceed with mod1\n\nNow to look at the coefficients on `mod1`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log10(attendance) ~ home_team_id + match_no + season, \n    data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.90496 -0.19277 -0.03661  0.14062  1.51043 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          2.9890968  0.0541578  55.192  < 2e-16 ***\nhome_team_idT-002-T -0.2686225  0.0619191  -4.338 1.58e-05 ***\nhome_team_idT-003-T -0.3359697  0.0446896  -7.518 1.24e-13 ***\nhome_team_idT-005-T -0.2652441  0.0524152  -5.060 4.98e-07 ***\nhome_team_idT-006-T -0.2461753  0.0464112  -5.304 1.39e-07 ***\nhome_team_idT-008-T -0.0507938  0.0425091  -1.195 0.232413    \nhome_team_idT-011-T -0.4073355  0.0693986  -5.870 5.95e-09 ***\nhome_team_idT-013-T -0.5394900  0.0448460 -12.030  < 2e-16 ***\nhome_team_idT-014-T -0.2734024  0.0619209  -4.415 1.12e-05 ***\nhome_team_idT-016-T -0.2675245  0.0598158  -4.472 8.62e-06 ***\nhome_team_idT-017-T -0.3209426  0.0440625  -7.284 6.60e-13 ***\nhome_team_idT-020-T -0.0394211  0.0447805  -0.880 0.378900    \nhome_team_idT-021-T  0.0452529  0.0575592   0.786 0.431939    \nhome_team_idT-023-T -0.4128162  0.0497442  -8.299 3.40e-16 ***\nhome_team_idT-027-T -0.4112510  0.0693942  -5.926 4.27e-09 ***\nhome_team_idT-028-T -0.3241747  0.0575895  -5.629 2.36e-08 ***\nhome_team_idT-030-T -0.3459956  0.0530576  -6.521 1.11e-10 ***\nhome_team_idT-031-T -0.3978321  0.0708242  -5.617 2.52e-08 ***\nmatch_no            -0.0002474  0.0003161  -0.783 0.434030    \nseason2012-2012     -0.0706150  0.0641552  -1.101 0.271298    \nseason2013-2013     -0.0381315  0.0604345  -0.631 0.528215    \nseason2014-2014      0.0752879  0.0611843   1.231 0.218797    \nseason2015-2015      0.2112739  0.0626453   3.373 0.000774 ***\nseason2016-2016      0.2591016  0.0582373   4.449 9.60e-06 ***\nseason2017-2017      0.1782820  0.0691801   2.577 0.010107 *  \nseason2017-2018      0.1231090  0.0579269   2.125 0.033812 *  \nseason2018-2019      0.1606422  0.0562308   2.857 0.004368 ** \nseason2019-2020      0.4160694  0.0578761   7.189 1.28e-12 ***\nseason2021-2022      0.3912164  0.0568712   6.879 1.06e-11 ***\nseason2022-2023      0.7350856  0.0570183  12.892  < 2e-16 ***\nseason2023-2024      0.8347182  0.0565907  14.750  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2971 on 994 degrees of freedom\n  (178 observations deleted due to missingness)\nMultiple R-squared:  0.5858,\tAdjusted R-squared:  0.5733 \nF-statistic: 46.86 on 30 and 994 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWe had some fun trying to find the most and least popular teams. The reference team, team 1, happens to be about the most popular team. \n\n\n::: {.cell}\n\n```{.r .cell-code}\newf_appearances %>% \n  filter(season == \"2023-2024\") %>% \n  select(team_id, team_name) %>% \n  distinct() %>%\n  arrange(team_id) |>\n  view()\n```\n:::\n\n  \nWe thought we could do more to visualise the difference in apparent popularity between teams, producing some 'tie fighter' graphs (also known as blobograms, apparently)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(mod1) %>% \n  filter(str_detect(term, \"home_team\")) %>% \n  mutate(term = str_remove(term, \"home_team_id\")) %>% \n  ggplot() +\n  geom_point(aes(x = estimate, y = term)) +\n  geom_errorbarh(aes(xmin = estimate - 2*std.error, xmax = estimate + 2*std.error, y = term)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nPoor old team 13! (Everton Women)\n\nCompared with the reference team (Arsenal Women) only 3 teams looked similarly popular: team 8 (Chelsea Women), team 20 (Manchester City), and team 21 (Manchester United).\n\n\n\nThen we decided to do the same kind of thing for season, which should showing growing popularity over time:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(mod1) %>% \n  filter(str_detect(term, \"season\")) %>% \n  mutate(term = str_remove(term, \"season\")) %>% \n  ggplot() +\n  geom_point(aes(x = estimate, y = term)) +\n  geom_errorbarh(aes(xmin = estimate - 2*std.error, xmax = estimate + 2*std.error, y = term)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nUp, up and away! (mostly...)\n\n\n## Conclusion\n\nSome places to go:\n\n- Why the decline in 2016, 2017, 2018?\n- What caused the jumps in 2015, 2019, 2022?\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}