{
  "hash": "9cfc039220ecf227294c350cf61906c9",
  "result": {
    "markdown": "---\ntitle: \"Tidy Tuesday: 20 Feb 2024 - R Grants\"\nauthor: \n  - \"Kennedy Owusu-Afriyie\"\n  - \"Antony Clark\"\n  - \"Brendan Clarke\"\n  - \"Jon Minton\"\n  - \"Nick Christofides\"\n  - \"Steph Curtis\"\n  - \"Gats Osorio\"\n  - \"Andrew Saul\"\n  - \"Myrian Scansetti\"\ndate: \"2024-02-22\"\ncode-fold: true\nwarning: false\nmessage: false\ncategories: [R, tidy tuesday, funding]\n---\n\n\n## Introduction\n\nThis [TidyTuesday session](https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-02-20/readme.md) investigated the funding of intrastructure steering committee grants from the R consortium over time, and was led by Kennedy Owuso-Afriyie. \n\n## Data loading \n\nWe looked at two options for loading the dataset: one using the `tidytuesdayR` package; the other linking to the url directly. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Option 1: tidytuesdayR package \n## install.packages(\"tidytuesdayR\")\n \nlibrary(tidyverse)\nlibrary(tidytuesdayR)\n \n \n# tuesdata <- tidytuesdayR::tt_load('2024-02-20')\n# ## OR\n# tuesdata <- tidytuesdayR::tt_load(2024, week = 8)\n \n# isc_grants <- tuesdata$isc_grants\n \n# Option 2: Read directly from GitHub\n \nisc_grants <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-02-20/isc_grants.csv')\n \nisc_grants\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 85 × 7\n    year group title                          funded proposed_by summary website\n   <dbl> <dbl> <chr>                           <dbl> <chr>       <chr>   <chr>  \n 1  2023     1 The future of DBI (extension …  10000 \"Kirill Mü… \"This … <NA>   \n 2  2023     1 Secure TLS Communications for…  10000 \"Charlie G… \"The p… <NA>   \n 3  2023     1 volcalc: Calculate predicted …  12265 \"Kristina … \"This … <NA>   \n 4  2023     1 autotest: Automated testing o…   3000 \"Mark Padg… \"The p… <NA>   \n 5  2023     1 api2r: An R Package for Auto-…  15750 \"Jon Harmo… \"This … <NA>   \n 6  2022     2 D3po: R Package for Easy Inte…   8000 \"Mauricio … \"The D… <NA>   \n 7  2022     2 Tooling and Guidance for Tran…   8000 \"Maëlle Sa… \"Tooli… <NA>   \n 8  2022     2 Online Submission and Review …  22000 \"Simon Urb… \"The O… <NA>   \n 9  2022     2 Upgrading SatRdays Website Te…   6000 \"Ben Ubah\"  \"The U… <NA>   \n10  2022     2 Building the “Spatial Data Sc…  25000 \"Orhun Ayd… \"The B… <NA>   \n# ℹ 75 more rows\n```\n:::\n:::\n\n\nSome questions we initially thought about asking: \n\n- Are there any keywords that stand out in the titles or summaries of awarded grants? \n- Have the funded amounts changed over time?\n\nAs a fairly new user to R, Kennedy focused on the second question, creating a bar plot of funding over time using `ggplot`. Meanwhile, Clarke and Clark investigated and proposed some approaches for addressing the first question. \n\n## Graph of funding over time\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfunding_by_year <- isc_grants %>% \n  group_by(year) %>% \n  summarise(total_funded = sum(funded)) %>% \n  ungroup()\n \nfunding_by_year %>% \n  ggplot(aes(x=year, y=total_funded)) + \n  geom_col() + \n  labs(\n    x = \"Year\", \n    y = \"total funded in dollars\",\n    title = \"Total funding by year\",\n    caption = \"source: TidyTuesday\",\n    subtitle = \"2018 is a bit weird\" \n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nWe discussed piping with the `%>%` operator, and the value this has for being able to develop code step-by-step in a way similar to human languages. \n\n- We said, when we see `<-` or `->`, this should be read as 'is assigned to'.\n- And we said, when we see the `%>%` (or `|>`) operator in a script, this should be read as, `and then`. \n- We noted how R can tell when it encounters an incomplete expression, and so doesn't evaluate, just as when someone hears a sentence that ends 'and then', they know it's not really the end of the sentence. \n\nWe also discussed how when making a graph, we should consider how objective or how subjective we should be when presenting the image to the viewer. This will depend on the audience. In our example, the x axis, y axis, title and caption labels are all just objective information. However the subtitle is more subjective, and so more our opinion rather than something no one could reasonably disagree with. \n\n## Tidy Text to get important key words \n\nBrendan offered the following code chunk to explore the content of the free text summary field in the dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"tidytext\")\n#install.packages(\"SnowballC\")\nlibrary(tidytext)\nlibrary(SnowballC) # for wordStem\n \nisc_grants |>\n  unnest_tokens(word, summary) |>\n  anti_join(get_stopwords()) |>\n  mutate(stem = wordStem(word))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6,242 × 8\n    year group title                      funded proposed_by website word  stem \n   <dbl> <dbl> <chr>                       <dbl> <chr>       <chr>   <chr> <chr>\n 1  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    prop… prop…\n 2  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    most… most…\n 3  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    focu… focus\n 4  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    main… main…\n 5  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    supp… supp…\n 6  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    dbi   dbi  \n 7  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    dbit… dbit…\n 8  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    test  test \n 9  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    suite suit \n10  2023     1 The future of DBI (extens…  10000 Kirill Mül… <NA>    three three\n# ℹ 6,232 more rows\n```\n:::\n:::\n\n\nThis pulled out words (other than stopwords[^1]) from the summary field, and identified the stem of these words. This potentially means the number of unique stems can be compared, rather than the number of unique words. \n\n[^1]: Stop words are terms that are so common within sentences they don't really add much unique information. They're words like 'and', 'the', 'an', and so on. \n\nAntony suggested that, as the summaries are all about supporting a technical programing language, some additional words are also so common they should also be considered stopwords. He also produced a wordcloud visualisation showing the most common non-stopwords in the corpus of summary text\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tidytext with SnowballC ----\n\n# Tokenize the text\n\n\nmy_stop_words <- \n  bind_rows(\n    get_stopwords(),\n    tibble(\n      word = c(\"r\",\"package\",\"data\",\"users\",\"project\",\"cran\",\"community\",\"use\",\n               \"development\",\"documentation\",\"can\",\"also\",\"system\",\"new\",\"code\",\n               \"available\",\"existing\",\"support\",\"make\",\"two\",\"build\"),\n      lexicon = \"tony's custom stop words\"\n    )\n  )\n\nmy_stop_words <- \n  my_stop_words %>% \n  mutate(stem = wordStem(word))\n\ntokens <- \n  isc_grants %>%\n  unnest_tokens(word, summary) %>% \n  mutate(stem = wordStem(word)) %>% \n  anti_join(my_stop_words, by = \"stem\")\n\n\ntoken_frequency <- tokens %>% count(word) %>% arrange(-n)\n\n\n\n# View the processed stems\nwordcloud::wordcloud(words = token_frequency$word, \n          freq = token_frequency$n, min.freq = 1,\n          max.words = 20, random.order = FALSE, rot.per = 0.35, \n          colors = RColorBrewer::brewer.pal(8, \"Dark2\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}