{
  "hash": "fa66cddef9f2e9ed0f15ae5ef7e0cd63",
  "result": {
    "markdown": "---\ntitle: \"Tidy Tuesday: Solar Eclipses\"\ndate: \"2024-04-11\"\nauthor:\n  - \"Myriam Scansetti\"\n  - \"Nick Christofides\"\n  - \"Wei Fan\"\n  - \"Kennedy Owusu-Afriyie\"\n  - \"Jon Minton\"\ncategories: [R, Tidy Tuesday]\n---\n\n\nThe most recent TidyTuesday session looked at data about solar eclipses in the USA, and was led by Myriam. The repo readme is [here](https://github.com/rfordatascience/tidytuesday/tree/master/data/2024/2024-04-09)\n\n## Loading the data \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\n# Let's use the tidytuesdayR load package\n\nall_data <- tidytuesdayR::tt_load('2024-04-09')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n--- Compiling #TidyTuesday Information for 2024-04-09 ----\n--- There are 4 files available ---\n--- Starting Download ---\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDownloading file 1 of 4: `eclipse_annular_2023.csv`\n\tDownloading file 2 of 4: `eclipse_total_2024.csv`\n\tDownloading file 3 of 4: `eclipse_partial_2023.csv`\n\tDownloading file 4 of 4: `eclipse_partial_2024.csv`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n--- Download complete ---\n```\n:::\n:::\n\n\n\n## Tidying the data\n\nThe data are a list of dataframes. Each dataframe has a similar data structure. We decided to spend some time tidying these dataframes, then combining them again into a single dataframe with additional attributes \n\n\n::: {.cell}\n\n```{.r .cell-code}\neclipse_annular_2023 <- all_data$eclipse_annular_2023 |>\n    mutate(year = 2023, type = \"annular\") |>\n    pivot_longer(contains(\"eclipse\"), names_to = \"event_number\", values_to = \"event_datetime\")\neclipse_total_2024 <- all_data$eclipse_total_2024 |>\n    mutate(year = 2024, type = \"total\") |>\n    pivot_longer(contains(\"eclipse\"), names_to = \"event_number\", values_to = \"event_datetime\")\neclipse_partial_2023 <- all_data$eclipse_partial_2023 |>\n    mutate(year = 2023, type = \"partial\") |>\n    pivot_longer(contains(\"eclipse\"), names_to = \"event_number\", values_to = \"event_datetime\")\neclipse_partial_2024 <- all_data$eclipse_partial_2024 |>\n    mutate(year = 2024, type = \"partial\") |>\n    pivot_longer(contains(\"eclipse\"), names_to = \"event_number\", values_to = \"event_datetime\")\n\ndata_tidied <- bind_rows(\n    list(eclipse_annular_2023, eclipse_partial_2023, eclipse_total_2024, eclipse_partial_2024)\n) |>\n    mutate(event_number = str_remove(event_number, \"eclipse_\") %>% as.numeric())\n\ndata_tidied\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 325,881 × 8\n   state name           lat   lon  year type    event_number event_datetime\n   <chr> <chr>        <dbl> <dbl> <dbl> <chr>          <dbl> <time>        \n 1 AZ    Chilchinbito  36.5 -110.  2023 annular            1 15:10:50      \n 2 AZ    Chilchinbito  36.5 -110.  2023 annular            2 15:56:20      \n 3 AZ    Chilchinbito  36.5 -110.  2023 annular            3 16:30:29      \n 4 AZ    Chilchinbito  36.5 -110.  2023 annular            4 16:33:31      \n 5 AZ    Chilchinbito  36.5 -110.  2023 annular            5 17:09:40      \n 6 AZ    Chilchinbito  36.5 -110.  2023 annular            6 18:02:10      \n 7 AZ    Chinle        36.2 -110.  2023 annular            1 15:11:10      \n 8 AZ    Chinle        36.2 -110.  2023 annular            2 15:56:50      \n 9 AZ    Chinle        36.2 -110.  2023 annular            3 16:31:21      \n10 AZ    Chinle        36.2 -110.  2023 annular            4 16:34:06      \n# ℹ 325,871 more rows\n```\n:::\n:::\n\n\n\n## Graphing the data \n\nAs we do not expect cities/towns to move between years, we thought if we plotted the `lon` and `lat` as points we will get an impression of the USA \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |> \n    ggplot(aes(lon, lat)) + \n    geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIndeed we do! Though we thought it might be more straightforward to focus on the main US territory\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |>\n    filter(\n        between(lon, -150, -50),\n        between(lat, 22, 50)\n    ) |>\n    ggplot(aes(lon, lat)) + \n    geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe now have an indirect map/signal of population density in the USA! \n\n## Eclipse type in 2024\n\nWe explored the four different datasets using filtering. For 2024 the types were `total` and `partial`. They look as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |>\n    filter(\n        between(lon, -150, -50),\n        between(lat, 22, 50)\n    ) |>\n    filter(year == 2024) |>\n    filter(event_number == 1) |>\n    ggplot(aes(lon, lat)) + \n    geom_point() + \n    facet_wrap(~type)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWe realised `total` is a swathe of locations cut through the rest of the USA. We therefore thought it might be good to show the points coloured by whether they are flagged as `total` or `partial` in eclipse type\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |>\n    filter(\n        between(lon, -150, -50),\n        between(lat, 22, 50)\n    ) |>\n    filter(year == 2024) |>\n    filter(event_number == 1) |>\n    mutate(is_total = type == \"total\") |>\n    ggplot(aes(lon, lat)) + \n    geom_point(aes(colour = is_total))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nAnd that's where we got to. We recombined two datasets to show which parts of the USA were in the path of the total eclipse. (Nick mentioned that he'd seen data suggesting AirBnB prices were especially high for properties in this swathe!)\n\n\n## Going further \n\nWe could have looked at doing something similar with the `annular` and `partial` data for 2023:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |>\n    filter(\n        between(lon, -150, -50),\n        between(lat, 22, 50)\n    ) |>\n    filter(year == 2023) |>\n    filter(event_number == 1) |>\n    mutate(is_annular = type == \"annular\") |>\n    ggplot(aes(lon, lat)) + \n    geom_point(aes(colour = is_annular))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThis shows how the swathe the 2023 eclipse epicentre cut through the USA was different to the 2024 eclipse path.\n\nWe could also have made use of the datetime column to show how the eclipse happened at different times in different parts of the USA:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tidied |>\n    filter(\n        between(lon, -150, -50),\n        between(lat, 22, 50)\n    ) |>\n    filter(year == 2024) |>\n    filter(event_number == 1) |>\n    mutate(is_total = type == \"total\") |>\n    mutate(start_time = min(event_datetime)) |>\n    mutate(time_since_start = event_datetime - start_time) |>\n    ggplot(aes(lon, lat)) + \n    geom_point(aes(colour = time_since_start, alpha = is_total)) + \n    scale_alpha_manual(values = c(`FALSE` = 0.01, `TRUE` = 1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nDon't know how to automatically pick scale for object of type <difftime>.\nDefaulting to continuous.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nWe can see from this that the event seemed to start on the west coast and move east. \n\nFinally, we could have looked at adding a basemap.  \n\nI tried following [this tutorial](https://builtin.com/data-science/ggmap) to get a basemap using `ggmap`. Unfortunately, `ggmap` now requires registering API keys (and credit card details) with Google. So this exercise is as yet incomplete!",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}