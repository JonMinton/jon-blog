{
  "hash": "5a34b2060f27417e4dc08fd3b7df5df6",
  "result": {
    "markdown": "---\ntitle: \"Getting started with the infer package\"\nauthor: \"Jon Minton\"\ndraft: true\ndate: \"2024-07-16\"\nresampling-order: 4\ncategories: [statistics, r, hypothesis tests, resampling, bootstrapping, hacker stats]\n---\n\n\n## Introduction \n\nThis post continues a short series on resampling methods, sometimes also known as 'Hacker Stats', for hypothesis testing. To recap: resampling *with replacement* is known as **bootstrapping**. Resampling *without replacement* can be used for **permutation tests**: testing whether *apparent* patterns in the data, including *apparent* associations between variables in the data, could likely have emerged from the Null distribution. \n\nIn [a previous post introducing bootstrapping](../bootstrapping/index.qmd), I showed how the approach can be used to perform something like hypothesis tests for quantities of interest that aren't as easily amenable as means to being assessed parametrically, such as differences in medians. In [the next post, on resampling and permutation tests](../permutation-with-base-r/index.qmd), I described the intuition and methodology behind resampling with replacement to produce Null distributions, and how to implement the procedure using base R. \n\nIn this post, I show how [the infer package](https://infer.netlify.app/), can be used to perform both bootstrapping and permutation testing in a way that's slightly easier, and more declarative in the context of a general hypothesis testing framework. \n\n## Setting up\n\nLet's install the `infer` packge and try a couple of examples from the documentation. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"infer\") # First time around\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(infer)\n```\n:::\n\n\n\n## The infer package \n\nFrom [the vignette page](https://infer.netlify.app/articles/infer) we can see that `infer`'s workflow is framed around four verbs:\n\n- **`specify()`** allows you to specify the variable, or relationship between variables, that you’re interested in.\n- **`hypothesize()`** allows you to declare the null hypothesis.\n- **`generate()`** allows you to generate data reflecting the null hypothesis.\n- **`calculate()`** allows you to calculate a distribution of statistics from the generated data to form the null distribution.\n\nThe package describes the problem of hypothesis testing as being somewhat generic, regardless of the specific test, hypothesis, or dataset being used: \n\n> Regardless of which hypothesis test we’re using, we’re still asking the same kind of question: is the effect/difference in our observed data real, or due to chance? To answer this question, we start by assuming that the observed data came from some world where “nothing is going on” (i.e. the observed effect was simply due to random chance), and call this assumption our *null hypothesis*. (In reality, we might not believe in the null hypothesis at all—the null hypothesis is in opposition to the *alternate hypothesis*, which supposes that the effect present in the observed data is actually due to the fact that “something is going on.”) We then calculate a *test statistic* from our data that describes the observed effect. We can use this test statistic to calculate a *p-value*, giving the probability that our observed data could come about if the null hypothesis was true. If this probability is below some pre-defined *significance level $\\alpha$*, then we can reject our null hypothesis.\n\n\n## The gss dataset\n\nLet's look through - and in some places adapt - the examples used. These mainly make use of the `gss` dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(gss)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(gss)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 11\n$ year    <dbl> 2014, 1994, 1998, 1996, 1994, 1996, 1990, 2016, 2000, 1998, 20…\n$ age     <dbl> 36, 34, 24, 42, 31, 32, 48, 36, 30, 33, 21, 30, 38, 49, 25, 56…\n$ sex     <fct> male, female, male, male, male, female, female, female, female…\n$ college <fct> degree, no degree, degree, no degree, degree, no degree, no de…\n$ partyid <fct> ind, rep, ind, ind, rep, rep, dem, ind, rep, dem, dem, ind, de…\n$ hompop  <dbl> 3, 4, 1, 4, 2, 4, 2, 1, 5, 2, 4, 3, 4, 4, 2, 2, 3, 2, 1, 2, 5,…\n$ hours   <dbl> 50, 31, 40, 40, 40, 53, 32, 20, 40, 40, 23, 52, 38, 72, 48, 40…\n$ income  <ord> $25000 or more, $20000 - 24999, $25000 or more, $25000 or more…\n$ class   <fct> middle class, working class, working class, working class, mid…\n$ finrela <fct> below average, below average, below average, above average, ab…\n$ weight  <dbl> 0.8960034, 1.0825000, 0.5501000, 1.0864000, 1.0825000, 1.08640…\n```\n:::\n:::\n\n\nLet's go slightly off piste and say we are interested in seeing if there is a relationship between age, a cardinal variable, and sex, a categorical variable. We can start by stating our null and alternative hypotheses explicitly:\n\n- **Null hypothesis**: There is no difference between age and sex\n- **Alt hypothesis**: There is a difference between age and sex\n\nLet's see if we can start by just looking at the data to see if, informally, it looks like it might better fit the Null or Alt hypothesis. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss |> \n    ggplot(aes(x=age, group = sex, colour = sex)) + \n    geom_density()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nIt looks like the densities of age distributions are similar for both sexes. However, they're not identical. Are the differences more likely to be due to chance, or are they more structural? \n\nWe can start by calculating, say, the differences in average ages between males and females:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss |>\n    group_by(sex) |>\n    summarise(n = n(), mean_age = mean(age))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  sex        n mean_age\n  <fct>  <int>    <dbl>\n1 male     263     40.6\n2 female   237     39.9\n```\n:::\n:::\n\n\n## Our first testable hypothesis (using permutation testing/sampling without replacement)\n\nThe mean age is `40.6` for males and `39.9` for females, a difference of about `0.7` years of age. Could this have occurred by chance?\n\nThere are `263` male observations, and `237` female observations, in the dataset. Imagine that the ages are values, and the sexes are labels that are added to these values. \n\nOne approach to operationalising the concept of the Null Hypothesis is to ask: *If we shifted around the labels assigned to the values, so there were still as many male and female labels, but they were randomly reassigned, what would the difference in mean age between these two groups be? What would happen if we did this many times?*\n\nThis is the essence of building a Null distribution using a permutation test, which is similar to a bootstrap except it involves resampling with replacement rather than without replacement. \n\nWe can perform this permutation test using the infer package as follows: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- gss |>\n    specify(age ~ sex) |>\n    hypothesize(null = 'independence') |>\n    generate(reps = 10000, type = 'permute')\n\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: age (numeric)\nExplanatory: sex (factor)\nNull Hypothesis: independence\n# A tibble: 5,000,000 × 3\n# Groups:   replicate [10,000]\n     age sex    replicate\n   <dbl> <fct>      <int>\n 1    28 male           1\n 2    52 female         1\n 3    53 male           1\n 4    31 male           1\n 5    18 male           1\n 6    42 female         1\n 7    57 female         1\n 8    48 female         1\n 9    20 female         1\n10    41 female         1\n# ℹ 4,999,990 more rows\n```\n:::\n:::\n\n\nThe infer package has now arbitrarily shifted around the labels assigned to the age values 10000 times. Each time is labelled with a different replicate number. Let's take the first nine replicates and show what the densities by sex look like: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel |>\n    filter(replicate <= 9) |>\n    ggplot(aes(x=age, group = sex, colour = sex)) + \n    geom_density() + \n    facet_wrap(~replicate)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWhat if we now look at the differences in means apparent in each of these permutations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel |>\n    calculate(stat = \"diff in means\", order = c(\"male\", \"female\")) |>\n    visualize()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nHere we can see the distribution of differences in means follows broadly a normal distribution, which appears to be centred on 0. \n\nLet's now calculate and save the observed difference in means.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp <- gss |>\n    group_by(sex) |>\n    summarise(mean_age = mean(age))\n\ntmp \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  sex    mean_age\n  <fct>     <dbl>\n1 male       40.6\n2 female     39.9\n```\n:::\n\n```{.r .cell-code}\ndiff_means <- tmp$mean_age[tmp$sex == \"male\"] - tmp$mean_age[tmp$sex == \"female\"]\n\ndiff_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7463541\n```\n:::\n:::\n\n\n### A two-sided hypothesis\n\nLet's now show where the observed difference in means falls along the distribution of differences in means generated by this permutation-based Null distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel |>\n    calculate(stat = \"diff in means\", order = c(\"male\", \"female\")) |>\n    visualize() +\n    shade_p_value(obs_stat = diff_means, direction = \"two-sided\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe observed difference in means appears to be quite close to the centre of mass for the distribution of differences in means generated by the Null distribution. So it appears very likely that this observed difference could be generated from a data generating process in which there's no real difference in mean ages between the two groups. We can formalise this slightly by calcuating a p-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel |>\n    calculate(stat = \"diff in means\", order = c(\"male\", \"female\")) |>\n    get_p_value(obs_stat = diff_means, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  p_value\n    <dbl>\n1   0.535\n```\n:::\n:::\n\n\nThe p value is much, much greater than 0.05, suggesting there's little evidence to reject the Null hypothesis, that in this dataset age is not influenced by sex. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}