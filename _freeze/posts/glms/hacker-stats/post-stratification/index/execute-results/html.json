{
  "hash": "583b65c857e6bd71b1d844eb84809551",
  "result": {
    "markdown": "---\ntitle: \"Resampling for post-stratification\"\nauthor: \"Jon Minton\"\ndate: \"2024-07-23\"\nresampling-order: 5\ncategories: [statistics, r, hypothesis tests, resampling, bootstrapping, post-stratification, hacker stats]\ncode-fold: true\nwarning: false\nmessage: false\n---\n\n\n## Introduction\n\nIn [the introductionary post](../resampling-approaches-intro/index.qmd) in this series on Hacker Stats, I mentioned that resampling methods can be used to perform post-stratification, meaning reweighting of observations from a sample in such a way as to make them more representative of the population of interest to us. Let's look at this using a  variation of the [red coin/blue coin](../permutation-with-base-r/index.qmd) example from a couple of posts ago.\n\n## Red Coin/Blue Coin\n\nImagine we have a **population** of two types of coin:\n\n-   **Red Coins**, which come up heads 65% of the time\n-   **Blue Coins**, which come up heads 47% of the time\n\nWithin our *population*, we know 75% of the coins are **Blue coins**, and 25 of the coins are **Red Coins**.\n\nHowever, our sample contains 20 red coins, and 20 blue coins. i.e. the distribution of coin types in our sample is different to that in our population.\n\nLet's first create this sample dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nset.seed(9)\n\ndraws_red <- rbinom(n=20, size = 1, prob = 0.65)\ndraws_blue <- rbinom(n=20, size = 1, prob = 0.47)\n\ncoin_colour <- c(\n    rep(\"red\", 20),\n    rep(\"blue\", 20)\n)\n\nreal_sample_data <- data.frame(\n    coin_colour = coin_colour, \n    outcome = c(draws_red, draws_blue)\n)\n\nrm(draws_red, draws_blue, coin_colour)\n\nhead(real_sample_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  coin_colour outcome\n1         red       1\n2         red       1\n3         red       1\n4         red       1\n5         red       1\n6         red       1\n```\n:::\n:::\n\n\nWhat's the expected probability of heads in the sample?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(real_sample_data$outcome)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.65\n```\n:::\n\n```{.r .cell-code}\nreal_sample_data |>\n    group_by(coin_colour) |>\n    summarise(prop = mean(outcome))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 2\n  coin_colour  prop\n  <chr>       <dbl>\n1 blue          0.5\n2 red           0.8\n```\n:::\n:::\n\n\nOverall, 65% of the sample - 20 reds, 20 blues - are heads. The proportion of blues is 50%, and of reds is 80%. So, it so happens that, with this random number seed, the proportions in the sample of both reds and blues are higher than the theoretical average (the `prob` value arguments in the code above).\n\nLet's now try to use bootstrapping to calculate a distribution around the sample mean:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_means <- function(x, nReps = 10000){\n    out <- vector(\"numeric\", nReps) \n\n    for (i in 1:nReps){\n        this_resample <- sample(\n            x=x, \n            size = length(x), \n            replace = TRUE # This is what makes it bootstrapping\n        )\n        out[i] <- mean(this_resample)\n    }\n    out\n}\n\nbootstrapped_means <- bootstrap_means(real_sample_data$outcome)\n\nhead(bootstrapped_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.750 0.625 0.700 0.775 0.800 0.700\n```\n:::\n:::\n\n\nWhat does this look like as a histogram?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(value = bootstrapped_means) |>\n    ggplot(aes(x = value)) + \n    geom_histogram(bins = 50)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe can see the familiar bell-shaped distribution of values here. What about for blues and reds separately?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrapped_means_reds <- bootstrap_means(\n    real_sample_data |>\n        filter(coin_colour == \"red\") |>\n        pull('outcome')  \n    )\n\nbootstrapped_means_blues <- bootstrap_means(\n    real_sample_data |>\n        filter(coin_colour == \"blue\") |>\n        pull('outcome')  \n    )\n\n\n\n\nhead(bootstrapped_means_reds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.65 0.70 0.85 0.85 1.00 0.60\n```\n:::\n\n```{.r .cell-code}\nhead(bootstrapped_means_blues)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.45 0.60 0.50 0.45 0.70 0.55\n```\n:::\n:::\n\n\nAnd what do these two distributions look like?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n    rep = 1:length(bootstrapped_means_reds),\n    red = bootstrapped_means_reds,\n    blue = bootstrapped_means_blues\n) |>\n    pivot_longer(\n        cols = c(red, blue),\n        names_to = \"colour\",\n        values_to = \"value\"\n    ) |>\n    ggplot(aes(x = value, fill = colour)) + \n    geom_histogram(bins = 50, position = \"dodge\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nSo it's clear the distributions for mean values of the two different coin types are different, even though there's some overlap.\n\nLet's now look at doing some post-stratification, where we sample from the two groups in proportion to the relative probabilities of encountering observations from the two groups in *the population* as compared with *the sample*. Let's think through what this means:\n\n| Group      | Sample | Population | Ratio |\n|------------|--------|------------|-------|\n| Blue       | 0.5    | 0.75       | $3/2$ |\n| Red        | 0.5    | 0.25       | $1/2$ |\n| Column Sum | 1.00   | 1.00       |       |\n\n: Proportions by group in sample and population\n\nIn this table, the ratio is the row-wise ratio of the population value divided by the sample value. Note that the ratios have a common denominator, 2, which we can drop in defining the probability weights, leaving us with `3` for `blue` and `1` for `red`.\n\nWe can adapt the standard bootstrapping approach by using the `prob` argument in the `sample()` function, using these weights:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_weights <- \n    tibble(\n        coin_colour = c(\"blue\", \"red\"),\n        wt = c(3, 1)\n    )\n\nreal_sample_data_wt <- \n    left_join(\n        real_sample_data, sample_weights\n    )\n\nreal_sample_data_wt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   coin_colour outcome wt\n1          red       1  1\n2          red       1  1\n3          red       1  1\n4          red       1  1\n5          red       1  1\n6          red       1  1\n7          red       1  1\n8          red       1  1\n9          red       0  1\n10         red       0  1\n11         red       1  1\n12         red       1  1\n13         red       0  1\n14         red       1  1\n15         red       1  1\n16         red       1  1\n17         red       1  1\n18         red       0  1\n19         red       1  1\n20         red       1  1\n21        blue       1  3\n22        blue       0  3\n23        blue       0  3\n24        blue       0  3\n25        blue       0  3\n26        blue       1  3\n27        blue       0  3\n28        blue       0  3\n29        blue       1  3\n30        blue       1  3\n31        blue       0  3\n32        blue       1  3\n33        blue       0  3\n34        blue       1  3\n35        blue       0  3\n36        blue       1  3\n37        blue       1  3\n38        blue       1  3\n39        blue       0  3\n40        blue       1  3\n```\n:::\n:::\n\n\nAnd now a slightly modified version of the bootstrapping function: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_means_wt <- function(x, wt, nReps = 10000){ #wt is the weighting\n    out <- vector(\"numeric\", nReps) \n\n    for (i in 1:nReps){\n        this_resample <- sample(\n            x=x, \n            size = length(x), \n            prob = wt, # This is the new argument\n            replace = TRUE # This is what makes it bootstrapping\n        )\n        out[i] <- mean(this_resample)\n    }\n    out\n}\n```\n:::\n\n\nAnd to run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrapped_means_poststratified <- bootstrap_means_wt(\n    x = real_sample_data_wt$outcome,\n    wt = real_sample_data_wt$wt\n)\n\nhead(bootstrapped_means_poststratified)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.750 0.550 0.625 0.525 0.575 0.600\n```\n:::\n:::\n\n\nNow, analytically, we can calculate what the mean of the population should be given the proportion of blues and reds, and the proportion of blues that are heads, and proportion of reds that are heads: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nheads_if_blue <- 0.47\nheads_if_red <- 0.65\n\nexpected_pop_prop_heads <- (3/4) * heads_if_blue + (1/4) * heads_if_red\n\nexpected_pop_prop_heads\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.515\n```\n:::\n:::\n\n\nSo within the population we would expect 51.5% of coins to come up heads. \n\nLet's now look at the bootstrapped and reweighted distribution to see where 0.515 fits within this distribution:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n    geom_histogram(aes(x = bootstrapped_means_poststratified), bins=50) + \n    geom_vline(aes(xintercept = expected_pop_prop_heads), linewidth = 1.2, colour = \"purple\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nSo we can see that the true population mean falls within the reweighted bootstrapped distribution of the values of the mean estimated. How about if we had not performed reweighting on the sample?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(value = bootstrapped_means) |>\n    ggplot() + \n    geom_histogram(aes(x = value), bins=50) + \n    geom_vline(aes(xintercept = expected_pop_prop_heads), linewidth = 1.2, colour = \"purple\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nSo, although on this occasion, the true population value is also within the range of the un-reweighted bootstrapped distribution, it is further from the centre of this distribution's mass. \n\nLet's give some numbers to the above. What proportion of the bootstrapped values are below the true population value?\n\nFirst without reweighting:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(bootstrapped_means < expected_pop_prop_heads)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0343\n```\n:::\n:::\n\n\nOnly about 3.4% of the means from the unweighted bootstrapping were more extreme than the true population value. \n\nAnd now with reweighting:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(bootstrapped_means_poststratified < expected_pop_prop_heads)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2102\n```\n:::\n:::\n\n\nNow 22.4% of values of the means from the reweighted/post-stratified bootstrapped distribution are below the true value. This is the difference between the true value being in the 90% central interval or not. \n\n\n## Summary\n\nIn this post we've illustrated the importance of post-stratifying data were we know a sample is biased in terms of the relative weight given to the strata it contains as compared with the population. We've also shown, using Base R functions alone, how to perform this post-stratification using just two additional changes: a vector of weights, which was fairly straightforward to calculate; and the passing of this vector of weights to the `prob` argument in the `sample()` function. \n\nIn this post we've focused on a hypothetical example, and built the requisite functions and code from scratch. In practice, packages like [`survey` can be used to perform post-stratification in fewer lines](https://stats.oarc.ucla.edu/r/faq/how-do-i-analyze-survey-data-with-stratification-after-sampling-poststratification/), [`svrep`](https://cran.r-project.org/web/packages/svrep/vignettes/bootstrap-replicates.html), and [boot](https://cran.r-project.org/web/packages/boot/index.html) can make the process much more straightforward. ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}