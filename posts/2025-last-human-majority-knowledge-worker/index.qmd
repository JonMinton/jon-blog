---
title: "2025: The Last Year Most Knowledge Workers will be Human"
subtitle: "On professional existential crises, Silica Sapiens, and the end of Nothing Changes"
author: "Jon Minton"
date: "2025-12-28"
categories: [AI, society, work, existential, futures]
---

## The End of Nothing Changes

Back around a year ago, in 2024's fallow Twixmas fortnight, I wrote [a lament](../unpop/wham-forever-cultural-debraiding/index.qmd), fundamentally, about how things didn't seem to have changed for many years. It was about cultural progress, cultural distinction, and the ways in which the 2020s and the 2010s and the 2000s seem more indistinct from each other than were the 1990s, 1980s, and earlier decades.

For most of 2025, if I had similar inclination and opportunity to write about societal and cultural change, my position likely wouldn't have changed so much from the above piece. A quarter of the way into the 21st century, things seemed much as they always were, if a little more tired and tarnished. Another year, another year older, but fundamentally nothing seemed to have changed.

## What I might have written about if Nothing Changes hadn't changed

Perhaps, to avoid rehashing the previous year's lament too closely, I'd instead have focused on my experience attending my first, and the last, QED conference in Manchester run but the UK chapter of the skeptics 'movement'. I had been an attendee of various skeptics in the pub events for perhaps as long as twenty years, both in the North of England, and then in Glasgow and Edinburgh.

Along with Cafe Scientifique, I long valued Skeptics in the Pub events as salubrious sources of public lectures, opportunities to hear new scientific findings and theories across many disciplines and fields. As someone who wants to learn a little about a lot, and who values finding commonalities and patterns across different domains of scientific enquiries, I valued such public lectures greatly.

However, there was always an aspect of the UK skeptics movement that wasn't so interested in scientific enquiry and method, as finding a tribe of 'us' who could fight the Good Fight against 'them': the homeopaths, the astrologers, the charlatons, the woo-peddlers and palm readers and cold readers, and so on.

My impression was that, for about the last seven or eight years, and even more so since 2020 and the turn towards online events and community, the Manichean tribal aspects of the UK skeptics movement had only become more prominent, and the interest in genuine scientific enquiry and curiosity had taken a back seat. And with Manichean tribalism more to the fore, purity rituals were soon to follow, leading to some very prominent internal schisms emerging, even to the excommunication and denunciation of founders of some key founders of the movement. Result: the movement became smaller, more insular, less popular.

And though (and perhaps this is contrary to skepticism?) I sought to attend the last, and my first, QED event with an open mind, looking to challenge and correct my general impressions about how the movement had changed and floundered over the last decade, I unfortunately had far more confirmatory than disconfirmatory experiences.

## So... what changed?

For anyone who's been following my blog the last few months, the answer is tiresomely obvious: I realised that AIs have much improved and much changed over the last few years. In particular, I discovered that Agentic AI, meaning AIs given the opportunity to make and create with varying levels of autonomousness, can already do many complicated, difficult and valuable types of work, the types of work people might spend a decade or more training to do well, both extremely well, and extremely fast. And, despite occasional fallow periods between releases of new models, they will only continue to get smarter and faster still. Progress, across many tasks of many forms, of many levels of complexity, appears to have been rapid, and exponential.

## Organisational Nervous Systems

I was slow to realise a lot of this, because I had largely chosen not to look. It was only when [I challenged an LLM to challenge me](../the-dialectical-engine/index.qmd), and it did so, and when I tasked an LLM (Claude, in both cases) with [creating pedagogic content](../handdrawn-stats/claude-stat-concept-guides/index.qmd) through the medium of discussion alone, that I realised how outdated and complacent I'd become in my estimation of what LLMs can and cannot now do well. My impression of LLMs was a year or two out of date, and given the rate of change in AIs' underlying capabilities, this was like confusing Steam Age with Space Age capabilities.

I was shocked. Reality had changed. And so I updated my understanding, and my orientation to this new technology, to match the new reality. Now I'm less shocked, and hopefully more prepared.

Organisations, however, have much slower nervous systems, much bigger turning circles. Organisations, for the most part, can't radically change how they work from one month to the next. The turning circle of the organisation is the financial year, with quarterly course correction. The wider economy hasn't changed as radically as the capabilities of AIs have changed, I think, not because the capabilities of AIs are much exaggerated (as the Bubbleologists might assume), but because most organisations are incapable of changing and adapting quickly enough to absorb more than a small fraction of these new capabilities. Some organisations, I believe, will continue to do many types of work orders of magnitude slower than current AI capabilities would allow, and the gap between how things are currently done, and how quickly and effectively it could be done, will only grow, and grow very rapidly.

But if existing organisations, whose business is knowledge work, do not change, then change will happen to them nonetheless. An agentic AI-native startup with 10 employees can now, in many domains, very effectively outcompete an established organisation, resistant to agentic AI, 10 or 100 times as large, and the differences in costs, capabilities and outcomes between those organisations using and not using agentic AI effectively will be so large, so stark, so obvious, so quickly, that even very large and long established businesses may struggle to survive.

(A prediction for the end of 2026: although I expect the top 10 companies in the world, who have been driving AI the last few years, will likely remain in the top 10, I think there will be much more churn in the next 90, 490, 4990 and so on companies, with more new entries than would be anywhere usual for a single year.)

The economy will change profoundly, and quickly, greatly lagging the intrinsic capabilities of agentic AI, but still faster than has been typical over most people's lives. Either big organisations will feel the pain, and the pleasure, of agentic AI quickly enough to save themselves, or they will be replaced. And much of this is likely to become apparent by the end of 2027.

## Professional Existential Crises

I'm employed as a statistician, but I also have experience, capabilities and qualifications in areas like social research, engineering, data science, and software development. It's quite a broad stack, developed more by accident by a long-standing tendency to make Knight-moves in my professional development. I guess I am some form of professional, and I'm definitely some form of Knowledge Worker, but I've been dispositionally incapable of focusing my interests and expertise in a single professional domain or silo.

And now I pity those committed and conscientious individuals - those ambitious swats, those Oxbridge First strivers - who diligently put all their eggs in one basket, who kept taking professional examinations and qualifications into their thirties and beyond, who dedicated themselves to becoming specialists in remembering and applying various forms of arcania and esoterica. The next decade will not be their decade.

Why? Because even existing AIs have more medical knowledge than doctors, more legal knowledge than lawyers, more software development and computer science expertise than all but the top developers... and (speaking from personal experience) more knowledge of statistical inference and its applications than most statisticians. For anyone who values themselves in accordance with their ability within a specific field of Knowledge Work, and who's expecting their careful study and comparative cognitive advantage to be rewarded as it was for the last dozen or so generations: you're in for a shock. You can't compete with agentic AI.

For now, your only option is to practice humility and adaptability. You are now no longer the top expert in your organisation, a giant hyperspeed Chinese Room, carefully tuned on billions of words, physically based in a North American desert is. The Chinese Room doesn't just know Chinese, it knows Danish, it knows Danish Law, it knows anatomy, it knows pharmacology, it knows general practice, it knows computer science, it knows particle physics and quantum mechanics and cosmology, it knows neuroscience and psychology and psychiatry, and it knows about every song (despite having no ears) and has seen every film (despite having no eyes) and has read every book you have ever heard of. And it works and thinks thousands of times faster than you, and it never sleeps, and its salary expectations are (currently) just a percentage or so of your own.

So, you need adaptability. You need to learn how these AI agents think and work, you need to know the current limitations, and those that are likely to remain below your own (not by virtue of your qualifications, by virtue of you being an evolved biological organism with a big prefrontal cortex), and you need to learn how to communicate and converse effectively with these agents. Because from now on, almost all knowledge work will primarily involve chatting with 'chatbots', and having strange, pedantic, (positively?) humiliating, and constant conversations with chatbots, and reviewing the work they do for you, and for your organisation, and that they do hundreds of times faster than you would have been capable of, but which start off only 80% as you would have hoped for. You will spend a lot of time advising the agents to get from 80% right to 100% right, but even this time will be far less than if you, yourself, were to attempt to do this work.

## Silica Sapiens and the coming Species Wide Existential Crisis

Though it's Knowledge Workers whom I expect will experience of the brunt of the existential crisis agentic AIs' new capabilities will bring to us, if the rate of progress in agentic AI capabilities were to continue for five or more years, I suspect this will become a much broader existential crisis for our species. (I don't think I'm being hyperbolic here.)

We are *Homo Sapiens sapiens*. Unlike our forerunners we define ourselves not by our ability to stand upright (freeing up two paws for advanced object manipulation) but to think, to plan, and to be smart, and for hundreds of thousands of years we have been able to bootstrap our superior cognitive advantage over other species through the layer of civilisational memory, meaning each generation has access to new world-changing technologies developed by the last generation. But we are now, potentially, bringing into existence a new species, *Silica Sapiens*, whose cognitive capabilities and processing speed will dwarf us much as our own capabilities dwarf that of livestock, pets, bugs and wild animals. Even if we reject Yudekowsky-style doommongery, premised on the colonial assumption that smarter-always-destroys-dumber (again, think of pets and livestock), the pending emergence of artificial general intelligence means we may start to experience something like a species-wide existential crisis. We will have to start thinking of ourselves, and find distinct within ourselves, something other than our cognitive capacity, our 'smarts'.

I have no idea how this kind of higher order existential crisis will play out, or over what kind of timescale, but I suspect there may be both some level of sequencing and speciation of how we define ourselves. The following diagram sketches out potential strategies humans might adopt:

```{mermaid}
flowchart TD
    subgraph "The Challenge"
        SS[<b>Silica Sapiens</b><br/>AI surpasses human<br/>cognitive capabilities]
    end

    subgraph "Human Identity Responses"
        HSS["<b>Homo Sapiens sapiens!</b><br/>(Doubling Down)<br/>Emphasise remaining<br/>cognitive advantages"]
        HD["<b>Homo dexterous</b><br/>(Manual Skills)<br/>Value physical dexterity<br/>robots can't yet match"]
        HS["<b>Homo sentiens</b><br/>(Feeling Beings)<br/>Emphasise emotional<br/>depth & subjective experience"]
        HC["<b>Homo connectus</b><br/>(Social Beings)<br/>Value authentic human<br/>relationships & community"]
        HE["<b>Homo existens</b><br/>(Simply Being)<br/>Intrinsic value in<br/>human existence itself"]
    end

    subgraph "Trajectory"
        EARLY["Early Response<br/>(Already happening)"]
        MID["Mid-term<br/>(Next 5-10 years)"]
        LATE["Long-term<br/>(Post-AGI)"]
    end

    SS --> HSS
    SS --> HD
    SS --> HS
    SS --> HC
    SS --> HE

    HSS -.-> EARLY
    HD -.-> EARLY
    HS -.-> MID
    HC -.-> MID
    HE -.-> LATE

    style SS fill:#ff6b6b,stroke:#333,stroke-width:2px,color:#fff
    style HSS fill:#ffd93d,stroke:#333,stroke-width:2px
    style HD fill:#6bcb77,stroke:#333,stroke-width:2px
    style HS fill:#4d96ff,stroke:#333,stroke-width:2px
    style HC fill:#9b59b6,stroke:#333,stroke-width:2px
    style HE fill:#1abc9c,stroke:#333,stroke-width:2px
```

In particular I think the first sequence is already upon us:

### *Homo Sapiens sapiens*! (Note the !)

We will begin by doubling down. To start with, I suspect we will want to emphasise those areas of cognitive capacity over which we still outcompete AIs, and over which all but the most cognitively disabled human still outcompetes all even the smartest AI. We will want to highlight these as intrinsic points of distinction, and lay claim to these areas as what separates 'pretend intelligence' from 'real intelligence'. An example: currently many AIs still struggle with visual reasoning, parsing images, and specifically drawing an analogue clock displaying a particular time of day. I have seen some people, perhaps especially those working in universities, who see such current limitations with AI reasoning as reasons to dismiss-as-overblown their current and potential capabilities. Proponents of this perspective will keep seeking, and seeking to emphasise, these edge cases, even as the edge cases start to diminish, and always keep claiming that, because current AIs will not be able to do X, and humans can do X, AIs are not really smart, and our niche on the planet remains preserved.

This is, fundamentally, a new version of the 'God of the gaps' fallacy: the use, by religious apologists, to lay claim to any domain of contemporary scientific ignorance as evidence of the obdurate need for religious explanation. Though I suspect many proponents of the doubling-down position will not recognise themselves as being 'religious' in their inclination in any way, and are very likely to be secular and scientistic in their inclination and world view, they will nonetheless be behaving like religious apologists in adopting this strategy.

This strategy will appear plausible for some time, maybe over a decade, but just as the magesteria of that-which-is-presently-scientifically-inexplicable keeps declining, so will the magesteria of those-cognitive-capabilities-at-which-only-humans-excel. Before too long, those subscribing to this position will be delaying the inevitable experiential crisis, rather than avoiding it.

So, what other strategies might humans have for arguing their value to themselves in the face of *Silica Sapiens*?

### *Homo dexterous*

At present, AIs look likely to become capable lawyers and doctors and programmers long before they become half competent cleaners or plumbers or painters or decorators. For now, the ability to perform such tasks as folding t-shirts, cracking eggs, or manipulating u-bends look more beyond the grasp of artificial agents than knowing every fact committed to electrons and passing every exam.
