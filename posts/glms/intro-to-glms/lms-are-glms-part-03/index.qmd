---
title: "Part Three: glm is just fancy lm"
author: "Jon Minton"
date: "2023-12-2"
categories: [statistics, R]
part-id: 3
bibliography: references.bib
---

## tl;dr

This is part of a series of posts which introduce and discuss the implications of a general framework for thinking about statistical modelling. This framework is most clearly expressed in @KinTomWit00.

## Part 3: How to express a linear model as a generalised linear model

In [the last part](../lms-are-glms-part-02/index.qmd), we introduced two types of generalised linear models, with two types of transformation for the systematic component of the model, `g(.)`, the logit transformation, and the identity transformation. This post will show how this framework is implemented in practice in R.

In R, there's the `lm` function for linear models, and the `glm` function for generalised linear models.

I've argued previously that the standard linear regression is just a specific type of generalised linear model, one that makes use of an identity transformation `I(.)` for its systematic component `g(.)`. Let's now demonstrate that by producing the same model specification using both `lm` and `glm`.

We can start by being painfully unimaginative and picking using one of R's standard datasets

```{r}
library(tidyverse)

iris |> 
  ggplot(aes(Petal.Length, Sepal.Length)) + 
  geom_point() + 
  labs(
    title = "The Iris dataset *Yawn*",
    x = "Petal Length",
    y = "Sepal Length"
  ) + 
  expand_limits(x = 0, y = 0)

```

It looks like, where the petal length is over 2.5, the relationship with sepal length is fairly linear

```{r}
iris |> 
  filter(Petal.Length > 2.5) |> 
  ggplot(aes(Petal.Length, Sepal.Length)) + 
  geom_point() + 
  labs(
    title = "The Iris dataset *Yawn*",
    x = "Petal Length",
    y = "Sepal Length"
  ) + 
  expand_limits(x = 0, y = 0)

```

So, let's make a linear regression just of this subset

```{r}
iris_ss <- 
  iris |> 
  filter(Petal.Length > 2.5) 
```

We can produce the regression using `lm` as follows:

```{r}
mod_lm <- lm(Sepal.Length ~ Petal.Length, data = iris_ss)
```

And we can use the `summary` function (which checks the type of `mod_lm` and evokes `summary.lm` implicitly) to get the following:

```{r}
summary(mod_lm)
```

Woohoo! Three stars next to the `Petal.Length` coefficient! Definitely publishable!

To do the same using `glm`.

```{r}
mod_glm <- glm(Sepal.Length ~ Petal.Length, data = iris_ss)
```

And we can use the `summary` function for this data too. In this case, `summary` evokes `summary.glm` because it knows the class of `mod_glm` contains `glm`.

```{r}
summary(mod_glm)
```

So, the coefficients are exactly the same. But there's also some additional information in the summary, including on the type of 'family' used. Why is this?

If we look at the help for `glm` we can see that, by default, the `family` argument is set to `gaussian`.

And if we delve a bit further into the help file, in the details about the family argument, it links to the `family` help page. The usage statement of the `family` help file is as follows:

```         
family(object, ...)

binomial(link = "logit")
gaussian(link = "identity")
Gamma(link = "inverse")
inverse.gaussian(link = "1/mu^2")
poisson(link = "log")
quasi(link = "identity", variance = "constant")
quasibinomial(link = "logit")
quasipoisson(link = "log")
```

Each family has a default `link` argument, and for this `gaussian` family, this link is the identity function.

We can also see that, for both the `binomial` and `quasibinomial` family, the default link is `logit`, which transforms all predictors onto a 0-1 scale, as shown in the last post.

So, by using the default family, the Gaussian family is selected, and by using the default Gaussian family member, the identity link is selected.

We can confirm this by setting the family and link explicitly, showing that we get the same results

```{r}
mod_glm2 <- glm(Sepal.Length ~ Petal.Length, family = gaussian(link = "identity"), data = iris_ss)
summary(mod_glm2)
```

It's the same!

How do these terms used in the `glm` function, `family` and `link`, relate to the general framework in @KinTomWit00?

-   `family` is the stochastic component, `f(.)`
-   `link` is the systematic component, `g(.)`

They're different terms, but it's the same broad framework.

Linear models are just one type of general linear model![^1]

### Coming up

In [the next part](../lms-are-glms-part-04/index.qmd) of this series, we will delve into the differences between linear regression models and logistic regression models, with a focus on how to get meaningful effect estimates from both types of model.

[^1]: **Note from Claude:** For Python users, the equivalent functionality is available through multiple libraries. The statsmodels library most closely mirrors R's approach: `statsmodels.api.GLM(y, X, family=sm.families.Gaussian())` is equivalent to R's `glm(y ~ x, family=gaussian())`. For production ML workflows, scikit-learn provides `LinearRegression()` and `LogisticRegression()` with simpler APIs but less statistical detail. The fast.ai course "Practical Deep Learning for Coders" demonstrates how these GLM concepts scale to deep learning, showing that even complex neural networks follow the same fit-predict-evaluate loop described in this series.
