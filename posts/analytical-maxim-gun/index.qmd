---
title: The Analytical Maxim Gun
subtitle: Some thoughts about integrated AI and the future of knowledge
author: Jon Minton
date: 2025-11-29
categories: [AI, futurism, elitism, history, guns, inequality, tradition]
---

The Analytical Maxim Gun: Some thoughts about integrated AI and the future of knowledge

The last few weeks I've found myself thinking increasingly, increasingly intensively, about AI. For those who've been following this blog, the timing of my stepchange  in perspective is likely easy to track: 
firstly, it was when I saw The Thinking Game, which made clear to me:
firstly that LLMs and AIs are not synonyms, and that for AIs trained on problems with more objective loss functions, the progress is harder to argue against;
secondly that if one compares the capabilities of AIs two or more years apart, the differences tend to be utterly spectacular.
Secondly, when a noticed Claude adopt what I'd call a 'dialectical stance' in a conversation with me, turning the tables on me, asking my probing and skeptical follow-up questions, rather than - as with the stereotype - being simply pathologically affirming and sychophantic.
Some specific things I've been thinking about:
How much the current stock market bull run (which has recently taken a sizeable stumble, wiping out about a month's worth of growth in a week) is driven by extremely high expectations about AI, and the extent to which these may be irrational;
How integrated such systems have already become into modern technologies;
Just how rapidly they've been developing, and about the risks for ourselves of assuming linear trends given exponential progress across many domains;
How many of skills and professions we value may no longer be fit for purpose, and the various academic rites of passage, and measures of excellence, which are currently valued, may soon find themslves largely useless (or worse).
This last couple of weeks I managed to tear myself away from the screen, however, and attend two talks by 'public intellectuals':
On Wednesday XXX, a talk by Jon Ronson, loosely based on his book The Psychopath Test (in which he argued that, at least in terms of glibness and superficial charm, ChatGPT may be a psychopath..)
Saturday XXX, a talk by historian David Olusoga [?], called A Gun Through Time, about the ways that the invention of specific types of firearm have profoundly affected geopolitics, culture, and the modern world. 
A Gun Through Time covered four British-invented firearms - The Musket; the Lee-Enfield; The Thompson submachine gun; and the Maxim machine-gun. It focused on the last two of these firearms, with the longer first half focused on the Thompson gun (developed in the late 1910s), and the shorter second half focused on the Maxim gun (developed in the 1880s).  
Though much shorter than the first half, the arguments proposed by Olusoga on the Maxim gun, and how it changed the world. struck me as much more impactful, and convincing, and I fear applicable, for how we might try to understand the impact of AI in the present era. 
In a way, it's all about speed. 
From my understanding (based on theory alone; based on the polls taken at the talk I seemed to be in a minority of the audience, in that I have never fired a firearm), a firearm is a means of initiating and focusing a controlled explosion such that an explosive force is directed such as to rapidly accelerate a dense projectile in a particular direction. And doing this involves: 
A trigger, meaning some aspect of a device that presents itself clearly to the user as an affordance, something that can be 'activated', and that exists clearly in an active or inactive state at any time; activating the trigger then cascades to:
A transmission mechanism, which occurs immediately, or near immediately, following that trigger's activation. The transmission mechanism means that each activation of the trigger should lead to:
An ignition and directed explosion,i.e. prolellant, causing a rapid force to be generated in a pre-determined direction, which rapidly accelerates:
a projectile, being a dense object which under the directed explosive force of the propellant accelerates rapidly (and which then transfers its energy into its target by decelerating as or more rapidly). 
For the musket, the transmission mechanism (a small amount of black powder in a pan struck by the trigger), the projectile (a lead ball), and the directed propellant (more black powder, poured into the muzzle, followed by wadding rammed along with projectile into the barrel), are all loaded in situ by the user. This means the conditions under which each projectile is propelled (the amount of wadding, the amount of ramming, the amounts of black powder, and so on) will be different each time. It also means that the usual rate of fire might only be around two rounds per minute, maybe three for especially well trained musketeers. 
Then, from the mid 19th century, the standardised round was invented: a metallic casing, with a shaped projectile at one end, a percussion cap at the other, and a fixed quantity and type of explosive powder (the propellant) sitting between the two ends. 
And because of this technological development, whereas a musket might have a rate of fire of two to three rounds per minute, an integrated-cartridge based rifle might easily manage 10 to 15 rounds per minute, so around a 5x increase in earlier rates of fire. 
What the standardised cartridge also provided, as well as convenience for the soldier, was consistency in terms of behaviour. And what this meant was that the recoil forces generated by each projectile firing tended to be consistent and predictable. 
And it appears to be this consistency in recoil forces that allowed the Maxim gun to slip into the 'adjacent possible'. Because in a maxim gun, these recoil forces are used to: 
1. Eject the spent cartridge
2. Load the next cartridge
3. ignite the current cartridge
4. See 1. 
And it's this looping property, a sequence of actions all flowing from each other, as made possible by the standardisation of munitions, that allowed the maxim gun to have a faster rate of fire still than the standard rifle. 
How much faster? 
If the rifle was 5x faster than the musket, then maybe we might naively expect the Maxim gun to be maybe 5x faster than the rifle, so maybe 50-80 rounds per minute. 
But this wasn't the case, the Maxim gun had (and has, they're still in use) a rate of fire over *600 rounds per minute*! So, not a 5x increase, as with muskets to rifles, but over a 50x increase, or over a 250x increase as compared with muskets. 
Put another way, a single Maxim gun unit (maybe a half dozone people?) could fire as many projectiles as literally hundreds of musketeers, or maybe a hundred or so trained archers, and require orders of magniture less training to use. 

So, the Maxim gun was simply on a different order of magnitude of technological advancement to its predecessors. And - Olusoga argues - this technology reshaped the world in profound and devastating ways. 
How? Well, according to Olusoga, in the decade before the invention of the Maxim gun, European nations owned less than 10% of Africa. Within 10 years of the Maxim gun being invented, European nations had successfully conquered over 90% of Africa. Along with quinine, the Maxim gun was possibly the key technology that allowed the European empires to expand south in this way.
Winning battles and conqueuring territory with the Maxim gun required a fundamentally different way of thinking about and doing warfare. The training and temperament of soldiers came to matter much less; the need for good planning and logistics came to matter much more. Maxim guns were machines for firing a lot of bullets, and so become pretty much useless if European powers either ran out of bullets, or ran out of spare parts for the guns. And Maxim guns were *heavy*, meaning if there were ways of moving Maxim guns that didn't depend on human muscle, these should be used in preference. 
In the African context, this meant *gunboats*, mobile platforms through which these machines of devastation could be injected into the veins and arteries of Africa's waterways. (And as settlements across the world tend to form near sources of freshwater, this constraint was likely less onerous for the invading forces than might initially be expected.)
So, a new set of skills, and a new way of working, was needed in order to make effective use of this horrifiying new technology. And within the African subcontinent, it seems all European imperial forces with expansionist ambitions adjusted their ways of invading and projecting power accordingly. European empires, in practice, adjusted their strategies and tactics so as to maximise the effects of the Maxim gun, becoming intercontinental logistics machines that fed the Maxim guns' insationable thirst for ammunition, slaughtering generations of brave and skilled warriors, then forcing peace, on very unequal terms, with the once proud kingdoms these warriors, until recently, served and protected (and terrorised). 

But, although the European Empires adapted their warcraft *in practice*, Olusogu argues, they were blinded - by tradition, by old fashioned notions of 'honour' and 'bravery', and by racism - into not adopting the lessons wholesale into their self-narratives, beliefs and theories. Fundamentally, they did not consider sufficiently the possibility that the African experience on the receiving end of the Maxim gun at the end of the 19th century would translate easily into the European continent, against other 'superior' European nations and empires whose soldiers, the European Empirial Elites believed, were surely drawn from better stock, were better equipped, better trained, braver and more heroic than the primative peoples they had conquered less than a generation ago. 
And this failure - failure to look at the empirical evidence, failure to realise that the laws of physics apply equally to all bodies regardless of language or melanin content, failure to adapt their beliefs about what distinguishes heroism from collective suicide - led to the horrors of the Great War, in which an early 19th century mentality met the Maxim machinegun. The European Elites had over a generation to adapt their worldview to the enormity of the new military technologies they had brought into the world. But for various reasons they did not.

The traditions were long established, the lessons about their historic utility hard won: warfare of European against European empire had for centuries involved some form of rock-paper-scissors interplay between the forces of artillery, musketry (and before that archery) and cavalry. And within this triangular configuration of troop types the apex warriors were considered the cavalry. Winston Churchill, from an Elite family, fiagued and cajoled his way into the cavalry's ranks during the British Empire's dismemberment of Africa in the 19th century, such was the mythic appeal of fighting on horseback with cutlass in hand. And within Africa cavalry were used occasionally to mop up those remnants of African forces who had retreated sufficiently far from the Maxim gun's radius and sightlines. These cavalry battles were then reported and valourised out of proportion to their value in conquering territories, so as to  allow the European Elites to still convince themselves of the continued value of *the old ways*. But in practice, even in the 19th century, they were highly wasteful and ineffective ways of turning European lives into African territory. The European Imperial Elites practiced a form of doublethink, of self deceipt, in continuing to heroise and valourise traditions they themselves had rendered redundant. 



But what relevance does this have to AI? Well, it's because I suspect - when it comes to research, and analysis, and code, and knowledge work - we are at the start of a new Maxim gun moment, and most of us haven't realised it yet. The heroism of learning a profession - spending years studying to become a medical doctor, or accountant, or lawyer, or even statistician - are losing their fundamental comparative value at an exponential rate. Studying and consistently applying if-then rules, the source of the heroic effort and cognitive distinction signaled by membership of such professions, is something computers have always found very easy; it's people who struggle to do this. And now AIs are developing - for all intents and purposes - the capacity to not just recall but to reason about the massive corpus of information inside their gigabrains.  Similarly, the apparently soft and subtle skills of potificating and speechifying, of finding the right form of words to tug at the heartstrings or appeal to the better (or basest) nature of different kinds of audience, the role of essayists, politicians, commentators - turned out to be even easier challenges for LLMs, fed a big corpus of words, to start to master than that of thinking analytically and reasonably. Even the demagogic, sycophantic and 'hallucinary' tendancies of (at least earlier) LLMs, to say what is expected to please the audience over what is factually correct, appears to have been well learned by such models based on the historic records of influential humans who did exactly the same. 

And with the expansion of AIs into ever more modalities - audio, visual, musical as well as textual - and integrated, specialised and applied to ever more domains of human ability and, until recently, brilliance, the magisteria of human comparative advantage starts to retreat to cover ever further. Even the uneven path of retreat is not as the modern Intellectual Elites might have imagined and hoped for: memorising millions of pages of legal text and finding the best arguments for how the laws of all the world's territories are likely to be interpreted and applied: easy for AIs. Folding t-shirts, picking up rubbish, dusting and hoovering: still difficult. But do the rates of retreat from the faultlines - faster in knowledge work, slower when it comes to embodied knowledge - lead amongst contemporary Elites to a reevaluation of what they (what we) value, and consider highly skilled? Not so much. For now, for instance, degrees and professional membership tend to gatekeep the majority of those less hazardous and better paying methods of remuneration, whereas years or decades developing the exquisite gross and fine motor skills that constitute more and less specialised embodied knowledge (elite sports notwithstanding) still tend to count for less. But for how much longer? 

As with the Maxim Gun and the Great War, I suspect the rites and sacrifices involved in becoming specialised knowledge workers may be valued sociologically and culturally decades longer than their economic value holds water. Just as the 'solving' of chess by the cro-magnon brute-force AIs of the late 1990s did not lead to the death of chess-playing as a hobby (just a renewed paranoia that the best human players may be technologically enhanced), and just as the horse or the motor vehicle did not lead to the end of valourisation of those humans who can run fast and/or for long distances, so I suspect institutes of secondary, tertiary and further education will continue to teach much the same material, and grade humans in much the same way, as they always have. And for a long time - possibly decades, possibly a half century - governments and parents may pay for such additional education, and aspirant knowledge workers will continue to seek out such credentialisation. But at some point, perhaps within the next five, the substantive need and value of trying to load such knowledge into slow, lossy human brains will become negligible, if not negative (if it leads to humans not defering tasks to AIs, which the AIs can complete more competently and orders of magnitude faster). The only remaining value of continuing to persue and receive such credentials will be to signal membership and status to other humans, to show that one has devoted oneself to the ancient traditions of Law or Medicine or Engineering, much as centuries before people expressed the vocation they had been called to by taking vows of silence or wearing sackcloth. Even the smartest lawyers won't practice law directly, and the smartest and most empathic medical doctors won't practice diagnosis and treatment of human ailments directly. In both cases, they will become figureheads, taking undue credit 99.99% of the time the AIs' solutions 'work', and taking the liability and blame the 0.01% of the time the AIs made a bad decision or executed it poorly. 
The intellectual elites will call this mast-sitting 'work', and those sitting atop the smartest legions of AIs may find themselves very well remunerated. They will justify their vastly better pay and conditions than those who ranked slightly lower in their professions, and those who did not credentialise them into any profession, by reference to their innate cognitive and moral superiority over less fortunate humans. Even though, compared to the AIs who do they were, they are effectively no different from the other humans whom they disparage. They will, like the European Imperial Elites, try to maintain belief in their own value and superiority even when almost all evidence is to the contrary. 

But eventually, like the Europeans at the receiving end of their own weaponry, like the Roadrunner who looks down, perhaps a generation or two after it becomes objectively net harmful to do so, attitudes and beliefs that sort-of suited the Old Way things were will become replaced, wholesale, by something new, something more realistic with the new reality in which sapiency ceases to be the canonical feature of homo sapiens, and people will have somehow re-evaluated their value, place and purpose in the world. 
How? No idea. When? Also no idea.


















